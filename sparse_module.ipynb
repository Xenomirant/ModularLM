{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6f2e6dc-f7ee-4e8d-9089-32bd090b3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fb81e0-0ae4-47b4-84f7-efc4a367a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675b0346-b198-449c-9540-7e62dd23aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8cff4de-135b-4690-83e4-90355cdb1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc9bb8b-2568-40d6-a08d-b911168807c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a031f9ae-f60b-47bf-ab38-0276bf132a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_module(model, indices, modules):\n",
    "    indices = indices if isinstance(indices, list) else [indices]\n",
    "    modules = modules if isinstance(modules, list) else [modules]\n",
    "    assert len(indices) == len(modules)\n",
    "\n",
    "    layers_name = [name for name, _ in model.named_modules()][1:]\n",
    "    for index, module in zip(indices, modules):\n",
    "        layer_name = re.sub(r'(.)(\\d)', r'[\\2]', layers_name[index])\n",
    "        exec(\"model.{name} = nn.Sequential(model.{name}, module)\".format(name = layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "961bb6fe-34e5-4824-b4e9-1efd943741ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "    \n",
    "        super().__init__()\n",
    "\n",
    "        self.pretrained = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        return self.pretrained(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa4fcb84-d189-4074-90e7-b9a3c98f9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_name = [name for name, _ in model.pretrained.named_modules()][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e09513e-0edf-4467-a61e-6231b363906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embeddings',\n",
       " 'embeddings.word_embeddings',\n",
       " 'embeddings.position_embeddings',\n",
       " 'embeddings.LayerNorm',\n",
       " 'embeddings.dropout',\n",
       " 'transformer',\n",
       " 'transformer.layer',\n",
       " 'transformer.layer.0',\n",
       " 'transformer.layer.0.attention',\n",
       " 'transformer.layer.0.attention.dropout',\n",
       " 'transformer.layer.0.attention.q_lin',\n",
       " 'transformer.layer.0.attention.k_lin',\n",
       " 'transformer.layer.0.attention.v_lin',\n",
       " 'transformer.layer.0.attention.out_lin',\n",
       " 'transformer.layer.0.sa_layer_norm',\n",
       " 'transformer.layer.0.ffn',\n",
       " 'transformer.layer.0.ffn.dropout',\n",
       " 'transformer.layer.0.ffn.lin1',\n",
       " 'transformer.layer.0.ffn.lin2',\n",
       " 'transformer.layer.0.ffn.activation',\n",
       " 'transformer.layer.0.output_layer_norm',\n",
       " 'transformer.layer.1',\n",
       " 'transformer.layer.1.attention',\n",
       " 'transformer.layer.1.attention.dropout',\n",
       " 'transformer.layer.1.attention.q_lin',\n",
       " 'transformer.layer.1.attention.k_lin',\n",
       " 'transformer.layer.1.attention.v_lin',\n",
       " 'transformer.layer.1.attention.out_lin',\n",
       " 'transformer.layer.1.sa_layer_norm',\n",
       " 'transformer.layer.1.ffn',\n",
       " 'transformer.layer.1.ffn.dropout',\n",
       " 'transformer.layer.1.ffn.lin1',\n",
       " 'transformer.layer.1.ffn.lin2',\n",
       " 'transformer.layer.1.ffn.activation',\n",
       " 'transformer.layer.1.output_layer_norm',\n",
       " 'transformer.layer.2',\n",
       " 'transformer.layer.2.attention',\n",
       " 'transformer.layer.2.attention.dropout',\n",
       " 'transformer.layer.2.attention.q_lin',\n",
       " 'transformer.layer.2.attention.k_lin',\n",
       " 'transformer.layer.2.attention.v_lin',\n",
       " 'transformer.layer.2.attention.out_lin',\n",
       " 'transformer.layer.2.sa_layer_norm',\n",
       " 'transformer.layer.2.ffn',\n",
       " 'transformer.layer.2.ffn.dropout',\n",
       " 'transformer.layer.2.ffn.lin1',\n",
       " 'transformer.layer.2.ffn.lin2',\n",
       " 'transformer.layer.2.ffn.activation',\n",
       " 'transformer.layer.2.output_layer_norm',\n",
       " 'transformer.layer.3',\n",
       " 'transformer.layer.3.attention',\n",
       " 'transformer.layer.3.attention.dropout',\n",
       " 'transformer.layer.3.attention.q_lin',\n",
       " 'transformer.layer.3.attention.k_lin',\n",
       " 'transformer.layer.3.attention.v_lin',\n",
       " 'transformer.layer.3.attention.out_lin',\n",
       " 'transformer.layer.3.sa_layer_norm',\n",
       " 'transformer.layer.3.ffn',\n",
       " 'transformer.layer.3.ffn.dropout',\n",
       " 'transformer.layer.3.ffn.lin1',\n",
       " 'transformer.layer.3.ffn.lin2',\n",
       " 'transformer.layer.3.ffn.activation',\n",
       " 'transformer.layer.3.output_layer_norm',\n",
       " 'transformer.layer.4',\n",
       " 'transformer.layer.4.attention',\n",
       " 'transformer.layer.4.attention.dropout',\n",
       " 'transformer.layer.4.attention.q_lin',\n",
       " 'transformer.layer.4.attention.k_lin',\n",
       " 'transformer.layer.4.attention.v_lin',\n",
       " 'transformer.layer.4.attention.out_lin',\n",
       " 'transformer.layer.4.sa_layer_norm',\n",
       " 'transformer.layer.4.ffn',\n",
       " 'transformer.layer.4.ffn.dropout',\n",
       " 'transformer.layer.4.ffn.lin1',\n",
       " 'transformer.layer.4.ffn.lin2',\n",
       " 'transformer.layer.4.ffn.activation',\n",
       " 'transformer.layer.4.output_layer_norm',\n",
       " 'transformer.layer.5',\n",
       " 'transformer.layer.5.attention',\n",
       " 'transformer.layer.5.attention.dropout',\n",
       " 'transformer.layer.5.attention.q_lin',\n",
       " 'transformer.layer.5.attention.k_lin',\n",
       " 'transformer.layer.5.attention.v_lin',\n",
       " 'transformer.layer.5.attention.out_lin',\n",
       " 'transformer.layer.5.sa_layer_norm',\n",
       " 'transformer.layer.5.ffn',\n",
       " 'transformer.layer.5.ffn.dropout',\n",
       " 'transformer.layer.5.ffn.lin1',\n",
       " 'transformer.layer.5.ffn.lin2',\n",
       " 'transformer.layer.5.ffn.activation',\n",
       " 'transformer.layer.5.output_layer_norm']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd5d0c13-460f-4b6d-af9d-5e9611bd0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparse_part(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin = nn.Linear(in_features=in_dim, out_features=out_dim)\n",
    "        self.laynorm = nn.LayerNorm(out_dim)\n",
    "        self.act = nn.ReLU6()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = self.lin(input)\n",
    "        x = self.laynorm(self.act(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652d2f0a-c740-4f3e-bd6c-1cf4544d83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparse_module(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_size: int, internal_size: int):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer = sparse_part(layer_size, internal_size)\n",
    "\n",
    "        self.bootleneck = sparse_part(internal_size, internal_size//8)\n",
    "\n",
    "        self.output = nn.Linear(internal_size//8, layer_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = self.layer(input)\n",
    "        x = self.bottleneck(self.lin2(input))\n",
    "        x = nn.functional.leaky_relu(self.output(x))\n",
    "\n",
    "        return x, nn.functional.l1_loss(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a297e76f-ae95-49b9-b093-75990f4df3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4591e74-179e-47dc-ab5b-34a3be9fde59",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_module(model.pretrained, 33, sparse_module(768, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "676e7666-2f8a-4b75-8610-85ba20531742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('',\n",
       "  DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): Sequential(\n",
       "              (0): GELUActivation()\n",
       "              (1): sparse_module(\n",
       "                (layer): sparse_part(\n",
       "                  (lin): Linear(in_features=768, out_features=96, bias=True)\n",
       "                  (laynorm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (bootleneck): sparse_part(\n",
       "                  (lin): Linear(in_features=96, out_features=12, bias=True)\n",
       "                  (laynorm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "                  (act): ReLU6()\n",
       "                )\n",
       "                (output): Linear(in_features=12, out_features=768, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2-5): 4 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )),\n",
       " ('embeddings',\n",
       "  Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('embeddings.word_embeddings', Embedding(30522, 768, padding_idx=0)),\n",
       " ('embeddings.position_embeddings', Embedding(512, 768)),\n",
       " ('embeddings.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('embeddings.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer',\n",
       "  Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): Sequential(\n",
       "            (0): GELUActivation()\n",
       "            (1): sparse_module(\n",
       "              (layer): sparse_part(\n",
       "                (lin): Linear(in_features=768, out_features=96, bias=True)\n",
       "                (laynorm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "                (act): ReLU6()\n",
       "              )\n",
       "              (bootleneck): sparse_part(\n",
       "                (lin): Linear(in_features=96, out_features=12, bias=True)\n",
       "                (laynorm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "                (act): ReLU6()\n",
       "              )\n",
       "              (output): Linear(in_features=12, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2-5): 4 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )),\n",
       " ('transformer.layer',\n",
       "  ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (attention): MultiHeadSelfAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (ffn): FFN(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attention): MultiHeadSelfAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (ffn): FFN(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (activation): Sequential(\n",
       "          (0): GELUActivation()\n",
       "          (1): sparse_module(\n",
       "            (layer): sparse_part(\n",
       "              (lin): Linear(in_features=768, out_features=96, bias=True)\n",
       "              (laynorm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "              (act): ReLU6()\n",
       "            )\n",
       "            (bootleneck): sparse_part(\n",
       "              (lin): Linear(in_features=96, out_features=12, bias=True)\n",
       "              (laynorm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "              (act): ReLU6()\n",
       "            )\n",
       "            (output): Linear(in_features=12, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (2-5): 4 x TransformerBlock(\n",
       "      (attention): MultiHeadSelfAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (ffn): FFN(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "  )),\n",
       " ('transformer.layer.0',\n",
       "  TransformerBlock(\n",
       "    (attention): MultiHeadSelfAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (ffn): FFN(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )),\n",
       " ('transformer.layer.0.attention',\n",
       "  MultiHeadSelfAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )),\n",
       " ('transformer.layer.0.attention.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.0.attention.q_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.0.attention.k_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.0.attention.v_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.0.attention.out_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.0.sa_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.0.ffn',\n",
       "  FFN(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "  )),\n",
       " ('transformer.layer.0.ffn.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.0.ffn.lin1',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('transformer.layer.0.ffn.lin2',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('transformer.layer.0.ffn.activation', GELUActivation()),\n",
       " ('transformer.layer.0.output_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.1',\n",
       "  TransformerBlock(\n",
       "    (attention): MultiHeadSelfAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (ffn): FFN(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (activation): Sequential(\n",
       "        (0): GELUActivation()\n",
       "        (1): sparse_module(\n",
       "          (layer): sparse_part(\n",
       "            (lin): Linear(in_features=768, out_features=96, bias=True)\n",
       "            (laynorm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (act): ReLU6()\n",
       "          )\n",
       "          (bootleneck): sparse_part(\n",
       "            (lin): Linear(in_features=96, out_features=12, bias=True)\n",
       "            (laynorm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "            (act): ReLU6()\n",
       "          )\n",
       "          (output): Linear(in_features=12, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )),\n",
       " ('transformer.layer.1.attention',\n",
       "  MultiHeadSelfAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )),\n",
       " ('transformer.layer.1.attention.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.1.attention.q_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.1.attention.k_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.1.attention.v_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.1.attention.out_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.1.sa_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.1.ffn',\n",
       "  FFN(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (activation): Sequential(\n",
       "      (0): GELUActivation()\n",
       "      (1): sparse_module(\n",
       "        (layer): sparse_part(\n",
       "          (lin): Linear(in_features=768, out_features=96, bias=True)\n",
       "          (laynorm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (act): ReLU6()\n",
       "        )\n",
       "        (bootleneck): sparse_part(\n",
       "          (lin): Linear(in_features=96, out_features=12, bias=True)\n",
       "          (laynorm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "          (act): ReLU6()\n",
       "        )\n",
       "        (output): Linear(in_features=12, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )),\n",
       " ('transformer.layer.1.ffn.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.1.ffn.lin1',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('transformer.layer.1.ffn.lin2',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('transformer.layer.1.ffn.activation',\n",
       "  Sequential(\n",
       "    (0): GELUActivation()\n",
       "    (1): sparse_module(\n",
       "      (layer): sparse_part(\n",
       "        (lin): Linear(in_features=768, out_features=96, bias=True)\n",
       "        (laynorm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (act): ReLU6()\n",
       "      )\n",
       "      (bootleneck): sparse_part(\n",
       "        (lin): Linear(in_features=96, out_features=12, bias=True)\n",
       "        (laynorm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "        (act): ReLU6()\n",
       "      )\n",
       "      (output): Linear(in_features=12, out_features=768, bias=True)\n",
       "    )\n",
       "  )),\n",
       " ('transformer.layer.1.ffn.activation.0', GELUActivation()),\n",
       " ('transformer.layer.1.ffn.activation.1',\n",
       "  sparse_module(\n",
       "    (layer): sparse_part(\n",
       "      (lin): Linear(in_features=768, out_features=96, bias=True)\n",
       "      (laynorm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      (act): ReLU6()\n",
       "    )\n",
       "    (bootleneck): sparse_part(\n",
       "      (lin): Linear(in_features=96, out_features=12, bias=True)\n",
       "      (laynorm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "      (act): ReLU6()\n",
       "    )\n",
       "    (output): Linear(in_features=12, out_features=768, bias=True)\n",
       "  )),\n",
       " ('transformer.layer.1.ffn.activation.1.layer',\n",
       "  sparse_part(\n",
       "    (lin): Linear(in_features=768, out_features=96, bias=True)\n",
       "    (laynorm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    (act): ReLU6()\n",
       "  )),\n",
       " ('transformer.layer.1.ffn.activation.1.layer.lin',\n",
       "  Linear(in_features=768, out_features=96, bias=True)),\n",
       " ('transformer.layer.1.ffn.activation.1.layer.laynorm',\n",
       "  LayerNorm((96,), eps=1e-05, elementwise_affine=True)),\n",
       " ('transformer.layer.1.ffn.activation.1.layer.act', ReLU6()),\n",
       " ('transformer.layer.1.ffn.activation.1.bootleneck',\n",
       "  sparse_part(\n",
       "    (lin): Linear(in_features=96, out_features=12, bias=True)\n",
       "    (laynorm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
       "    (act): ReLU6()\n",
       "  )),\n",
       " ('transformer.layer.1.ffn.activation.1.bootleneck.lin',\n",
       "  Linear(in_features=96, out_features=12, bias=True)),\n",
       " ('transformer.layer.1.ffn.activation.1.bootleneck.laynorm',\n",
       "  LayerNorm((12,), eps=1e-05, elementwise_affine=True)),\n",
       " ('transformer.layer.1.ffn.activation.1.bootleneck.act', ReLU6()),\n",
       " ('transformer.layer.1.ffn.activation.1.output',\n",
       "  Linear(in_features=12, out_features=768, bias=True)),\n",
       " ('transformer.layer.1.output_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.2',\n",
       "  TransformerBlock(\n",
       "    (attention): MultiHeadSelfAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (ffn): FFN(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )),\n",
       " ('transformer.layer.2.attention',\n",
       "  MultiHeadSelfAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )),\n",
       " ('transformer.layer.2.attention.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.2.attention.q_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.2.attention.k_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.2.attention.v_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.2.attention.out_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.2.sa_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.2.ffn',\n",
       "  FFN(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "  )),\n",
       " ('transformer.layer.2.ffn.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.2.ffn.lin1',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('transformer.layer.2.ffn.lin2',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('transformer.layer.2.ffn.activation', GELUActivation()),\n",
       " ('transformer.layer.2.output_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.3',\n",
       "  TransformerBlock(\n",
       "    (attention): MultiHeadSelfAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (ffn): FFN(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )),\n",
       " ('transformer.layer.3.attention',\n",
       "  MultiHeadSelfAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )),\n",
       " ('transformer.layer.3.attention.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.3.attention.q_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.3.attention.k_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.3.attention.v_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.3.attention.out_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.3.sa_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.3.ffn',\n",
       "  FFN(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "  )),\n",
       " ('transformer.layer.3.ffn.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.3.ffn.lin1',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('transformer.layer.3.ffn.lin2',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('transformer.layer.3.ffn.activation', GELUActivation()),\n",
       " ('transformer.layer.3.output_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.4',\n",
       "  TransformerBlock(\n",
       "    (attention): MultiHeadSelfAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (ffn): FFN(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )),\n",
       " ('transformer.layer.4.attention',\n",
       "  MultiHeadSelfAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )),\n",
       " ('transformer.layer.4.attention.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.4.attention.q_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.4.attention.k_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.4.attention.v_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.4.attention.out_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.4.sa_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.4.ffn',\n",
       "  FFN(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "  )),\n",
       " ('transformer.layer.4.ffn.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.4.ffn.lin1',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('transformer.layer.4.ffn.lin2',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('transformer.layer.4.ffn.activation', GELUActivation()),\n",
       " ('transformer.layer.4.output_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.5',\n",
       "  TransformerBlock(\n",
       "    (attention): MultiHeadSelfAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    )\n",
       "    (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (ffn): FFN(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )),\n",
       " ('transformer.layer.5.attention',\n",
       "  MultiHeadSelfAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "  )),\n",
       " ('transformer.layer.5.attention.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.5.attention.q_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.5.attention.k_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.5.attention.v_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.5.attention.out_lin',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('transformer.layer.5.sa_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('transformer.layer.5.ffn',\n",
       "  FFN(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (activation): GELUActivation()\n",
       "  )),\n",
       " ('transformer.layer.5.ffn.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('transformer.layer.5.ffn.lin1',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('transformer.layer.5.ffn.lin2',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('transformer.layer.5.ffn.activation', GELUActivation()),\n",
       " ('transformer.layer.5.output_layer_norm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.pretrained.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a6ec6170-03a1-4e22-b98f-4f4eff406c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30261ff8-c233-4362-92ab-db2f2d265b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a95de7c-3c7f-409d-b513-0cc0dc42efca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2d9bcd12-831a-43de-bc33-239865fab11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,  102]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoded_input.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "545394c0-e015-49d2-8d41-d38e2005359a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1, 12]), torch.Size([1, 12])]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[val.shape for val in  encoded_input.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1700f2-ae67-4abc-b700-786fbdac7ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "525d6207-84fb-4c4b-8d32-c318065ade26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorchsummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[33], line 12\u001b[0m, in \u001b[0;36mencoder.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:822\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    820\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[0;32m--> 822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:587\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    579\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    580\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    581\u001b[0m         hidden_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    584\u001b[0m         output_attentions,\n\u001b[1;32m    585\u001b[0m     )\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 587\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/distilbert/modeling_distilbert.py:513\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    522\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1547\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1545\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1547\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1550\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchsummary/torchsummary.py:19\u001b[0m, in \u001b[0;36msummary.<locals>.register_hook.<locals>.hook\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     17\u001b[0m m_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (class_name, module_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m summary[m_key] \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m---> 19\u001b[0m summary[m_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     20\u001b[0m summary[m_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, input_size=[(512, )],\n",
    "                    device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e3fdbda7-89a1-4d27-96d1-b6072c751c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
