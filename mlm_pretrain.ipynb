{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77fd790a-b5cd-4884-814a-caf435148f96",
   "metadata": {},
   "outputs": [],
   "source": [
    " #! pip install accelerate==0.27.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e24773c-b515-4c6b-bf22-aa5a076b243f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BertForMaskedLM,\n",
    "    get_scheduler,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback\n",
    ")\n",
    "import io\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import wandb\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea03d9f-1ce5-442b-be15-8cfd46aef8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MinioHandler import MinioHandler\n",
    "\n",
    "minio = MinioHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3dd15c6-13e8-438a-8ceb-ce3355e7bf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxenomirant\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxenomirant\u001b[0m (\u001b[33mgrammar-bert\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/ModularLM/wandb/run-20240509_225323-jjhqgywx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grammar-bert/pretrain-bert/runs/jjhqgywx' target=\"_blank\">Poly MLM head higher lr</a></strong> to <a href='https://wandb.ai/grammar-bert/pretrain-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grammar-bert/pretrain-bert' target=\"_blank\">https://wandb.ai/grammar-bert/pretrain-bert</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grammar-bert/pretrain-bert/runs/jjhqgywx' target=\"_blank\">https://wandb.ai/grammar-bert/pretrain-bert/runs/jjhqgywx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/grammar-bert/pretrain-bert/runs/jjhqgywx?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7852705fd720>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "wandb.init(\n",
    "    project='pretrain-bert',\n",
    "    entity='grammar-bert',\n",
    "    name=\"Poly MLM head higher lr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb6a601-9503-4773-a4a9-67ff67f3488c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b4cf068-544d-4572-9b83-6022f4d99cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/train_dataset.csv'\n",
    "TEST_PATH = 'data/test_dataset.csv'\n",
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased'\n",
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 128\n",
    "MLM_PROB = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f94118a-eb4a-4d25-ac49-0d3b85ed1876",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = \"ckpt/pretrained_bert/model_epoch_10.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8e8664-43d1-4bf8-a0de-345a38628007",
   "metadata": {
    "id": "V06Z3lby7xme"
   },
   "outputs": [],
   "source": [
    "def collate_func(batch):\n",
    "    batch = [data_collator.torch_call(item) for item in zip(*batch)]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7737d08f-1c9f-4a0b-9bb0-3f33289dbf96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7JP-0xw72PH",
    "outputId": "2f1ca2ee-6378-4dae-cd1e-3eac9d6235a9"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True\n",
    "\n",
    "tokenizer.pad_token = '[SEP]'\n",
    "tokenizer.eos_token = '[SEP]'\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=MLM_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def20330-58a2-49ed-9d14-3bcaba3b1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = load_dataset(\"csv\", \n",
    "                  data_files={\"train\": TRAIN_PATH,\n",
    "                                \"test\": TEST_PATH},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ef092f-cd53-4b9d-a9c9-036d704d178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"polypers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b319270f-113e-450b-9134-41fad7f0ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dt = dt.map(tokenize_function, batched=True, remove_columns=[\"Unnamed: 0\", \"base\", \"was_changed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5de443a1-aa40-4052-bd46-60bb8359c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "284d38f7-0bc3-490c-8071-c89fbc06d70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=119547, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3210ccf9-670f-4235-b8fb-085f93235968",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = minio.get_object(WEIGHTS_PATH, type=\"model\")\n",
    "model_dict = torch.load(ckpt)\n",
    "\n",
    "# necessary for averaged models\n",
    "# model_dict[\"model_state_dict\"] = {\".\".join(k.split(\".\")[1:]): v for k, v in model_dict[\"model_state_dict\"].items() if \".\".join(k.split(\".\")[1:])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "000edfdf-8b7e-4b1b-aa2c-bc8087d44fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b943f1-0b30-4b89-8be8-13117618e437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bae9bf-5ec1-4b53-9f44-e5fe7157b168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04009075-8125-422f-8670-b75bd788f643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0411, -2.3667, -1.9080,  ..., -1.8968, -1.8275, -1.8176],\n",
       "        [ 3.2326, -2.7675, -2.5292,  ..., -2.2934,  1.3292, -2.3785],\n",
       "        [ 2.1270,  0.2167, -1.5603,  ..., -2.1788, -0.1589, -2.4368],\n",
       "        [ 0.0673,  0.5578, -3.3598,  ...,  3.8780,  9.6325, -3.7395],\n",
       "        [-2.1819,  2.7796, -2.1316,  ..., -2.0703, -2.4410, -2.5248]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cls.predictions.transform(torch.randn((5, 768)).to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac58289a-82c4-4796-a0e8-14e1857c2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name.startswith(\"cls\"):\n",
    "        param.requires_grad = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03f6c1bc-0f1c-47cf-91ce-6a4323674b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls.predictions.bias\n",
      "cls.predictions.transform.dense.weight\n",
      "cls.predictions.transform.dense.bias\n",
      "cls.predictions.transform.LayerNorm.weight\n",
      "cls.predictions.transform.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82e6ae3-51f1-4f33-9ef2-5649db6aaf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "867d930e-3fd1-4e83-ba99-e5e66db0df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveCallback(TrainerCallback):\n",
    "\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        '''\n",
    "        A callback that prints a message at the beginning of training\n",
    "        '''\n",
    "        print(\"Starting training\")\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        '''\n",
    "        Saves to S3 at the end of epoch\n",
    "        '''\n",
    "        print(\"Saving model checkpoint...\")\n",
    "        buffer = io.BytesIO()\n",
    "        torch.save({\n",
    "                    'epoch': state.epoch,\n",
    "                    'model_state_dict': OrderedDict({k: v for k, v in kwargs[\"model\"].cls.state_dict().items() if ~k.startswith(\"predictions.decoder\")}),\n",
    "                    'optimizer_state_dict': kwargs[\"optimizer\"].state_dict(),\n",
    "                    }, \n",
    "                   f=buffer)\n",
    "                # TODO -- add custom hash to model instead of value\n",
    "        minio.put_object(buffer.getvalue(), \n",
    "                             save_name=f\"ckpt/poly_mlm-head_higher_lr_epoch_{int(state.epoch)}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7b61792-62b5-4be6-a8f1-678cf2b7e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from transformers.trainer_callback import ProgressCallback\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "\n",
    "def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "    if state.is_local_process_zero and self.training_bar is not None:\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "ProgressCallback.on_log = on_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11aaa7f8-3bfc-4039-a764-2ecce3083a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1535: FutureWarning: `--adafactor` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--optim adafactor` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"ckpt/poly_mlm-head higher lr\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    dataloader_drop_last=True,\n",
    "    dataloader_num_workers=6, \n",
    "    learning_rate=3e-3,\n",
    "    num_train_epochs=5,\n",
    "    gradient_accumulation_steps=6,\n",
    "    per_device_train_batch_size=8,\n",
    "    adafactor=True,\n",
    "    optim=\"adafactor\",\n",
    "    warmup_steps=1000,\n",
    "    report_to=\"wandb\", \n",
    "    logging_steps=5000,\n",
    "    save_steps=25000,\n",
    "    save_total_limit=10,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dt[\"train\"],\n",
    "    eval_dataset=tokenized_dt[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[SaveCallback, ProgressCallback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f10215a7-e698-455e-b73d-7c5c200f04e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84e5cac-550d-4424-b97a-b41cef1cb252",
   "metadata": {},
   "source": [
    "#### Infinite tries to disable logging to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c5dd9-e9f3-496a-964f-3af28487b5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9c90f08d4744fe8ced78d3b6faf02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='178109' max='215480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [178109/215480 8:36:25 < 1:48:21, 5.75 it/s, Epoch 4.13/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.852500</td>\n",
       "      <td>1.878477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.771700</td>\n",
       "      <td>1.823570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.757800</td>\n",
       "      <td>1.802954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint...\n",
      "ModularLM/ckpt/poly_mlm-head_higher_lr_epoch_0.pt: |####################| 353.43 MB/353.43 MB 100% [elapsed: 00:04 left: 00:00, 73.03 MB/sec]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28731 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint...\n",
      "ModularLM/ckpt/poly_mlm-head_higher_lr_epoch_4.pt: |####################| 353.43 MB/353.43 MB 100% [elapsed: 00:04 left: 00:00, 86.31 MB/sec] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28731 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
