{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkRjTgTvHt0C"
   },
   "source": [
    "# Bert Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jESjuwfQHw8c"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SSzfVu-SnBOl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.39.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
      "Requirement already satisfied: maskedtensor in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: torch==1.12 in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
      "Requirement already satisfied: minio in /usr/local/lib/python3.10/dist-packages (7.2.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12) (4.8.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.6)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.44.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (69.0.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from minio) (2023.11.17)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio) (2.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio) (23.1.0)\n",
      "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from minio) (3.20.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio) (21.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio) (2.21)\n",
      "\u001b[33mDEPRECATION: nb-black 1.0.7 has a non-standard dependency specifier black>='19.3'; python_version >= \"3.6\". pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of nb-black or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers datasets evaluate wandb maskedtensor torch==1.12 minio tqdm scipy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K8_hHVCNnBOq"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pickle as pkl\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BertForMaskedLM,\n",
    "    get_scheduler,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "from maskedtensor import masked_tensor\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import io\n",
    "from PairsDataset import PairsDataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRY_NAME = \"naive_cosine_with_pretrained_bert_lower_lr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=f\"logs/{TRY_NAME}_grad_log\", filemode=\"w\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio handler to use remote data -- implements get and put methods with pickling option (view file)\n",
    "\n",
    "from MinioHandler import MinioHandler\n",
    "\n",
    "minio = MinioHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMZUfmdLEBnR",
    "outputId": "75c4dd46-dd6c-4f31-ad83-74a0a565b17c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fF-ss42aIADq"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZ1tRDh5RvDP",
    "outputId": "93a64300-36f2-4450-dded-ede6b6454b44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxenomirant\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "_XaOQ4gtSauA",
    "outputId": "94169790-8c91-4460-aaf1-56ab846703ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxenomirant\u001b[0m (\u001b[33mgrammar-bert\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/ModularLM/wandb/run-20240406_232038-hvmxm1ne</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grammar-bert/grammar-bert-model1/runs/hvmxm1ne' target=\"_blank\">crusher-seven-118</a></strong> to <a href='https://wandb.ai/grammar-bert/grammar-bert-model1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grammar-bert/grammar-bert-model1' target=\"_blank\">https://wandb.ai/grammar-bert/grammar-bert-model1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grammar-bert/grammar-bert-model1/runs/hvmxm1ne' target=\"_blank\">https://wandb.ai/grammar-bert/grammar-bert-model1/runs/hvmxm1ne</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/grammar-bert/grammar-bert-model1/runs/hvmxm1ne?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x72b86ccf5360>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='grammar-bert-model1',\n",
    "    entity='grammar-bert'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zi_u2NiL0mgC",
    "outputId": "cbeb7da4-03ef-40c1-a015-90ec071ab357"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KTpeEhBwIBdl"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 16\n",
    "MLM_PROB = 0.15\n",
    "\n",
    "#DATA_PATH = '/content/drive/MyDrive/nnlp/bert/biblioteka_prikluchenij_both_agr.csv'\n",
    "DATA_PATH = \"data/train_dataset.csv\"\n",
    "TEST_PATH = \"data/tda_test.csv\"\n",
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased'\n",
    "WEIGHTS_PATH = \"ckpt/pretrained_bert_epoch_9.999976796259556.pt\"\n",
    "# whether to log the layers being changed (happens once per notebook restart)\n",
    "LOG_LAYERS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zdbf_sj8Hy_9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TQrOptuKvk4A"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(DATA_PATH, index_col = 0)\n",
    "# df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df.was_changed].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GB-e4FABxy8y"
   },
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "\n",
    "# idx_init = df.initial.progress_apply(lambda x: x.replace(' ', ''))\n",
    "# idx_pol = df.polypers.progress_apply(lambda x: x.replace(' ', ''))\n",
    "# idx = -(idx_init == idx_pol)\n",
    "# df['was_changed'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yrQu60MLz9cT"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Train test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TEST_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(DATA_PATH, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = train_test_split(df, test_size=TEST_SIZE, stratify = df[\"was_changed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(\"data/train_bpa.csv\")\n",
    "# test.to_csv(\"data/test_bpa.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pick items from test for TDA and homology computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/test_bpa.csv\", index_col = 0)\n",
    "\n",
    "# df = df[df.was_changed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tda_data = df.sample(n = 250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tda_data.to_csv(\"tda_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.put_object(tda_data, save_name=\"data/tda_test.pkl\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything to minio -- also possible to use default minio functions from Minio class\n",
    "\n",
    "# minio.minio.fput_object(file_path=\"data/test_dataset.csv\", bucket_name=\"public\",\n",
    "#                       object_name=\"ModularLM/data/test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDe7I4QR4gVY"
   },
   "source": [
    "## Dataset and collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "V06Z3lby7xme"
   },
   "outputs": [],
   "source": [
    "def collate_func(batch):\n",
    "    batch = [data_collator.torch_call(item) for item in zip(*batch)]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7JP-0xw72PH",
    "outputId": "2f1ca2ee-6378-4dae-cd1e-3eac9d6235a9"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenizer.pad_token = '[SEP]'\n",
    "tokenizer.eos_token = '[SEP]'\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=MLM_PROB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh94UBHqxuSA",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MLM Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Mb9N8GAh_9Te"
   },
   "outputs": [],
   "source": [
    "# dt = datasets.Dataset.from_csv(DATA_PATH)\n",
    "# dt = dt.remove_columns(['polypers', 'was_changed']).rename_column('initial', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "d84hj1c4IQwT"
   },
   "outputs": [],
   "source": [
    "# N_samples = 10**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6ZHrIWiQA_rn"
   },
   "outputs": [],
   "source": [
    "# def tokenize_function(example):\n",
    "#     return tokenizer(example['text'], truncation=True)\n",
    "\n",
    "# tok_dt = dt.select(range(N_samples)).map(tokenize_function, batched=True)\n",
    "# tok_dt = tok_dt.train_test_split(test_size=100,\n",
    "#                          shuffle=True,\n",
    "#                          seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "AKDqk2mzBQz-"
   },
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     report_to = 'wandb',\n",
    "#     output_dir='part1-model',\n",
    "#     learning_rate=1e-3,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     num_train_epochs=1,\n",
    "#     # evaluation_strategy='steps',\n",
    "#     # eval_steps=20,\n",
    "#     logging_steps=20,\n",
    "#     logging_first_step=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "F3MYlLtm76uJ"
   },
   "outputs": [],
   "source": [
    "# model = BertForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "# model.to(device)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "LC0KZCwqA50q"
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tok_dt['train'],\n",
    "#     # eval_dataset=tok_dt['test'],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7vEzJTIREz0k"
   },
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8nu5cYyIxDd"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "4RB10XU9bMbH"
   },
   "outputs": [],
   "source": [
    "def save_gradients(model, division_layer):\n",
    "    layers = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        # division layer passed == division layer + 1 as is inside train\n",
    "        if name.startswith(f'bert.encoder.layer.{division_layer}'):\n",
    "            break\n",
    "        if (param.requires_grad) and param.grad is not None:\n",
    "            layers[name] = param.grad.detach().clone()\n",
    "    if LOG_LAYERS:\n",
    "        logger.info(f\"Saved layers: {str(layers.keys())}\")\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "qHcpG4G8cclV"
   },
   "outputs": [],
   "source": [
    "def change_gradients(*, model, layers, \n",
    "                     division_layer,\n",
    "                     weight_mlm=0.5, \n",
    "                     weight_cos=1, ):\n",
    "\n",
    "    global LOG_LAYERS\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        # division layer passed == division layer + 1 as is inside train\n",
    "        if name.startswith(f'bert.encoder.layer.{division_layer}'):\n",
    "            break\n",
    "        if name in layers:\n",
    "            param.grad = weight_cos * param.grad + weight_mlm * layers[name]\n",
    "            if LOG_LAYERS:\n",
    "                logger.info(f\"Changed layer: {name}\")\n",
    "                logger.info(f\"gradients changed. {(weight_cos * param.grad).norm(), (weight_mlm * layers[name]).norm()}\\n\")\n",
    "    LOG_LAYERS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "H9vdmHBsLAXg"
   },
   "outputs": [],
   "source": [
    "class CosWeightDecay:\n",
    "    '''\n",
    "    Cosine Weight with decaying step sizes after each multiplication\n",
    "    '''\n",
    "    def __init__(self, init_state=1, step=0.5):\n",
    "        self.cur_state = init_state\n",
    "        self.step = step\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        res = self.cur_state * other\n",
    "        self.cur_state = self.cur_state * self.step\n",
    "        return res\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.cur_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "H9vdmHBsLAXg"
   },
   "outputs": [],
   "source": [
    "class CosWeightSum2One:\n",
    "    '''\n",
    "    Cosine Weight summing to 1 over 10 steps (must be subject to change in case other step size is required)\n",
    "    This looks quite dumb...\n",
    "    '''\n",
    "    def __init__(self, init_coef = 100, steps: int = 10, linear = False):\n",
    "        self.counter = -1\n",
    "        if linear:\n",
    "            self.steps = init_coef*np.ones(steps)\n",
    "            return None\n",
    "        self.steps = init_coef*np.arange(2, steps+2)**-1.5\n",
    "        return None\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        res = self.steps[self.counter] * other\n",
    "        return res\n",
    "    \n",
    "    def step(self):\n",
    "        self.counter+=1\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.steps[self.counter])\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = -1\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.steps[self.counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "RsNP-PPvQayL"
   },
   "outputs": [],
   "source": [
    "class CosLoss:\n",
    "    def __init__(self, vector=None, alpha=0):\n",
    "        self.loss = nn.CosineEmbeddingLoss()\n",
    "        self.target = torch.ones(BATCH_SIZE).to(model.device)\n",
    "        self.alpha = alpha\n",
    "        self.vector = vector\n",
    "\n",
    "    def __call__(self, hid_ref, hid_cur, target):\n",
    "        cos_loss = self.loss(hid_ref, hid_cur, target)\n",
    "        if self.vector is not None:\n",
    "            cos_loss += self.alpha * self.loss(self.vector, hid_ref - hid_cur,\n",
    "                                               self.target)\n",
    "        return cos_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "74aJSuBCtRcI"
   },
   "outputs": [],
   "source": [
    "def train(model, criteria, optimizer, lr_scheduler, data, hom_data, n_epochs=1,\n",
    "          n_cosine=10, division_layer=4, weight_mlm=1,\n",
    "          weight_cos=1, save_every_epoch=3, test_every=5000):\n",
    "\n",
    "    # global mlm_losses, cosine_losses\n",
    "    # change global loss tracking to local only -- for now it seems unnecessary\n",
    "    global tda_save_dict\n",
    "\n",
    "    tq_epoch = trange(n_epochs, desc='Epochs: ')\n",
    "    tq_batch = tqdm(total=len(data))\n",
    "\n",
    "    # target for cosine loss\n",
    "    target = -torch.ones(BATCH_SIZE).to(model.device)\n",
    "    grads = None\n",
    "    \n",
    "    # just initialization -- first few batches make no difference for tracking\n",
    "    cos_loss = 0\n",
    "    mlm_loss = 0\n",
    "    hom_computed = 0\n",
    "    # TODO -- optimize for gradual saving of dict intead of accumulation\n",
    "\n",
    "\n",
    "    # save necessary features to dict\n",
    "    def save_tda_features(hom_data: torch.utils.data.DataLoader, save_dict: dict):\n",
    "\n",
    "        nonlocal hom_computed\n",
    "        hom_computed+=1\n",
    "        base = []\n",
    "        polypers = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, batch in tqdm(enumerate(hom_data)):\n",
    "                # base embeddings after layer\n",
    "                pred_base = model(**{k: v.to(model.device) for k, v in batch[0].items()},\n",
    "                                  output_hidden_states=True)\n",
    "                hid_ref = torch.mean(pred_base.hidden_states[division_layer], dim=1)\n",
    "                base.extend(hid_ref.detach().cpu().numpy())\n",
    "\n",
    "                # polypers embeddings after layer\n",
    "                pred_new = model(**{k: v.to(model.device) for k, v in batch[1].items()},\n",
    "                                  output_hidden_states=True)\n",
    "                hid_cur = torch.mean(pred_new.hidden_states[division_layer], dim=1)\n",
    "                polypers.extend(hid_cur.detach().cpu().numpy())\n",
    "        \n",
    "        save_dict[hom_computed][\"base\"] = base\n",
    "        save_dict[hom_computed][\"polypers\"] = polypers\n",
    "        return save_dict\n",
    "\n",
    "    def gradient_norm():\n",
    "        grads = [\n",
    "        param.grad.detach().flatten()\n",
    "        for param in model.parameters()\n",
    "        if param.grad is not None\n",
    "        ]\n",
    "        norm = torch.cat(grads).norm()\n",
    "        return norm\n",
    "        \n",
    "    #########################################################\n",
    "    # training loop \n",
    "    #########################################################\n",
    "    for epoch in tq_epoch:\n",
    "        tq_batch.reset()\n",
    "        cosine_losses = [cos_loss]\n",
    "        mlm_losses = [mlm_loss]\n",
    "\n",
    "        for i, batch in enumerate(data):\n",
    "            # save data for TDA\n",
    "            if i % test_every == 0:\n",
    "                tda_save_dict = save_tda_features(hom_data, tda_save_dict)\n",
    "                # also a point of optimization\n",
    "                minio.put_object(tda_save_dict, \n",
    "                                 save_name=f\"data/TDA_FEATURES/tda_save_dict_{TRY_NAME}.pkl\", \n",
    "                                 pickle=True)\n",
    "                model.train()\n",
    "            # pred on base text    \n",
    "            pred = model(**{k: v.to(model.device) for k, v in batch[0].items()},\n",
    "                         output_hidden_states=True, )\n",
    "            \n",
    "            # once upon 10 steps, compute mlm loss\n",
    "            if i % n_cosine == 0:\n",
    "                pred.loss.backward(retain_graph=True)\n",
    "                grads = save_gradients(\n",
    "                    model=model, \n",
    "                    division_layer=division_layer\n",
    "                )\n",
    "                mlm_grad_norm = gradient_norm()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                mlm_losses.append(pred.loss.detach().cpu())\n",
    "                # reset cosine weight every cycle\n",
    "                weight_cos.reset()\n",
    "                # take lr_step also every cycle\n",
    "                lr_scheduler.step()\n",
    "            \n",
    "            # compute cosine anyway\n",
    "            # pred on polypers text\n",
    "            pred_new = model(**{k: v.to(model.device) for k, v in batch[1].items()},\n",
    "                             output_hidden_states=True)\n",
    "            \n",
    "            hid_ref = pred.hidden_states[division_layer]\n",
    "            hid_cur = pred_new.hidden_states[division_layer]\n",
    "            \n",
    "            # look for changed ids only\n",
    "            if MEAN_OVER_CHANGED:\n",
    "                mask = (batch[0][\"input_ids\"] - batch[1][\"input_ids\"]) != 0\n",
    "                mask = mask.unsqueeze(-1).expand(-1, -1, 768) \n",
    "                # masked tensors don't support loss calculations as filling with 0 stops differentiation\n",
    "                # hid_ref = masked_tensor(hid_ref, mask.to(model.device), requires_grad=True).to_tensor(value=0)\n",
    "                # hid_cur = masked_tensor(hid_cur, mask.to(model.device), requires_grad=True).to_tensor(value=0)\n",
    "                hid_ref = hid_ref*mask.to(model.device)\n",
    "                hid_cur = hid_cur*mask.to(model.device)\n",
    "\n",
    "            \n",
    "            hid_ref = torch.mean(hid_ref, dim=1)\n",
    "            hid_cur = torch.mean(hid_cur, dim=1)\n",
    "\n",
    "            cos_loss = criteria(hid_ref, hid_cur, target)\n",
    "            cos_loss.backward()\n",
    "            cos_grad_norm = gradient_norm()\n",
    "            \n",
    "            # as indexing in weight_cos starts from -1, take a step before applying            \n",
    "            weight_cos.step()\n",
    "\n",
    "            # new_grads = {}\n",
    "            # for name, parameter in model.named_parameters():\n",
    "            #     if name in grads:\n",
    "            #         new_grads[name] = parameter.grad.clone()\n",
    "\n",
    "            change_gradients(model=model, \n",
    "                             layers=grads, \n",
    "                             division_layer=division_layer,\n",
    "                             weight_mlm=weight_mlm, \n",
    "                             weight_cos=weight_cos)\n",
    "            \n",
    "            # with open(\"grad_log\", \"a\") as f:\n",
    "            #     for name, parameter in model.named_parameters():\n",
    "            #         if name in new_grads:\n",
    "            #             f.writelines(f\"{name} - {(new_grads[name] - parameter.grad).norm()}\")\n",
    "                \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()                    \n",
    "\n",
    "            cosine_losses.append(cos_loss.detach().cpu())\n",
    "\n",
    "            cos_loss = (sum(cosine_losses[-30:]) / len(cosine_losses[-30:])).item()\n",
    "            mlm_loss = (sum(mlm_losses[-30:]) / len(mlm_losses[-30:])).item()\n",
    "\n",
    "            # TODO: possibly send not every batch -- however, it acts asynchrously, so doesn't seem to make much difference\n",
    "            wandb.log({\"MLM loss\": mlm_loss,\n",
    "                       \"Cosine loss\": cos_loss,\n",
    "                       \"MLM grad norm\": mlm_grad_norm,\n",
    "                       \"Cos grad norm\": cos_grad_norm,\n",
    "                       \"Cos_Weight\": weight_cos.weight,\n",
    "                       \"learning_rate\": lr_scheduler.get_last_lr()[0]\n",
    "                      })\n",
    "            tq_batch.set_postfix({\n",
    "                    'MLM loss': mlm_loss,\n",
    "                    'Cosine loss': cos_loss\n",
    "                })\n",
    "\n",
    "            tq_batch.update(1)\n",
    "\n",
    "        if epoch % save_every_epoch == 0:\n",
    "            # Note -- we don't save the model class, only the weights\n",
    "            print(\"Saving model checkpoint...\")\n",
    "            buffer = io.BytesIO()\n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'mlm_loss': pred.loss,\n",
    "                    'cos_loss': cos_loss\n",
    "                            }, f=buffer)\n",
    "            # TODO -- add custom hash to model instead of value\n",
    "            minio.put_object(buffer.getvalue(), \n",
    "                             save_name=f\"ckpt/{TRY_NAME}/model_epoch_{epoch}.pt\")\n",
    "    \n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "SPNBA0emMpWr"
   },
   "outputs": [],
   "source": [
    "dt = PairsDataset(tokenizer, path=DATA_PATH)\n",
    "dl = DataLoader(dt, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                collate_fn=collate_func, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "SPNBA0emMpWr"
   },
   "outputs": [],
   "source": [
    "dt_tda = PairsDataset(tokenizer, path=TEST_PATH)\n",
    "dl_tda = DataLoader(dt_tda, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                collate_fn=collate_func, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "3I3B8JUjnBOs"
   },
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights from the last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = minio.get_object(WEIGHTS_PATH, type=\"model\")\n",
    "model_dict = torch.load(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Compute SVD on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from SVDmatrix import GetSVD\n",
    "\n",
    "# get_svd = GetSVD(model=model, dataloader=dl, division_layer=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_svd.get_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(get_svd.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_svd.compute_svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.put_object(get_svd.matrix, save_name=\"3rd_layer_diff_matrix.pkl\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = minio.get_object(\"3rd_layer_diff_matrix.pkl\", unpickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.put_object(get_svd.svd, save_name=\"3rd_layer_diff_svd.pkl\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different solution (when library internal tobytes interface is implemented --\n",
    "# this variant is prefered)\n",
    "\n",
    "# minio.put_object(get_svd.svd[0].tobytes(), save_name=\"svd_test\", pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "CAq3W2Qd3c3y"
   },
   "outputs": [],
   "source": [
    "n_mlm = 1\n",
    "n_cosine = 10\n",
    "division_layer = 3\n",
    "weight_mlm = 1\n",
    "MEAN_OVER_CHANGED = True\n",
    "\n",
    "# scale by number of steps in a cycle\n",
    "weight_mlm /= n_cosine\n",
    "\n",
    "weight_cos = CosWeightSum2One(init_coef=1)\n",
    "#weight_cos = CosWeightSum2One(init_coef=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "vncR8UNMvk4C"
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = name.startswith(f\"bert.encoder.layer.{division_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "mSRwfobbRsQY"
   },
   "outputs": [],
   "source": [
    "# vec = torch.normal(0.5,\n",
    "#                    0.1,\n",
    "#                    size=(768, ),\n",
    "#                    requires_grad=False).repeat(BATCH_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "O48t9N1K8XCF"
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=5e-4)\n",
    "# criterion = CosLoss(alpha=0.5, vec=vec)\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "\n",
    "num_epochs = 7\n",
    "num_training_steps = num_epochs * len(dl)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"cosine\", optimizer=optimizer, num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SWA addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchcontrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWA_optim = torchcontrib.optim.SWA(optimizer, \n",
    "#                                    swa_start = , \n",
    "#                                    swa_freq = , \n",
    "#                                    swa_lr=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396,
     "referenced_widgets": [
      "001cfa81c7354e93be3df3a5cf1b1058",
      "1957ad156733493da7a1d98af4e41f75",
      "b09cac7f786d41508fc087bfdc5967b7",
      "3adea4ff86b3452ea61fa306820297e6",
      "644be7a3004544af89d53d40dfad2f2b",
      "ab1566b360054b28942a3037cf3b746a",
      "36d21aa4eb7245f7918062cea3ea7a1b",
      "99f7527310794081b4b6adf4b6f3d4eb",
      "02c75806a08d4fd48c35b5a1dcdea1fb",
      "4064efa851f842cdb64b85b7498e2072",
      "9cd5f89775324214b3bcf755a575bf56",
      "7145096b67ab4dc69573e9047570c587",
      "e465332bfe814a2485071916e79d6ec0",
      "f468a1aab83f440a9a49912cb2cf901e",
      "cf17fde9c27f40a4b4e8ee7a83918f96",
      "e60d7f63aedf4b52982c846515cbc703",
      "991f151a7fe041e39275a97cdc1d2838",
      "edf64befa1a3437f82ca7886bb27b9af",
      "4c82641162ed4e569484ba69cbc255c6",
      "e1441e83a1f84e448f7a4b19dc1e6527",
      "99f562bfbd5c4f25a847a01add5d776a",
      "f76d3bb75a774ce9a538561618ca09cf"
     ]
    },
    "id": "F762mn4J1t5F",
    "outputId": "51fddd23-30ec-446f-fcde-ae5f7db8f13e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a0b31d3f4c4d2b9ae9692b23d6dae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a756e2bf9b4fb39c554f16973ef328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04154e20fa494c919dbf0b93ce18b045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModularLM/data/TDA_FEATURES/tda_save_dict_naive_cosine_with_pretrained_bert_lower_lr.pkl: |####################| 1.42 MB/1.42 MB 100% [elapsed: 00:00 left: 00:00, 3354.94 MB/sec]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved layers: dict_keys(['bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias'])\n",
      "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.self.query.weight\n",
      "INFO:__main__:gradients changed. (tensor(0.0242, device='cuda:0'), tensor(0.0675, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.self.query.bias\n",
      "INFO:__main__:gradients changed. (tensor(0.0011, device='cuda:0'), tensor(0.0030, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.self.key.weight\n",
      "INFO:__main__:gradients changed. (tensor(0.0239, device='cuda:0'), tensor(0.0660, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.self.key.bias\n",
      "INFO:__main__:gradients changed. (tensor(2.1112e-10, device='cuda:0'), tensor(5.9007e-10, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.self.value.weight\n",
      "INFO:__main__:gradients changed. (tensor(0.0793, device='cuda:0'), tensor(0.2084, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.self.value.bias\n",
      "INFO:__main__:gradients changed. (tensor(0.0065, device='cuda:0'), tensor(0.0168, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.output.dense.weight\n",
      "INFO:__main__:gradients changed. (tensor(0.0348, device='cuda:0'), tensor(0.0981, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.output.dense.bias\n",
      "INFO:__main__:gradients changed. (tensor(0.0075, device='cuda:0'), tensor(0.0207, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "INFO:__main__:gradients changed. (tensor(0.0074, device='cuda:0'), tensor(0.0148, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "INFO:__main__:gradients changed. (tensor(0.0063, device='cuda:0'), tensor(0.0175, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.intermediate.dense.weight\n",
      "INFO:__main__:gradients changed. (tensor(0.0880, device='cuda:0'), tensor(0.2483, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.intermediate.dense.bias\n",
      "INFO:__main__:gradients changed. (tensor(0.0025, device='cuda:0'), tensor(0.0069, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.output.dense.weight\n",
      "INFO:__main__:gradients changed. (tensor(0.0476, device='cuda:0'), tensor(0.1344, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.output.dense.bias\n",
      "INFO:__main__:gradients changed. (tensor(0.0056, device='cuda:0'), tensor(0.0159, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "INFO:__main__:gradients changed. (tensor(0.0192, device='cuda:0'), tensor(0.0391, device='cuda:0'))\n",
      "\n",
      "INFO:__main__:Changed layer: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "INFO:__main__:gradients changed. (tensor(0.0092, device='cuda:0'), tensor(0.0261, device='cuda:0'))\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896326d308cc4f6c85961bdfada19d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModularLM/data/TDA_FEATURES/tda_save_dict_naive_cosine_with_pretrained_bert_lower_lr.pkl: |####################| 2.84 MB/2.84 MB 100% [elapsed: 00:00 left: 00:00, 4574.19 MB/sec]"
     ]
    }
   ],
   "source": [
    "tda_save_dict = defaultdict(dict)\n",
    "\n",
    "train(model=model, criteria=criterion, optimizer=optimizer,\n",
    "      lr_scheduler=lr_scheduler, data=dl, hom_data=dl_tda,\n",
    "      n_epochs=num_epochs,\n",
    "      n_cosine=n_cosine, division_layer=division_layer+1,\n",
    "      weight_mlm=weight_mlm, weight_cos=weight_cos,\n",
    "      save_every_epoch=3, test_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001cfa81c7354e93be3df3a5cf1b1058": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1957ad156733493da7a1d98af4e41f75",
       "IPY_MODEL_b09cac7f786d41508fc087bfdc5967b7",
       "IPY_MODEL_3adea4ff86b3452ea61fa306820297e6"
      ],
      "layout": "IPY_MODEL_644be7a3004544af89d53d40dfad2f2b"
     }
    },
    "02c75806a08d4fd48c35b5a1dcdea1fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1957ad156733493da7a1d98af4e41f75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab1566b360054b28942a3037cf3b746a",
      "placeholder": "",
      "style": "IPY_MODEL_36d21aa4eb7245f7918062cea3ea7a1b",
      "value": "Epochs:0%"
     }
    },
    "36d21aa4eb7245f7918062cea3ea7a1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3adea4ff86b3452ea61fa306820297e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4064efa851f842cdb64b85b7498e2072",
      "placeholder": "",
      "style": "IPY_MODEL_9cd5f89775324214b3bcf755a575bf56",
      "value": "0/1[00:56&lt;?,?it/s]"
     }
    },
    "4064efa851f842cdb64b85b7498e2072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c82641162ed4e569484ba69cbc255c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "644be7a3004544af89d53d40dfad2f2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7145096b67ab4dc69573e9047570c587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e465332bfe814a2485071916e79d6ec0",
       "IPY_MODEL_f468a1aab83f440a9a49912cb2cf901e",
       "IPY_MODEL_cf17fde9c27f40a4b4e8ee7a83918f96"
      ],
      "layout": "IPY_MODEL_e60d7f63aedf4b52982c846515cbc703"
     }
    },
    "991f151a7fe041e39275a97cdc1d2838": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99f562bfbd5c4f25a847a01add5d776a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99f7527310794081b4b6adf4b6f3d4eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cd5f89775324214b3bcf755a575bf56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab1566b360054b28942a3037cf3b746a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b09cac7f786d41508fc087bfdc5967b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99f7527310794081b4b6adf4b6f3d4eb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02c75806a08d4fd48c35b5a1dcdea1fb",
      "value": 0
     }
    },
    "cf17fde9c27f40a4b4e8ee7a83918f96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99f562bfbd5c4f25a847a01add5d776a",
      "placeholder": "",
      "style": "IPY_MODEL_f76d3bb75a774ce9a538561618ca09cf",
      "value": "166/37379[00:55&lt;2:56:01,3.52it/s,Cosineloss=1.46]"
     }
    },
    "e1441e83a1f84e448f7a4b19dc1e6527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e465332bfe814a2485071916e79d6ec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_991f151a7fe041e39275a97cdc1d2838",
      "placeholder": "",
      "style": "IPY_MODEL_edf64befa1a3437f82ca7886bb27b9af",
      "value": "0%"
     }
    },
    "e60d7f63aedf4b52982c846515cbc703": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edf64befa1a3437f82ca7886bb27b9af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f468a1aab83f440a9a49912cb2cf901e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c82641162ed4e569484ba69cbc255c6",
      "max": 37379,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1441e83a1f84e448f7a4b19dc1e6527",
      "value": 166
     }
    },
    "f76d3bb75a774ce9a538561618ca09cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
