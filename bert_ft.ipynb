{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkRjTgTvHt0C"
   },
   "source": [
    "# Bert Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jESjuwfQHw8c"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SSzfVu-SnBOl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install transformers[torch] datasets evaluate wandb minio tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K8_hHVCNnBOq"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pickle as pkl\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    BertForMaskedLM,\n",
    "    get_scheduler,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "# from maskedtensor import masked_tensor\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import io\n",
    "from PairsDataset import PairsDataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import logging\n",
    "import ema_swa_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRY_NAME = \"naive_cosine_with_pretrained_bert_with_ema_0.999\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KTpeEhBwIBdl"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 16\n",
    "MLM_PROB = 0.15\n",
    "\n",
    "#DATA_PATH = '/content/drive/MyDrive/nnlp/bert/biblioteka_prikluchenij_both_agr.csv'\n",
    "DATA_PATH = \"data/train_dataset.csv\"\n",
    "TEST_PATH = \"data/tda_test.csv\"\n",
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased'\n",
    "WEIGHTS_PATH = \"ckpt/pretrained_bert_epoch_9.999976796259556.pt\"\n",
    "\n",
    "USE_SWA = False\n",
    "\n",
    "USE_EMA = True\n",
    "EMA_DECAY = 0.999\n",
    "\n",
    "# whether to log the layers being changed (happens once per notebook restart)\n",
    "LOG_LAYERS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zi_u2NiL0mgC",
    "outputId": "cbeb7da4-03ef-40c1-a015-90ec071ab357"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "learning_rate = 5e-4\n",
    "\n",
    "n_mlm = 1\n",
    "n_cosine = 10\n",
    "division_layer = 3\n",
    "weight_mlm = 1\n",
    "MEAN_OVER_CHANGED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DESCRIPTION = \\\n",
    "f'''\n",
    "Model: based on rubert, additionally pretrained for 10 epochs;\n",
    "Checkpoint: {WEIGHTS_PATH};\n",
    "Context: {SEQ_LEN};\n",
    "Batch size: {BATCH_SIZE};\n",
    "\n",
    "Loss: classic cosine embedding with steps along the MLM gradient;\n",
    "Loss only over diff in tokenization: {MEAN_OVER_CHANGED};\n",
    "N_MLM: {n_mlm};\n",
    "N_Cosine: {n_cosine};\n",
    "Division_layer: {division_layer};\n",
    "weight_mlm: {weight_mlm};\n",
    "weight_cosine: polynomial decay, sum to 1;\n",
    "\n",
    "LR_SCHEDULER: MultiStep;\n",
    "Initial learning rate: {learning_rate};\n",
    "Steps: 5, \n",
    "Decay: 0.5,\n",
    "Epochs: {num_epochs};\n",
    "\n",
    "Additional parameters and notes:\n",
    "EMA: {USE_EMA};\n",
    "EMA_DECAY: {EMA_DECAY};\n",
    "\n",
    "SWA: {USE_SWA};\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=f\"logs/{TRY_NAME}_grad_log\", filemode=\"w\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio handler to use remote data -- implements get and put methods with pickling option (view file)\n",
    "\n",
    "from MinioHandler import MinioHandler\n",
    "\n",
    "minio = MinioHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMZUfmdLEBnR",
    "outputId": "75c4dd46-dd6c-4f31-ad83-74a0a565b17c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZ1tRDh5RvDP",
    "outputId": "93a64300-36f2-4450-dded-ede6b6454b44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxenomirant\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "_XaOQ4gtSauA",
    "outputId": "94169790-8c91-4460-aaf1-56ab846703ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxenomirant\u001b[0m (\u001b[33mgrammar-bert\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/local/ModularLM/wandb/run-20240408_073358-p54ddw8k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grammar-bert/grammar-bert-model1/runs/p54ddw8k' target=\"_blank\">serene-moon-148</a></strong> to <a href='https://wandb.ai/grammar-bert/grammar-bert-model1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grammar-bert/grammar-bert-model1' target=\"_blank\">https://wandb.ai/grammar-bert/grammar-bert-model1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grammar-bert/grammar-bert-model1/runs/p54ddw8k' target=\"_blank\">https://wandb.ai/grammar-bert/grammar-bert-model1/runs/p54ddw8k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/grammar-bert/grammar-bert-model1/runs/p54ddw8k?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x77faffcb3a00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='grammar-bert-model1',\n",
    "    entity='grammar-bert'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zdbf_sj8Hy_9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TQrOptuKvk4A"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(DATA_PATH, index_col = 0)\n",
    "# df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df.was_changed].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GB-e4FABxy8y"
   },
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "\n",
    "# idx_init = df.initial.progress_apply(lambda x: x.replace(' ', ''))\n",
    "# idx_pol = df.polypers.progress_apply(lambda x: x.replace(' ', ''))\n",
    "# idx = -(idx_init == idx_pol)\n",
    "# df['was_changed'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yrQu60MLz9cT"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Train test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TEST_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(DATA_PATH, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = train_test_split(df, test_size=TEST_SIZE, stratify = df[\"was_changed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(\"data/train_bpa.csv\")\n",
    "# test.to_csv(\"data/test_bpa.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pick items from test for TDA and homology computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/test_bpa.csv\", index_col = 0)\n",
    "\n",
    "# df = df[df.was_changed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tda_data = df.sample(n = 250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tda_data.to_csv(\"tda_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.put_object(tda_data, save_name=\"data/tda_test.pkl\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything to minio -- also possible to use default minio functions from Minio class\n",
    "\n",
    "# minio.minio.fput_object(file_path=\"data/test_dataset.csv\", bucket_name=\"public\",\n",
    "#                       object_name=\"ModularLM/data/test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDe7I4QR4gVY"
   },
   "source": [
    "## Dataset and collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "V06Z3lby7xme"
   },
   "outputs": [],
   "source": [
    "def collate_func(batch):\n",
    "    batch = [data_collator.torch_call(item) for item in zip(*batch)]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7JP-0xw72PH",
    "outputId": "2f1ca2ee-6378-4dae-cd1e-3eac9d6235a9"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenizer.pad_token = '[SEP]'\n",
    "tokenizer.eos_token = '[SEP]'\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=MLM_PROB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh94UBHqxuSA",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MLM Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Mb9N8GAh_9Te"
   },
   "outputs": [],
   "source": [
    "# dt = datasets.Dataset.from_csv(DATA_PATH)\n",
    "# dt = dt.remove_columns(['polypers', 'was_changed']).rename_column('initial', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "d84hj1c4IQwT"
   },
   "outputs": [],
   "source": [
    "# N_samples = 10**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "6ZHrIWiQA_rn"
   },
   "outputs": [],
   "source": [
    "# def tokenize_function(example):\n",
    "#     return tokenizer(example['text'], truncation=True)\n",
    "\n",
    "# tok_dt = dt.select(range(N_samples)).map(tokenize_function, batched=True)\n",
    "# tok_dt = tok_dt.train_test_split(test_size=100,\n",
    "#                          shuffle=True,\n",
    "#                          seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "AKDqk2mzBQz-"
   },
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     report_to = 'wandb',\n",
    "#     output_dir='part1-model',\n",
    "#     learning_rate=1e-3,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     num_train_epochs=1,\n",
    "#     # evaluation_strategy='steps',\n",
    "#     # eval_steps=20,\n",
    "#     logging_steps=20,\n",
    "#     logging_first_step=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "F3MYlLtm76uJ"
   },
   "outputs": [],
   "source": [
    "# model = BertForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "# model.to(device)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "LC0KZCwqA50q"
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tok_dt['train'],\n",
    "#     # eval_dataset=tok_dt['test'],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "7vEzJTIREz0k"
   },
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8nu5cYyIxDd"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "4RB10XU9bMbH"
   },
   "outputs": [],
   "source": [
    "def save_gradients(model, division_layer):\n",
    "    layers = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        # division layer passed == division layer + 1 as is inside train\n",
    "        if name.startswith(f'bert.encoder.layer.{division_layer}'):\n",
    "            break\n",
    "        if (param.requires_grad) and param.grad is not None:\n",
    "            layers[name] = param.grad.detach().clone()\n",
    "    if LOG_LAYERS:\n",
    "        logger.info(f\"Saved layers: {str(layers.keys())}\")\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "qHcpG4G8cclV"
   },
   "outputs": [],
   "source": [
    "def change_gradients(*, model, layers, \n",
    "                     division_layer,\n",
    "                     weight_mlm=0.5, \n",
    "                     weight_cos=1, ):\n",
    "\n",
    "    global LOG_LAYERS\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        # division layer passed == division layer + 1 as is inside train\n",
    "        if name.startswith(f'bert.encoder.layer.{division_layer}'):\n",
    "            break\n",
    "        if name in layers:\n",
    "            param.grad = weight_cos * param.grad + weight_mlm * layers[name]\n",
    "            if LOG_LAYERS:\n",
    "                logger.info(f\"Changed layer: {name}\")\n",
    "                logger.info(f\"gradients changed. {(weight_cos * param.grad).norm(), (weight_mlm * layers[name]).norm()}\\n\")\n",
    "    LOG_LAYERS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "H9vdmHBsLAXg"
   },
   "outputs": [],
   "source": [
    "class CosWeightDecay:\n",
    "    '''\n",
    "    Cosine Weight with decaying step sizes after each multiplication\n",
    "    '''\n",
    "    def __init__(self, init_state=1, step=0.5):\n",
    "        self.cur_state = init_state\n",
    "        self.step = step\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        res = self.cur_state * other\n",
    "        self.cur_state = self.cur_state * self.step\n",
    "        return res\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.cur_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "H9vdmHBsLAXg"
   },
   "outputs": [],
   "source": [
    "class CosWeightSum2One:\n",
    "    '''\n",
    "    Cosine Weight summing to 1 over 10 steps (must be subject to change in case other step size is required)\n",
    "    This looks quite dumb...\n",
    "    '''\n",
    "    def __init__(self, init_coef = 100, steps: int = 10, linear = False):\n",
    "        self.counter = -1\n",
    "        if linear:\n",
    "            self.steps = init_coef*np.ones(steps)\n",
    "            return None\n",
    "        self.steps = init_coef*np.arange(2, steps+2)**-1.5\n",
    "        return None\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        res = self.steps[self.counter] * other\n",
    "        return res\n",
    "    \n",
    "    def step(self):\n",
    "        self.counter+=1\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.steps[self.counter])\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = -1\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.steps[self.counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "RsNP-PPvQayL"
   },
   "outputs": [],
   "source": [
    "class CosLoss:\n",
    "    def __init__(self, vector=None, alpha=0):\n",
    "        self.loss = nn.CosineEmbeddingLoss()\n",
    "        self.target = torch.ones(BATCH_SIZE).to(model.device)\n",
    "        self.alpha = alpha\n",
    "        self.vector = vector\n",
    "\n",
    "    def __call__(self, hid_ref, hid_cur, target):\n",
    "        cos_loss = self.loss(hid_ref, hid_cur, target)\n",
    "        if self.vector is not None:\n",
    "            cos_loss += self.alpha * self.loss(self.vector, hid_ref - hid_cur,\n",
    "                                               self.target)\n",
    "        return cos_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "74aJSuBCtRcI"
   },
   "outputs": [],
   "source": [
    "def train(model, criteria, optimizer, lr_scheduler, data, hom_data, n_epochs=1,\n",
    "          n_cosine=10, division_layer=4, weight_mlm=1,\n",
    "          weight_cos=1, save_every_epoch=3, test_every=5000):\n",
    "\n",
    "    # global mlm_losses, cosine_losses\n",
    "    # change global loss tracking to local only -- for now it seems unnecessary\n",
    "    global tda_save_dict\n",
    "\n",
    "    tq_epoch = trange(n_epochs, desc='Epochs: ')\n",
    "    tq_batch = tqdm(total=len(data))\n",
    "\n",
    "    # target for cosine loss\n",
    "    target = -torch.ones(BATCH_SIZE).to(model.device)\n",
    "    grads = None\n",
    "    \n",
    "    # just initialization -- first few batches make no difference for tracking\n",
    "    cos_loss = 0\n",
    "    mlm_loss = 0\n",
    "    hom_computed = 0\n",
    "    # TODO -- optimize for gradual saving of dict intead of accumulation\n",
    "\n",
    "\n",
    "    # save necessary features to dict\n",
    "    def save_tda_features(hom_data: torch.utils.data.DataLoader, save_dict: dict):\n",
    "\n",
    "        nonlocal hom_computed\n",
    "        hom_computed+=1\n",
    "        base = []\n",
    "        polypers = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, batch in tqdm(enumerate(hom_data)):\n",
    "                # base embeddings after layer\n",
    "                pred_base = model(**{k: v.to(model.device) for k, v in batch[0].items()},\n",
    "                                  output_hidden_states=True)\n",
    "                hid_ref = torch.mean(pred_base.hidden_states[division_layer], dim=1)\n",
    "                base.extend(hid_ref.detach().cpu().numpy())\n",
    "\n",
    "                # polypers embeddings after layer\n",
    "                pred_new = model(**{k: v.to(model.device) for k, v in batch[1].items()},\n",
    "                                  output_hidden_states=True)\n",
    "                hid_cur = torch.mean(pred_new.hidden_states[division_layer], dim=1)\n",
    "                polypers.extend(hid_cur.detach().cpu().numpy())\n",
    "        \n",
    "        save_dict[hom_computed][\"base\"] = base\n",
    "        save_dict[hom_computed][\"polypers\"] = polypers\n",
    "        return save_dict\n",
    "\n",
    "    def gradient_norm():\n",
    "        grads = [\n",
    "        param.grad.detach().flatten()\n",
    "        for param in model.parameters()\n",
    "        if param.grad is not None\n",
    "        ]\n",
    "        norm = torch.cat(grads).norm()\n",
    "        return norm\n",
    "        \n",
    "    #########################################################\n",
    "    # training loop \n",
    "    #########################################################\n",
    "    for epoch in tq_epoch:\n",
    "        tq_batch.reset()\n",
    "        cosine_losses = [cos_loss]\n",
    "        mlm_losses = [mlm_loss]\n",
    "\n",
    "        for i, batch in enumerate(data):\n",
    "            # save data for TDA\n",
    "            if i % test_every == 0:\n",
    "                tda_save_dict = save_tda_features(hom_data, tda_save_dict)\n",
    "                # also a point of optimization\n",
    "                minio.put_object(tda_save_dict, \n",
    "                                 save_name=f\"data/TDA_FEATURES/tda_save_dict_{TRY_NAME}.pkl\", \n",
    "                                 pickle=True)\n",
    "                model.train()\n",
    "            # pred on base text    \n",
    "            pred = model(**{k: v.to(model.device) for k, v in batch[0].items()},\n",
    "                         output_hidden_states=True, )\n",
    "            \n",
    "            # once upon 10 steps, compute mlm loss\n",
    "            if i % n_cosine == 0:\n",
    "                pred.loss.backward(retain_graph=True)\n",
    "                grads = save_gradients(\n",
    "                    model=model, \n",
    "                    division_layer=division_layer\n",
    "                )\n",
    "                mlm_grad_norm = gradient_norm()\n",
    "\n",
    "                if (USE_EMA | USE_SWA):\n",
    "                    avg_model.update_parameters(model)                    \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                mlm_losses.append(pred.loss.detach().cpu())\n",
    "                # reset cosine weight every cycle\n",
    "                weight_cos.reset()\n",
    "                # take lr_step also every cycle\n",
    "                lr_scheduler.step()\n",
    "            \n",
    "            # compute cosine anyway\n",
    "            # pred on polypers text\n",
    "            pred_new = model(**{k: v.to(model.device) for k, v in batch[1].items()},\n",
    "                             output_hidden_states=True)\n",
    "            \n",
    "            hid_ref = pred.hidden_states[division_layer]\n",
    "            hid_cur = pred_new.hidden_states[division_layer]\n",
    "            \n",
    "            # look for changed ids only\n",
    "            if MEAN_OVER_CHANGED:\n",
    "                mask = (batch[0][\"input_ids\"] - batch[1][\"input_ids\"]) != 0\n",
    "                mask = mask.unsqueeze(-1).expand(-1, -1, 768) \n",
    "                # masked tensors don't support loss calculations as filling with 0 stops differentiation\n",
    "                # hid_ref = masked_tensor(hid_ref, mask.to(model.device), requires_grad=True).to_tensor(value=0)\n",
    "                # hid_cur = masked_tensor(hid_cur, mask.to(model.device), requires_grad=True).to_tensor(value=0)\n",
    "                hid_ref = hid_ref*mask.to(model.device)\n",
    "                hid_cur = hid_cur*mask.to(model.device)\n",
    "\n",
    "            \n",
    "            hid_ref = torch.mean(hid_ref, dim=1)\n",
    "            hid_cur = torch.mean(hid_cur, dim=1)\n",
    "\n",
    "            cos_loss = criteria(hid_ref, hid_cur, target)\n",
    "            cos_loss.backward()\n",
    "            cos_grad_norm = gradient_norm()\n",
    "            \n",
    "            # as indexing in weight_cos starts from -1, take a step before applying            \n",
    "            weight_cos.step()\n",
    "\n",
    "            # new_grads = {}\n",
    "            # for name, parameter in model.named_parameters():\n",
    "            #     if name in grads:\n",
    "            #         new_grads[name] = parameter.grad.clone()\n",
    "\n",
    "            change_gradients(model=model, \n",
    "                             layers=grads, \n",
    "                             division_layer=division_layer,\n",
    "                             weight_mlm=weight_mlm, \n",
    "                             weight_cos=weight_cos)\n",
    "            \n",
    "            # with open(\"grad_log\", \"a\") as f:\n",
    "            #     for name, parameter in model.named_parameters():\n",
    "            #         if name in new_grads:\n",
    "            #             f.writelines(f\"{name} - {(new_grads[name] - parameter.grad).norm()}\")\n",
    "                \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()                    \n",
    "\n",
    "            cosine_losses.append(cos_loss.detach().cpu())\n",
    "\n",
    "            cos_loss = (sum(cosine_losses[-30:]) / len(cosine_losses[-30:])).item()\n",
    "            mlm_loss = (sum(mlm_losses[-30:]) / len(mlm_losses[-30:])).item()\n",
    "\n",
    "            # TODO: possibly send not every batch -- however, it acts asynchrously, so doesn't seem to make much difference\n",
    "            wandb.log({\"MLM loss\": mlm_loss,\n",
    "                       \"Cosine loss\": cos_loss,\n",
    "                       \"MLM grad norm\": mlm_grad_norm,\n",
    "                       \"Cos grad norm\": cos_grad_norm,\n",
    "                       \"Cos_Weight\": weight_cos.weight,\n",
    "                       \"learning_rate\": lr_scheduler.get_last_lr()[0]\n",
    "                      })\n",
    "            tq_batch.set_postfix({\n",
    "                    'MLM loss': mlm_loss,\n",
    "                    'Cosine loss': cos_loss\n",
    "                })\n",
    "\n",
    "            tq_batch.update(1)\n",
    "\n",
    "        if epoch % save_every_epoch == 0:\n",
    "            # Note -- we don't save the model class, only the weights\n",
    "            print(\"Saving model checkpoint...\")\n",
    "            buffer = io.BytesIO()\n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'mlm_loss': pred.loss,\n",
    "                    'cos_loss': cos_loss\n",
    "                            }, f=buffer)\n",
    "            # TODO -- add custom hash to model instead of value\n",
    "            minio.put_object(buffer.getvalue(), \n",
    "                             save_name=f\"ckpt/{TRY_NAME}/model_epoch_{epoch}.pt\")\n",
    "    \n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "SPNBA0emMpWr"
   },
   "outputs": [],
   "source": [
    "dt = PairsDataset(tokenizer, path=DATA_PATH)\n",
    "dl = DataLoader(dt, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                collate_fn=collate_func, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "SPNBA0emMpWr"
   },
   "outputs": [],
   "source": [
    "dt_tda = PairsDataset(tokenizer, path=TEST_PATH)\n",
    "dl_tda = DataLoader(dt_tda, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                collate_fn=collate_func, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3I3B8JUjnBOs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights from the last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = minio.get_object(WEIGHTS_PATH, type=\"model\")\n",
    "model_dict = torch.load(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_dict[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Compute SVD on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from SVDmatrix import GetSVD\n",
    "\n",
    "# get_svd = GetSVD(model=model, dataloader=dl, division_layer=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_svd.get_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(get_svd.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_svd.compute_svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.put_object(get_svd.matrix, save_name=\"3rd_layer_diff_matrix.pkl\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = minio.get_object(\"3rd_layer_diff_matrix.pkl\", unpickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.put_object(get_svd.svd, save_name=\"3rd_layer_diff_svd.pkl\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different solution (when library internal tobytes interface is implemented --\n",
    "# this variant is prefered)\n",
    "\n",
    "# minio.put_object(get_svd.svd[0].tobytes(), save_name=\"svd_test\", pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "CAq3W2Qd3c3y"
   },
   "outputs": [],
   "source": [
    "# scale by number of steps in a cycle\n",
    "weight_mlm /= n_cosine\n",
    "\n",
    "weight_cos = CosWeightSum2One(init_coef=1)\n",
    "#weight_cos = CosWeightSum2One(init_coef=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "vncR8UNMvk4C"
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = name.startswith(f\"bert.encoder.layer.{division_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "mSRwfobbRsQY"
   },
   "outputs": [],
   "source": [
    "# vec = torch.normal(0.5,\n",
    "#                    0.1,\n",
    "#                    size=(768, ),\n",
    "#                    requires_grad=False).repeat(BATCH_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "O48t9N1K8XCF"
   },
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), lr=learning_rate)\n",
    "# criterion = CosLoss(alpha=0.5, vec=vec)\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "\n",
    "num_training_steps = int(num_epochs * len(dl) / n_cosine * n_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50460"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of lr sheduler updates\n",
    "num_training_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate & averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (USE_SWA):\n",
    "    \n",
    "    # lr_scheduler = get_scheduler(\n",
    "    #                 name=\"cosine\", optimizer=optimizer, num_warmup_steps=0,\n",
    "    #                 num_training_steps=num_training_steps\n",
    "    #                 )\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                        milestones=[len(dl)*i for i in range(1, num_epochs)][:5],\n",
    "                                                        gamma=0.5,)\n",
    "    \n",
    "    # # Note: Averaged model is applicable to custom modules -- not only full models, \n",
    "    # so it can be used for module training as well\n",
    "    if USE_EMA:\n",
    "        avg_model = ema_swa_utils.AveragedModel(model,  \n",
    "                                                multi_avg_fn=ema_swa_utils.get_ema_multi_avg_fn(decay=EMA_DECAY)).to(device)\n",
    "elif USE_SWA:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: based on rubert, additionally pretrained for 10 epochs;\n",
      "Checkpoint: ckpt/pretrained_bert_epoch_9.999976796259556.pt;\n",
      "Context: 64;\n",
      "Batch size: 16;\n",
      "\n",
      "Loss: classic cosine embedding with steps along the MLM gradient;\n",
      "Loss only over diff in tokenization: True;\n",
      "N_MLM: 1;\n",
      "N_Cosine: 10;\n",
      "Division_layer: 3;\n",
      "weight_mlm: 1;\n",
      "weight_cosine: polynomial decay, sum to 1;\n",
      "\n",
      "LR_SCHEDULER: MultiStep;\n",
      "Initial learning rate: 0.0005;\n",
      "Steps: 5, \n",
      "Decay: 0.5,\n",
      "Epochs: 15;\n",
      "\n",
      "Additional parameters and notes:\n",
      "EMA: True;\n",
      "EMA_DECAY: 0.999;\n",
      "\n",
      "SWA: False;\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396,
     "referenced_widgets": [
      "001cfa81c7354e93be3df3a5cf1b1058",
      "1957ad156733493da7a1d98af4e41f75",
      "b09cac7f786d41508fc087bfdc5967b7",
      "3adea4ff86b3452ea61fa306820297e6",
      "644be7a3004544af89d53d40dfad2f2b",
      "ab1566b360054b28942a3037cf3b746a",
      "36d21aa4eb7245f7918062cea3ea7a1b",
      "99f7527310794081b4b6adf4b6f3d4eb",
      "02c75806a08d4fd48c35b5a1dcdea1fb",
      "4064efa851f842cdb64b85b7498e2072",
      "9cd5f89775324214b3bcf755a575bf56",
      "7145096b67ab4dc69573e9047570c587",
      "e465332bfe814a2485071916e79d6ec0",
      "f468a1aab83f440a9a49912cb2cf901e",
      "cf17fde9c27f40a4b4e8ee7a83918f96",
      "e60d7f63aedf4b52982c846515cbc703",
      "991f151a7fe041e39275a97cdc1d2838",
      "edf64befa1a3437f82ca7886bb27b9af",
      "4c82641162ed4e569484ba69cbc255c6",
      "e1441e83a1f84e448f7a4b19dc1e6527",
      "99f562bfbd5c4f25a847a01add5d776a",
      "f76d3bb75a774ce9a538561618ca09cf"
     ]
    },
    "id": "F762mn4J1t5F",
    "outputId": "51fddd23-30ec-446f-fcde-ae5f7db8f13e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f27d1dc03b47e98574eb0ce6f33f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262b6611b96149c18d6077bccc983f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c157ab1e70c47c68876e6545b6de534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModularLM/data/TDA_FEATURES/tda_save_dict_naive_cosine_with_pretrained_bert_with_ema_0.999.pkl: |####################| 1.42 MB/1.42 MB 100% [elapsed: 00:00 left: 00:00, 4645.71 MB/sec]"
     ]
    }
   ],
   "source": [
    "tda_save_dict = defaultdict(dict)\n",
    "\n",
    "train(model=model, criteria=criterion, optimizer=optimizer,\n",
    "      lr_scheduler=lr_scheduler, data=dl, hom_data=dl_tda,\n",
    "      n_epochs=num_epochs,\n",
    "      n_cosine=n_cosine, division_layer=division_layer+1,\n",
    "      weight_mlm=weight_mlm, weight_cos=weight_cos,\n",
    "      save_every_epoch=3, test_every=5000)\n",
    "\n",
    "if (USE_EMA | USE_SWA):\n",
    "    torch.optim.swa_utils.update_bn(dl, avg_model)\n",
    "\n",
    "logger.info(\"Saving model...\")\n",
    "buffer = io.BytesIO()\n",
    "torch.save({\n",
    "        'model_state_dict': avg_model.state_dict(),\n",
    "                }, f=buffer)\n",
    "\n",
    "minio.put_object(buffer.getvalue(), \n",
    "                 save_name=f\"ckpt/trained_models/{TRY_NAME}/model.pt\")\n",
    "\n",
    "minio.put_object(DESCRIPTION, \n",
    "                save_name=f\"ckpt/trained_models/{TRY_NAME}/DESCRIPTION.txt\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001cfa81c7354e93be3df3a5cf1b1058": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1957ad156733493da7a1d98af4e41f75",
       "IPY_MODEL_b09cac7f786d41508fc087bfdc5967b7",
       "IPY_MODEL_3adea4ff86b3452ea61fa306820297e6"
      ],
      "layout": "IPY_MODEL_644be7a3004544af89d53d40dfad2f2b"
     }
    },
    "02c75806a08d4fd48c35b5a1dcdea1fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1957ad156733493da7a1d98af4e41f75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab1566b360054b28942a3037cf3b746a",
      "placeholder": "​",
      "style": "IPY_MODEL_36d21aa4eb7245f7918062cea3ea7a1b",
      "value": "Epochs:   0%"
     }
    },
    "36d21aa4eb7245f7918062cea3ea7a1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3adea4ff86b3452ea61fa306820297e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4064efa851f842cdb64b85b7498e2072",
      "placeholder": "​",
      "style": "IPY_MODEL_9cd5f89775324214b3bcf755a575bf56",
      "value": " 0/1 [00:56&lt;?, ?it/s]"
     }
    },
    "4064efa851f842cdb64b85b7498e2072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c82641162ed4e569484ba69cbc255c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "644be7a3004544af89d53d40dfad2f2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7145096b67ab4dc69573e9047570c587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e465332bfe814a2485071916e79d6ec0",
       "IPY_MODEL_f468a1aab83f440a9a49912cb2cf901e",
       "IPY_MODEL_cf17fde9c27f40a4b4e8ee7a83918f96"
      ],
      "layout": "IPY_MODEL_e60d7f63aedf4b52982c846515cbc703"
     }
    },
    "991f151a7fe041e39275a97cdc1d2838": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99f562bfbd5c4f25a847a01add5d776a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99f7527310794081b4b6adf4b6f3d4eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cd5f89775324214b3bcf755a575bf56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab1566b360054b28942a3037cf3b746a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b09cac7f786d41508fc087bfdc5967b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99f7527310794081b4b6adf4b6f3d4eb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02c75806a08d4fd48c35b5a1dcdea1fb",
      "value": 0
     }
    },
    "cf17fde9c27f40a4b4e8ee7a83918f96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99f562bfbd5c4f25a847a01add5d776a",
      "placeholder": "​",
      "style": "IPY_MODEL_f76d3bb75a774ce9a538561618ca09cf",
      "value": " 166/37379 [00:55&lt;2:56:01,  3.52it/s, Cosine loss=1.46]"
     }
    },
    "e1441e83a1f84e448f7a4b19dc1e6527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e465332bfe814a2485071916e79d6ec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_991f151a7fe041e39275a97cdc1d2838",
      "placeholder": "​",
      "style": "IPY_MODEL_edf64befa1a3437f82ca7886bb27b9af",
      "value": "  0%"
     }
    },
    "e60d7f63aedf4b52982c846515cbc703": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edf64befa1a3437f82ca7886bb27b9af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f468a1aab83f440a9a49912cb2cf901e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c82641162ed4e569484ba69cbc255c6",
      "max": 37379,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1441e83a1f84e448f7a4b19dc1e6527",
      "value": 166
     }
    },
    "f76d3bb75a774ce9a538561618ca09cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
