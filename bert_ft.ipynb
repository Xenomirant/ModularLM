{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkRjTgTvHt0C"
   },
   "source": [
    "# Bert Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jESjuwfQHw8c"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SSzfVu-SnBOl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install transformers[torch] datasets evaluate wandb minio tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gudhi ripser giotto-tda scikit-tda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "K8_hHVCNnBOq"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorForWholeWordMask,\n",
    "    DefaultDataCollator,\n",
    "    default_data_collator,\n",
    "    BertForMaskedLM,\n",
    "    get_scheduler,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import transformers\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam, SGD\n",
    "import torch_optimizer as optim\n",
    "# from maskedtensor import masked_tensor\n",
    "\n",
    "from tqdm.auto import trange, tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import io\n",
    "import pathlib\n",
    "from PairsDataset import PairsDataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "import logging\n",
    "import ema_swa_utils\n",
    "import tda_utils\n",
    "from tda_utils import Stats\n",
    "import SVDmatrix\n",
    "from collections import deque\n",
    "\n",
    "import multiprocessing as mp\n",
    "mp.set_start_method('spawn')\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRY_NAME = \"plain_mlm_test_all_layers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KTpeEhBwIBdl"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 16\n",
    "MLM_PROB = 0.15\n",
    "\n",
    "#DATA_PATH = '/content/drive/MyDrive/nnlp/bert/biblioteka_prikluchenij_both_agr.csv'\n",
    "DATA_PATH = \"data/train_dataset_with_masks.csv\"\n",
    "TEST_PATH = \"data/tda_test_with_masks.csv\"\n",
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased'\n",
    "WEIGHTS_PATH = \"ckpt/pretrained_bert/model_epoch_10.pt\"\n",
    "\n",
    "USE_SWA = False\n",
    "SWA_START = 4\n",
    "SWA_LR = 5e-2\n",
    "\n",
    "USE_EMA = False\n",
    "EMA_DECAY = 0.999\n",
    "\n",
    "# whether to log the layers being changed (happens once per notebook restart)\n",
    "LOG_LAYERS = True\n",
    "\n",
    "# full, batch, none\n",
    "# actually full and batch anisotropy are different -- the first is for bigger matrices of embeddings\n",
    "# of base and changed language -- and the batch-wise calculates it based on the matrix of differences\n",
    "# TODO: make it a relevant parameter, currently full is computed all the time\n",
    "COMPUTE_ANISOTROPY = \"full\"\n",
    "SAVE_ANISOTROPY_MATRIX = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zi_u2NiL0mgC",
    "outputId": "cbeb7da4-03ef-40c1-a015-90ec071ab357"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "learning_rate = 3e-4\n",
    "num_warmup_steps = 2000\n",
    "\n",
    "n_mlm = 1\n",
    "n_cosine = 10\n",
    "division_layer = 3\n",
    "weight_mlm = 1\n",
    "weight_loss = 1\n",
    "weight_cosine = 1.2\n",
    "weight_projection = 0.9\n",
    "projection_dim = 5\n",
    "USE_MASKS = True\n",
    "USE_TDA_MASKS = True\n",
    "\n",
    "# we save model checkpoint before weight update in case of huge mlm loss jumps, this is the threshold, when to save\n",
    "mlm_jump_threshold = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DESCRIPTION = \\\n",
    "f'''\n",
    "\n",
    "Description: test run with all computations but for mlm loss only -- useful for comparison, all weights trained;\n",
    "\n",
    "Model: based on rubert, additionally pretrained for 10 epochs;\n",
    "Checkpoint: {WEIGHTS_PATH};\n",
    "Context: {SEQ_LEN};\n",
    "Batch size: {BATCH_SIZE};\n",
    "\n",
    "Loss: just mlm; \n",
    "MLM type: token masking;\n",
    "\n",
    "All the other parameters are taken as usual -- but for now we only update mlm and do it for each batch, not every 10. \n",
    "\n",
    "N_MLM: {n_mlm};\n",
    "N_Cosine: {n_cosine};\n",
    "Division_layer: {division_layer};\n",
    "weight_mlm: {weight_mlm};\n",
    "weight_loss: {weight_loss}, constant; -- weight_cosine: {weight_cosine}, \n",
    "                            weight_projection: {weight_projection};\n",
    "\n",
    "\n",
    "LR_SCHEDULER: Cosine annealing with warmup;\n",
    "Initial learning rate: {learning_rate};\n",
    "Warmup_steps: {num_warmup_steps};\n",
    "Steps: {num_epochs}, \n",
    "Decay: None,\n",
    "Epochs: {num_epochs};\n",
    "\n",
    "Additional parameters and notes:\n",
    "EMA: {USE_EMA};\n",
    "EMA_DECAY: {EMA_DECAY};\n",
    "\n",
    "SWA: {USE_SWA};\n",
    "SWA_START: {SWA_START};\n",
    "SWA_LR: {SWA_LR};\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = f\"./logs/{TRY_NAME}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path(directory)\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=path.joinpath(\"run.log\"), filemode=\"w\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio handler to use remote data -- implements get and put methods with pickling option (view file)\n",
    "\n",
    "from MinioHandler import MinioHandler\n",
    "\n",
    "minio = MinioHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMZUfmdLEBnR",
    "outputId": "75c4dd46-dd6c-4f31-ad83-74a0a565b17c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZ1tRDh5RvDP",
    "outputId": "93a64300-36f2-4450-dded-ede6b6454b44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxenomirant\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "_XaOQ4gtSauA",
    "outputId": "94169790-8c91-4460-aaf1-56ab846703ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mxenomirant\u001b[0m (\u001b[33mgrammar-bert\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/ModularLM/wandb/run-20240503_122545-3a8ci5uk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grammar-bert/grammar-bert-model1/runs/3a8ci5uk' target=\"_blank\">plain_mlm_test_all_layers</a></strong> to <a href='https://wandb.ai/grammar-bert/grammar-bert-model1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grammar-bert/grammar-bert-model1' target=\"_blank\">https://wandb.ai/grammar-bert/grammar-bert-model1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grammar-bert/grammar-bert-model1/runs/3a8ci5uk' target=\"_blank\">https://wandb.ai/grammar-bert/grammar-bert-model1/runs/3a8ci5uk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/grammar-bert/grammar-bert-model1/runs/3a8ci5uk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x796fc989a0b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='grammar-bert-model1',\n",
    "    entity='grammar-bert', \n",
    "    name=TRY_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zdbf_sj8Hy_9",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TQrOptuKvk4A"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(DATA_PATH, index_col = 0)\n",
    "# df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df.was_changed].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GB-e4FABxy8y"
   },
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "\n",
    "# idx_init = df.initial.progress_apply(lambda x: x.replace(' ', ''))\n",
    "# idx_pol = df.polypers.progress_apply(lambda x: x.replace(' ', ''))\n",
    "# idx = -(idx_init == idx_pol)\n",
    "# df['was_changed'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yrQu60MLz9cT"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Slightly more complicated masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mask(base: dict, other: dict):\n",
    "#     '''\n",
    "#     Creates mask based on tokenizer output \n",
    "#     (really dumb solution but it somehow works)\n",
    "#     '''\n",
    "#     base_mask = np.zeros_like(base[\"input_ids\"])\n",
    "#     other_mask = np.zeros_like(other[\"input_ids\"])\n",
    "\n",
    "#     base_ids = base[\"input_ids\"]\n",
    "#     other_ids = other[\"input_ids\"]\n",
    "    \n",
    "#     j = 0\n",
    "#     i = 0\n",
    "#     base_counter = 1\n",
    "#     other_counter = 1\n",
    "#     flag = False\n",
    "    \n",
    "#     while True:\n",
    "#         # try:\n",
    "#         #     print(i, j, other_ids[i], base_ids[j], \n",
    "#         #           tokenizer.convert_ids_to_tokens(other_ids[i]), tokenizer.convert_ids_to_tokens(base_ids[j]), other_counter, base_counter)\n",
    "#         # except IndexError:\n",
    "#         #     pass\n",
    "#         try:\n",
    "#             if base_ids[j] == other_ids[i]:\n",
    "#                 if tokenizer.convert_ids_to_tokens(other_ids[i]).startswith(\"##\"):\n",
    "#                     other_counter += 1\n",
    "#                 else:\n",
    "#                     other_counter = 1\n",
    "        \n",
    "#                 if tokenizer.convert_ids_to_tokens(base_ids[j]).startswith(\"##\"):\n",
    "#                     base_counter += 1\n",
    "#                 else:\n",
    "#                     base_counter = 1\n",
    "                \n",
    "#                 i += 1\n",
    "#                 j += 1\n",
    "#                 continue\n",
    "                \n",
    "#             flag = True\n",
    "#             flag2 = True\n",
    "#             while flag:\n",
    "        \n",
    "#                 if tokenizer.convert_ids_to_tokens(other_ids[i]).startswith(\"##\"):\n",
    "#                     i += 1\n",
    "#                     other_counter += 1\n",
    "#                     flag2 = False\n",
    "    \n",
    "#                 if tokenizer.convert_ids_to_tokens(base_ids[j]).startswith(\"##\"):\n",
    "#                     j += 1\n",
    "#                     base_counter += 1\n",
    "#                     flag2 = False\n",
    "\n",
    "#                 if not any([tokenizer.convert_ids_to_tokens(other_ids[i]).startswith(\"##\"),\n",
    "#                            tokenizer.convert_ids_to_tokens(base_ids[j]).startswith(\"##\")]):\n",
    "#                     flag = False\n",
    "#                     if flag2:\n",
    "#                         i+=1\n",
    "#                         j+=1\n",
    "                        \n",
    "            \n",
    "#             base_mask[j-base_counter:j] = [1]*base_counter\n",
    "#             other_mask[i-other_counter:i] = [1]*other_counter\n",
    "#             base_counter = 1\n",
    "#             other_counter = 1\n",
    "                    \n",
    "#         except IndexError:\n",
    "#             break\n",
    "\n",
    "#     base = np.zeros(SEQ_LEN, dtype=int)\n",
    "#     other = np.zeros(SEQ_LEN, dtype=int)\n",
    "\n",
    "#     base[:len(base_mask)] = base_mask[:SEQ_LEN]\n",
    "#     other[:len(other_mask)] = other_mask[:SEQ_LEN]\n",
    "    \n",
    "#     return base, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = []\n",
    "# polypers = []\n",
    "\n",
    "# for i in tqdm(range(len(dt.dataset))):\n",
    "\n",
    "#     base_mask, polypers_mask = create_mask(tokenizer(dt.dataset[\"base\"][i]), tokenizer(dt.dataset[\"polypers\"][i]))\n",
    "\n",
    "#     base.append(base_mask)\n",
    "#     polypers.append(polypers_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(DATA_PATH, index_col=0)\n",
    "# dataset = data[(data.was_changed)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"base_mask\"] = base\n",
    "# dataset[\"polypers_mask\"] = polypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.to_csv(\"data/train_dataset_with_masks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.fput_object(object_name=\"ModularLM/data/train_dataset_with_masks.csv\", file_path=\"./data/train_dataset_with_masks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mask(base: dict, other: dict):\n",
    "#     '''\n",
    "#     Creates mask based on tokenizer output \n",
    "#     (really dumb solution but it somehow works)\n",
    "#     '''\n",
    "#     base_mask = np.zeros_like(base[\"input_ids\"])\n",
    "#     other_mask = np.zeros_like(other[\"input_ids\"])\n",
    "\n",
    "#     base_ids = base[\"input_ids\"]\n",
    "#     other_ids = other[\"input_ids\"]\n",
    "    \n",
    "#     cur = 0\n",
    "#     i = 0\n",
    "#     counter = 0\n",
    "#     token_counter = 1\n",
    "#     flag = False\n",
    "    \n",
    "#     while True:\n",
    "#         try:\n",
    "#             print(i, cur, other_ids[i], base_ids[cur], \n",
    "#                   tokenizer.convert_ids_to_tokens(other_ids[i]), tokenizer.convert_ids_to_tokens(base_ids[cur]),\n",
    "#                  end = \" \")\n",
    "#         except IndexError:\n",
    "#             pass\n",
    "#         try:\n",
    "#             if other_ids[i] == base_ids[cur]:\n",
    "#                 if flag:\n",
    "#                     base_mask[cur-token_counter:cur] = [1]*token_counter\n",
    "#                     flag = False\n",
    "#                 if tokenizer.convert_ids_to_tokens(base_ids[cur]).startswith(\"##\"):    \n",
    "#                     token_counter += 1\n",
    "#                 else:\n",
    "#                     token_counter = 1\n",
    "#                 cur += 1\n",
    "#                 i += 1\n",
    "#                 print(token_counter)\n",
    "#                 continue\n",
    "#         except IndexError:\n",
    "#             break\n",
    "#         print()\n",
    "#         if tokenizer.convert_ids_to_tokens(other_ids[i]).startswith(\"##\"):\n",
    "#             other_mask[i-token_counter:i+1] = [1]*(token_counter+1)\n",
    "#             flag = True\n",
    "#             counter += 1\n",
    "#             i += 1\n",
    "#             continue\n",
    "#         else: \n",
    "#             # base_mask[curtoken_counter-1:cur] = [1]*(token_counter)\n",
    "#             # flag = False\n",
    "#             cur += token_counter\n",
    "#             continue\n",
    "#         cur += 1\n",
    "#         i += 1\n",
    "   \n",
    "#     return base_mask, other_mask        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Train test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TEST_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(DATA_PATH, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = train_test_split(df, test_size=TEST_SIZE, stratify = df[\"was_changed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(\"data/train_bpa.csv\")\n",
    "# test.to_csv(\"data/test_bpa.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pick items from test for TDA and homology computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/test_bpa.csv\", index_col = 0)\n",
    "\n",
    "# df = df[df.was_changed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tda_data = df.sample(n = 250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tda_data.to_csv(\"tda_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.put_object(tda_data, save_name=\"data/tda_test.pkl\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything to minio -- also possible to use default minio functions from Minio class\n",
    "\n",
    "# minio.minio.fput_object(file_path=\"data/test_dataset.csv\", bucket_name=\"public\",\n",
    "#                       object_name=\"ModularLM/data/test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDe7I4QR4gVY"
   },
   "source": [
    "## Dataset and collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tda_collate_func(batch):\n",
    "    if USE_MASKS:\n",
    "        ref = [item[0] for item in batch]\n",
    "        cur = [item[1] for item in batch]\n",
    "        mask_ref = torch.BoolTensor([(item[2]) for item in batch])\n",
    "        mask_cur = torch.BoolTensor([(item[3]) for item in batch])\n",
    "        return [def_data_collator(ref), def_data_collator(cur), mask_ref, mask_cur]\n",
    "    batch = [torch.tensor(item) for item in zip(*batch)]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "V06Z3lby7xme"
   },
   "outputs": [],
   "source": [
    "def collate_func(batch):\n",
    "    if USE_MASKS:\n",
    "        ref = [item[0] for item in batch]\n",
    "        cur = [item[1] for item in batch]\n",
    "        mask_ref = torch.BoolTensor([item[2] for item in batch])\n",
    "        mask_cur = torch.BoolTensor([item[3] for item in batch])\n",
    "        return [data_collator.torch_call(ref), data_collator.torch_call(cur), mask_ref, mask_cur]\n",
    "    batch = [data_collator.torch_call(item) for item in zip(*batch)]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7JP-0xw72PH",
    "outputId": "2f1ca2ee-6378-4dae-cd1e-3eac9d6235a9"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenizer.pad_token = '[SEP]'\n",
    "tokenizer.eos_token = '[SEP]'\n",
    "## note the change -- we now mask the whole words independent of tokenization\n",
    "# data_collator = DataCollatorForWholeWordMask(tokenizer=tokenizer, mlm_probability=MLM_PROB)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=MLM_PROB)\n",
    "def_data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3I3B8JUjnBOs"
   },
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained(MODEL_NAME, torch_dtype=torch.float32)\n",
    "model.to(device)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weights from the last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=119547, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh94UBHqxuSA",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MLM Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Mb9N8GAh_9Te"
   },
   "outputs": [],
   "source": [
    "# dt = datasets.Dataset.from_csv(DATA_PATH)\n",
    "# dt = dt.remove_columns(['polypers', 'was_changed']).rename_column('initial', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "d84hj1c4IQwT"
   },
   "outputs": [],
   "source": [
    "# N_samples = 10**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "6ZHrIWiQA_rn"
   },
   "outputs": [],
   "source": [
    "# def tokenize_function(example):\n",
    "#     return tokenizer(example['text'], truncation=True)\n",
    "\n",
    "# tok_dt = dt.select(range(N_samples)).map(tokenize_function, batched=True)\n",
    "# tok_dt = tok_dt.train_test_split(test_size=100,\n",
    "#                          shuffle=True,\n",
    "#                          seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "AKDqk2mzBQz-"
   },
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     report_to = 'wandb',\n",
    "#     output_dir='part1-model',\n",
    "#     learning_rate=1e-3,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     num_train_epochs=1,\n",
    "#     # evaluation_strategy='steps',\n",
    "#     # eval_steps=20,\n",
    "#     logging_steps=20,\n",
    "#     logging_first_step=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "F3MYlLtm76uJ"
   },
   "outputs": [],
   "source": [
    "# model = BertForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "# model.to(device)\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "LC0KZCwqA50q"
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tok_dt['train'],\n",
    "#     # eval_dataset=tok_dt['test'],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "7vEzJTIREz0k"
   },
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8nu5cYyIxDd"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "4RB10XU9bMbH"
   },
   "outputs": [],
   "source": [
    "def save_gradients(model, division_layer):\n",
    "    layers = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        # division layer passed == division layer + 1 as is inside train\n",
    "        if name.startswith(f'bert.encoder.layer.{division_layer}'):\n",
    "            break\n",
    "        if (param.requires_grad) and param.grad is not None:\n",
    "            layers[name] = param.grad.detach().clone()\n",
    "    if LOG_LAYERS:\n",
    "        logger.info(f\"Saved layers: {str(layers.keys())}\")\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "qHcpG4G8cclV"
   },
   "outputs": [],
   "source": [
    "def change_gradients(*, model, layers, \n",
    "                     division_layer,\n",
    "                     weight_mlm=0.5, \n",
    "                     weight_loss=1, ):\n",
    "\n",
    "    global LOG_LAYERS\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        # division layer passed == division layer + 1 as is inside train\n",
    "        if name.startswith(f'bert.encoder.layer.{division_layer}'):\n",
    "            break\n",
    "        if name in layers:\n",
    "            # param.grad = weight_loss * param.grad + weight_mlm * layers[name]\n",
    "            param.grad = weight_mlm * layers[name]\n",
    "            if LOG_LAYERS:\n",
    "                logger.info(f\"Changed layer: {name}\")\n",
    "                logger.info(f\"gradients changed. {(weight_loss * param.grad).norm(), (weight_mlm * layers[name]).norm()}\\n\")\n",
    "    LOG_LAYERS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "H9vdmHBsLAXg"
   },
   "outputs": [],
   "source": [
    "class LossWeightDecay:\n",
    "    '''\n",
    "    Cosine Weight with decaying step sizes after each multiplication\n",
    "    '''\n",
    "    def __init__(self, init_state=1, decay=0.5):\n",
    "        self.init_state = init_state\n",
    "        self.cur_state = init_state\n",
    "        self.decay = decay\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        res = self.cur_state * other\n",
    "        return res\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.cur_state)\n",
    "\n",
    "    def step(self):\n",
    "        self.cur_state = self.cur_state * self.decay\n",
    "        return None\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_state = self.init_state\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.cur_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "H9vdmHBsLAXg"
   },
   "outputs": [],
   "source": [
    "class LossWeightSum2One:\n",
    "    '''\n",
    "    Cosine Weight summing to 1 over 10 steps (must be subject to change in case other step size is required)\n",
    "    '''\n",
    "    def __init__(self, init_coef = 1, steps: int = 10, linear = False):\n",
    "        self.counter = -1\n",
    "        if linear:\n",
    "            self.steps = init_coef*np.ones(steps)\n",
    "            return None\n",
    "        self.steps = init_coef*np.arange(2, steps+2)**-1.5\n",
    "        return None\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        res = self.steps[self.counter] * other\n",
    "        return res\n",
    "    \n",
    "    def step(self):\n",
    "        self.counter+=1\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.steps[self.counter])\n",
    "\n",
    "    def reset(self):\n",
    "        self.counter = -1\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.steps[self.counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "RsNP-PPvQayL"
   },
   "outputs": [],
   "source": [
    "class CosLoss:\n",
    "    def __init__(self, vector=None, alpha=0):\n",
    "        self.loss = nn.CosineEmbeddingLoss()\n",
    "        self.target = -torch.ones(BATCH_SIZE).to(model.device)\n",
    "        self.alpha = alpha\n",
    "        self.vector = vector\n",
    "\n",
    "    def __call__(self, hid_ref, hid_cur, target):\n",
    "        cos_loss = self.loss(hid_ref, hid_cur, target)\n",
    "        if self.vector is not None:\n",
    "            cos_loss += self.alpha * self.loss(self.vector, hid_ref - hid_cur,\n",
    "                                               self.target)\n",
    "        return cos_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionLoss:\n",
    "    def __init__(self, *, subspace_matrix, weight_cosine: int = 1, weight_projection: int = 1):\n",
    "        '''\n",
    "        Minimizes distance from vector to its projection while maximizing the cosine distance between target and given vectors\n",
    "        (Overall, separates and orthogonalizes subspace w.r.t. given reference vectors)\n",
    "        subspace_matrix -- matrix used for projection construction using M@(M.T@M)^{-1}@M.T\n",
    "        alpha -- weight of cosine loss\n",
    "        beta -- weight of projection distance minimization\n",
    "        '''\n",
    "        self.loss = nn.CosineEmbeddingLoss()\n",
    "        self.target = -torch.ones(BATCH_SIZE).to(model.device)\n",
    "        self.weight_cosine = weight_cosine\n",
    "        self.weight_projection = weight_projection\n",
    "        subspace_matrix = torch.tensor(subspace_matrix)\n",
    "        self.orth_proj = torch.eye(768) - subspace_matrix @ torch.linalg.inv(subspace_matrix.T @ subspace_matrix) @ subspace_matrix.T\n",
    "        self.orth_proj = self.orth_proj.to(model.device)        \n",
    "\n",
    "    def __call__(self, hid_ref, hid_cur, target):\n",
    "        \n",
    "        cos_loss = self.weight_cosine * self.loss(hid_ref, hid_cur, target)\n",
    "\n",
    "        proj_loss = self.weight_projection * torch.linalg.norm(hid_cur@self.orth_proj, ord=2, dim=1).sum()\n",
    "\n",
    "        total_loss = cos_loss + proj_loss\n",
    "        \n",
    "        return total_loss, cos_loss, proj_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criteria, optimizer, lr_scheduler, data, hom_data, n_epochs=1,\n",
    "          n_cosine=10, division_layer=4, weight_mlm=1,\n",
    "          weight_loss=1, save_every_epoch=3, test_every=5000):\n",
    "\n",
    "    # global mlm_losses, cosine_losses\n",
    "    # change global loss tracking to local only -- for now it seems unnecessary\n",
    "    global tda_save_dict\n",
    "\n",
    "    executor = ThreadPoolExecutor(max_workers=6)\n",
    "\n",
    "    tq_epoch = trange(n_epochs, desc='Epochs: ')\n",
    "    tq_batch = tqdm(total=len(data))\n",
    "\n",
    "    # target for cosine loss\n",
    "    target = -torch.ones(BATCH_SIZE).to(model.device)\n",
    "    grads = None\n",
    "    \n",
    "    # just initialization -- first few batches make no difference for tracking\n",
    "    total_loss = 0\n",
    "    mlm_loss = 0\n",
    "    hom_computed = 0\n",
    "    mlm_jumps = 0\n",
    "    anisotropy_matrix = dict()\n",
    "    anisotropy_matrix[\"base\"] = None\n",
    "    anisotropy_matrix[\"polypers\"] = None\n",
    "    # TODO -- optimize for gradual saving of dict intead of accumulation\n",
    "\n",
    "    def global_computation(name, matrix, other):\n",
    "\n",
    "        if matrix is None:\n",
    "            matrix = other\n",
    "        else:\n",
    "            matrix = torch.cat((matrix, other), dim = 0)\n",
    "        if matrix.shape[0] == 4096:\n",
    "            proc = mp.Process(target=SVDmatrix.compute_anisotropy, \n",
    "                              kwargs={\"matrix\":matrix,\n",
    "                                      \"write_to_file\": path.joinpath(f\"{name}.anisotropy\")},\n",
    "                             daemon=True)\n",
    "            proc2 = mp.Process(target=tda_utils.calculate_ph_dim,\n",
    "                               kwargs={\"W\": matrix,\n",
    "                                      \"write_to_file\": path.joinpath(f\"{name}.ph_dim\")},\n",
    "                               daemon=True)\n",
    "\n",
    "            proc3 = mp.Process(target=tda_utils.compute_tda_features,\n",
    "                              kwargs={\"points\": matrix,\n",
    "                                     \"max_dim\": 1, \n",
    "                                     \"write_to_file\": path.joinpath(f\"{name}.tda_feats\")},\n",
    "                              daemon=True)\n",
    "            proc.start()\n",
    "            proc2.start()\n",
    "            proc3.start()\n",
    "            return None\n",
    "        return matrix\n",
    "\n",
    "    # function to read global anisotropy computation results\n",
    "    def get_last_line(filename):\n",
    "        try:\n",
    "            with open(filename, 'r') as f:\n",
    "                lastline = deque(f, 1)[0]\n",
    "        except FileNotFoundError:\n",
    "            lastline = \"0.0\"\n",
    "        return lastline\n",
    "\n",
    "    def read_tda_feats(filename):\n",
    "        feats = get_last_line(filename)\n",
    "        if feats == \"0.0\":\n",
    "            return Stats(entropy=.0, mean=.0, std=.0)\n",
    "            \n",
    "        return eval(feats)\n",
    "\n",
    "    # save necessary features to dict\n",
    "    def save_tda_features(hom_data: torch.utils.data.DataLoader, save_dict: dict):\n",
    "\n",
    "        nonlocal hom_computed\n",
    "        hom_computed+=1\n",
    "        base = []\n",
    "        polypers = []\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(hom_data):\n",
    "                # base embeddings after layer\n",
    "                pred_base = model(**{k: v.to(model.device) for k, v in batch[0].items()},\n",
    "                                  output_hidden_states=True)\n",
    "                hid_ref = pred_base.hidden_states[division_layer]\n",
    "                if USE_TDA_MASKS:\n",
    "                    hid_ref *= batch[2].unsqueeze(-1).to(model.device)\n",
    "                hid_ref = torch.mean(hid_ref, dim = 1)\n",
    "                base.extend(hid_ref.detach().cpu().numpy())\n",
    "\n",
    "                # polypers embeddings after layer\n",
    "                pred_new = model(**{k: v.to(model.device) for k, v in batch[1].items()},\n",
    "                                  output_hidden_states=True)\n",
    "                hid_cur = pred_new.hidden_states[division_layer]\n",
    "                if USE_TDA_MASKS:\n",
    "                    hid_cur *= batch[3].unsqueeze(-1).to(model.device)\n",
    "                hid_cur = torch.mean(hid_cur, dim = 1)\n",
    "                polypers.extend(hid_cur.detach().cpu().numpy())\n",
    "        \n",
    "        save_dict[hom_computed][\"base\"] = base\n",
    "        save_dict[hom_computed][\"polypers\"] = polypers\n",
    "        return save_dict\n",
    "\n",
    "    def save_model(epoch, model, optimizer, pred, total_loss, custom_name=None):\n",
    "        print(\"Saving model checkpoint...\")\n",
    "        buffer = io.BytesIO()\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'mlm_loss': pred.loss,\n",
    "                'cos_loss': total_loss\n",
    "                        }, f=buffer)\n",
    "        # TODO -- add custom hash to model instead of value\n",
    "        if custom_name is None:\n",
    "            minio.put_object(buffer.getvalue(), \n",
    "                         save_name=f\"ckpt/{TRY_NAME}/model_epoch_{epoch}.pt\")\n",
    "        else:\n",
    "            minio.put_object(buffer.getvalue(), \n",
    "                         save_name=f\"ckpt/{TRY_NAME}/model_{custom_name}.pt\")\n",
    "        return None\n",
    "            \n",
    "\n",
    "    def gradient_norm():\n",
    "        grads = [\n",
    "        param.grad.detach().flatten()\n",
    "        for param in model.parameters()\n",
    "        if param.grad is not None\n",
    "        ]\n",
    "        norm = torch.cat(grads).norm()\n",
    "        return norm\n",
    "        \n",
    "    #########################################################\n",
    "    # training loop \n",
    "    #########################################################\n",
    "    for epoch in tq_epoch:\n",
    "        tq_batch.reset()\n",
    "        total_losses = [total_loss]\n",
    "        mlm_losses = [mlm_loss]\n",
    "\n",
    "        for i, batch in enumerate(data):\n",
    "            # save data for TDA\n",
    "            if i % test_every == 0:\n",
    "                tda_save_dict = save_tda_features(hom_data, tda_save_dict)\n",
    "                # also a point of optimization\n",
    "                minio.put_object(tda_save_dict, \n",
    "                                 save_name=f\"data/TDA_FEATURES/tda_save_dict_{TRY_NAME}.pkl\", \n",
    "                                 pickle=True)\n",
    "                test_base_pers_dim = executor.submit(tda_utils.calculate_ph_dim, W=np.array(\n",
    "                    tda_save_dict[hom_computed][\"base\"])\n",
    "                                                    )\n",
    "                test_polypers_pers_dim = executor.submit(tda_utils.calculate_ph_dim, W=np.array(\n",
    "                    tda_save_dict[hom_computed][\"polypers\"])\n",
    "                                                        )\n",
    "                test_base_tda_feats = executor.submit(tda_utils.compute_tda_features, points=np.array(\n",
    "                    tda_save_dict[hom_computed][\"base\"])\n",
    "                                                     )\n",
    "                test_polypers_tda_feats = executor.submit(tda_utils.compute_tda_features, points=np.array(\n",
    "                    tda_save_dict[hom_computed][\"polypers\"])\n",
    "                                                         )\n",
    "                model.train()\n",
    "            # pred on base text    \n",
    "            pred = model(**{k: v.to(model.device) for k, v in batch[0].items()},\n",
    "                         output_hidden_states=True, )\n",
    "\n",
    "            ######################################\n",
    "            # MLM loss update ####################\n",
    "            ######################################\n",
    "            # once upon 10 steps, compute mlm loss\n",
    "\n",
    "            pred.loss.backward()\n",
    "            # grads = save_gradients(\n",
    "            #     model=model, \n",
    "            #     division_layer=division_layer\n",
    "            # )\n",
    "            mlm_grad_norm = gradient_norm()\n",
    "\n",
    "            if (USE_EMA | USE_SWA):\n",
    "                avg_model.update_parameters(model)\n",
    "                # if we use SWA we need to redefine \n",
    "                if USE_SWA: \n",
    "                    if epoch >= SWA_START:\n",
    "                        # it's supposed we won't use regular scheduler after SWA start\n",
    "                        lr_scheduler = swa_scheduler\n",
    "\n",
    "            # WARNING! we take lr step only every cycle, not batch\n",
    "            lr_scheduler.step()\n",
    "            optimizer.step()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            mlm_losses.append(pred.loss.detach().cpu())\n",
    "            mlm_loss = (sum(mlm_losses[-30:]) / len(mlm_losses[-30:])).item()\n",
    "            if (mlm_losses[-1] >= mlm_loss*mlm_jump_threshold) and len(mlm_losses) > 100:\n",
    "                save_model(epoch, model, optimizer, pred, total_loss, custom_name=f\"emergency_mlm_jump_{mlm_jumps}\")\n",
    "                mlm_jumps += 1\n",
    "                \n",
    "\n",
    "            ###########################################\n",
    "            ###########################################\n",
    "            \n",
    "            # compute cosine anyway\n",
    "            # pred on polypers text\n",
    "            pred_new = model(**{k: v.to(model.device) for k, v in batch[1].items()},\n",
    "                             output_hidden_states=True)\n",
    "            \n",
    "            hid_ref = pred.hidden_states[division_layer]\n",
    "            hid_cur = pred_new.hidden_states[division_layer]\n",
    "\n",
    "            # process classes one by one (if we need masked | avergaved vectors, we can just exchange the order in these few blocks)\n",
    "            anisotropy_matrix[\"base\"] = global_computation(name=\"base\", \n",
    "                                                               matrix=anisotropy_matrix[\"base\"],\n",
    "                                                              other=torch.mean(hid_ref.detach().clone().cpu(), dim=1))\n",
    "            anisotropy_matrix[\"polypers\"] = global_computation(name=\"polypers\", \n",
    "                                                               matrix=anisotropy_matrix[\"polypers\"],\n",
    "                                                              other=torch.mean(hid_cur.detach().clone().cpu(), dim=1))\n",
    "            \n",
    "            # look for changed ids only\n",
    "            if USE_MASKS:\n",
    "                # commented as deprecated for now\n",
    "                # 1. use diff in indices as masking (too simple)\n",
    "                # mask = (batch[0][\"input_ids\"] - batch[1][\"input_ids\"]) != 0\n",
    "                # mask = mask.unsqueeze(-1).expand(-1, -1, 768).to(model.device)\n",
    "                # 2. Not working but interesting\n",
    "                # # masked tensors don't support loss calculations as filling with 0 stops differentiation\n",
    "                # hid_ref = masked_tensor(hid_ref, mask.to(model.device), requires_grad=True).to_tensor(value=0)\n",
    "                # hid_cur = masked_tensor(hid_cur, mask.to(model.device), requires_grad=True).to_tensor(value=0)\n",
    "\n",
    "                # multiply by mask to zero-out non-target elements\n",
    "                hid_ref = hid_ref*batch[2].unsqueeze(-1).to(model.device)\n",
    "                hid_cur = hid_cur*batch[3].unsqueeze(-1).to(model.device)\n",
    "            \n",
    "            hid_ref = torch.mean(hid_ref, dim=1)\n",
    "            hid_cur = torch.mean(hid_cur, dim=1)\n",
    "\n",
    "            # compute batch anisotropy\n",
    "            local_anisotropy = executor.submit(SVDmatrix.compute_anisotropy, matrix=(hid_cur-hid_ref).detach().cpu())\n",
    "            \n",
    "            ###########################################\n",
    "            ## CHANGE IN CASE DIFFERENT LOSS IS USED ##\n",
    "            ###########################################\n",
    "            total_loss, cos_loss, proj_loss = criteria(hid_ref, hid_cur, target)\n",
    "            # total_loss.backward()\n",
    "            # total_grad_norm = gradient_norm()\n",
    "            \n",
    "            # as indexing in weight_loss starts from -1, take a step before applying            \n",
    "            weight_loss.step()\n",
    "\n",
    "            # change_gradients(model=model, \n",
    "            #                  layers=grads, \n",
    "            #                  division_layer=division_layer,\n",
    "            #                  weight_mlm=weight_mlm, \n",
    "            #                  weight_loss=weight_loss)\n",
    "                \n",
    "            # optimizer.step()\n",
    "            # optimizer.zero_grad()                    \n",
    "\n",
    "            total_losses.append(total_loss.detach().cpu())\n",
    "\n",
    "            # some averaged estimate to report\n",
    "            total_loss = (sum(total_losses[-30:]) / len(total_losses[-30:])).item()\n",
    "\n",
    "            tda_feats_base = read_tda_feats(path.joinpath(\"base.tda_feats\"))\n",
    "            tda_feats_poly = read_tda_feats(path.joinpath(\"polypers.tda_feats\"))\n",
    "            \n",
    "\n",
    "            # TODO: possibly send not every batch -- however, it acts asynchrously, so doesn't seem to make much difference\n",
    "            wandb.log({\"Epoch\": epoch,\n",
    "                       \"MLM loss\": mlm_loss,\n",
    "                       \"Additional loss\": total_loss,\n",
    "                       \"Cos loss\": cos_loss.item(), \n",
    "                       \"Proj loss\": proj_loss.item(),\n",
    "                       \"MLM grad norm\": mlm_grad_norm,\n",
    "                       # \"Additional grad norm\": total_grad_norm,\n",
    "                       \"Cos Weight\": weight_loss.weight, # may be not that necessary to report unless we chaned it somehow\n",
    "                       \"Learning rate\": lr_scheduler.get_last_lr()[0],\n",
    "                       \"Local anisotropy\": local_anisotropy.result(),\n",
    "                       \"Global anisotropy base\": float(get_last_line(path.joinpath(\"base.anisotropy\"))),\n",
    "                       \"Global anisotropy polypers\": float(get_last_line(path.joinpath(\"polypers.anisotropy\"))),\n",
    "                       \"Global persistent dimension base\": float(get_last_line(path.joinpath(\"base.ph_dim\"))),\n",
    "                       \"Global persistent dimension polypers\": float(get_last_line(path.joinpath(\"polypers.ph_dim\"))),\n",
    "                       \"Global persistent entropy base\": tda_feats_base.entropy,\n",
    "                       \"Global persistent barcode mean base\": tda_feats_base.mean,\n",
    "                       \"Global persistent barcode std base\": tda_feats_base.std,\n",
    "                       \"Global persistent entropy polypers\": tda_feats_poly.entropy,\n",
    "                       \"Global persistent barcode mean polypers\": tda_feats_poly.mean,\n",
    "                       \"Global persistent barcode std polypers\": tda_feats_poly.std,\n",
    "                       \"TDA test persistent dimension base\": test_base_pers_dim.result(),\n",
    "                       \"TDA test persistent dimension polypers\": test_polypers_pers_dim.result(),\n",
    "                       \"TDA test persistent entropy base\": test_base_tda_feats.result().entropy,\n",
    "                       \"TDA test persistent barcode mean base\": test_base_tda_feats.result().mean,\n",
    "                       \"TDA test persistent barcode std\": test_base_tda_feats.result().std,\n",
    "                       \"TDA test persistent entropy polypers\": test_polypers_tda_feats.result().entropy,\n",
    "                       \"TDA test persistent barcode mean polypers\": test_polypers_tda_feats.result().mean,\n",
    "                       \"TDA test persistent entropy polypers\": test_polypers_tda_feats.result().std,\n",
    "                      })\n",
    "            tq_batch.set_postfix({\n",
    "                    'MLM loss': mlm_loss,\n",
    "                    'Additional loss': total_loss\n",
    "                })\n",
    "\n",
    "            tq_batch.update(1)\n",
    "\n",
    "        if epoch % save_every_epoch == 0:\n",
    "            # Note -- we don't save the model class, only the weights\n",
    "            save_model(epoch, model, optimizer, pred, total_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "SPNBA0emMpWr"
   },
   "outputs": [],
   "source": [
    "dt = PairsDataset(tokenizer, path=DATA_PATH)\n",
    "dl = DataLoader(dt, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                collate_fn=collate_func, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "SPNBA0emMpWr"
   },
   "outputs": [],
   "source": [
    "dt_tda = PairsDataset(tokenizer, path=TEST_PATH)\n",
    "dl_tda = DataLoader(dt_tda, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                    collate_fn=tda_collate_func,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Compute SVD on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SVDmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_svd = SVDmatrix.GetSVD(model=model, dataloader=dl, division_layer=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_svd.get_matrix(use_masks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(get_svd.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.put_object(get_svd.matrix, save_name=\"matrices/3rd_layer_diff_matrix_masked.pkl\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_svd.compute_svd(compute_uv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minio.put_object(get_svd.svd, save_name=\"matrices/3rd_layer_diff_svd_masked.pkl\", pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different solution (when library internal tobytes interface is implemented --\n",
    "# this variant is prefered)\n",
    "\n",
    "# minio.put_object(get_svd.svd[0].tobytes(), save_name=\"svd_test\", pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "CAq3W2Qd3c3y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scale by number of steps in a cycle\n",
    "# weight_mlm /= n_cosine\n",
    "\n",
    "# reassign weight loss to custom class implementation\n",
    "# weight_loss = LossWeightSum2One(init_coef=1)\n",
    "\n",
    "# set weight to constant \n",
    "weight_loss = LossWeightDecay(init_state=weight_loss/n_cosine, decay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "vncR8UNMvk4C"
   },
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     param.requires_grad = name.startswith(f\"bert.encoder.layer.{division_layer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "mSRwfobbRsQY"
   },
   "outputs": [],
   "source": [
    "# vec = torch.normal(0.5,\n",
    "#                    0.1,\n",
    "#                    size=(768, ),\n",
    "#                    requires_grad=False).repeat(BATCH_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_matrix = minio.get_object(\"matrices/3rd_layer_diff_svd.pkl\", unpickle=True)\n",
    "diff_matrix_masked = minio.get_object(\"matrices/3rd_layer_diff_svd_masked.pkl\", unpickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2108.806   ,  582.30066 ,  296.07874 ,  216.58394 ,  191.25536 ,\n",
       "        184.14783 ,  146.94238 ,  142.75288 ,  132.13673 ,  131.36597 ,\n",
       "        118.71447 ,  115.409805,  106.333984,  103.84306 ,  100.275635],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_matrix[1][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.3043  , 116.136986,  59.20416 ,  49.841587,  44.61275 ,\n",
       "        34.94017 ,  28.383049,  27.118603,  25.738264,  24.668709,\n",
       "        23.207108,  22.882563,  22.174425,  21.728552,  21.218142],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_matrix_masked[1][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "\n",
    "ax[0].plot(diff_matrix[1],)\n",
    "ax[0].title.set_text(\"unmasked\")\n",
    "ax[1].plot(diff_matrix_masked[1])\n",
    "ax[1].title.set_text(\"masked\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = torch.tensor(diff_matrix_masked[2][-5:]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj = torch.tensor(np.vstack((diff_matrix_masked[2][:3], diff_matrix_masked[2][-2:]))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 5])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "del diff_matrix, diff_matrix_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "O48t9N1K8XCF"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adafactor(model.parameters(), lr=learning_rate)\n",
    "# criterion = CosLoss(alpha=0.5, vec=vec)\n",
    "# criterion = nn.CosineEmbeddingLoss()\n",
    "criterion = ProjectionLoss(subspace_matrix=proj, weight_cosine=weight_cosine, weight_projection=weight_projection)\n",
    "\n",
    "num_training_steps = int(num_epochs * len(dl) / n_cosine * n_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16820"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of lr sheduler updates\n",
    "num_training_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate & averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_SWA:\n",
    "    \n",
    "    lr_scheduler = get_scheduler(\n",
    "                    name=\"cosine\", optimizer=optimizer, num_warmup_steps=num_warmup_steps,\n",
    "                    num_training_steps=num_training_steps\n",
    "                    )\n",
    "\n",
    "    # make steps at the end of first 5 epochs -- may be object to change made explicitely\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "    #                                                     milestones=[int(len(dl)*i/n_cosine*n_mlm) for i in range(1, num_epochs)],\n",
    "    #                                                     gamma=0.8,)\n",
    "    \n",
    "    # # Note: Averaged model is applicable to custom modules -- not only full models, \n",
    "    # so it can be used for module training as well\n",
    "    if USE_EMA:\n",
    "        avg_model = ema_swa_utils.AveragedModel(model,  \n",
    "                                                multi_avg_fn=ema_swa_utils.get_ema_multi_avg_fn(decay=EMA_DECAY)).to(device)\n",
    "\n",
    "elif USE_SWA:\n",
    "    avg_model = ema_swa_utils.AveragedModel(model,\n",
    "                                           multi_avg_fn=ema_swa_utils.get_swa_multi_avg_fn()).to(device)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                        milestones=[int(len(dl)*i/n_cosine*n_mlm)for i in range(1, num_epochs)][:3],\n",
    "                                                        gamma=0.5,)\n",
    "    # ex. after 5 epochs\n",
    "    logger.info(f\"Using swa after {SWA_START} epochs\")\n",
    "    # grows swa learning rate from current optimizer value till the SWA_lr,\n",
    "    # anneal epochs determines the number of steps necessary\n",
    "    # may be it's plausible to change from our current implementation to the epoch-wise stepping\n",
    "    swa_scheduler = ema_swa_utils.SWALR(optimizer=optimizer, \n",
    "                                    swa_lr=SWA_LR,\n",
    "                                    anneal_strategy=\"cos\",\n",
    "                                    anneal_epochs=3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Description: test run with all computations but for mlm loss only -- useful for comparison, all weights trained;\n",
      "\n",
      "Model: based on rubert, additionally pretrained for 10 epochs;\n",
      "Checkpoint: ckpt/pretrained_bert/model_epoch_10.pt;\n",
      "Context: 64;\n",
      "Batch size: 16;\n",
      "\n",
      "Loss: just mlm; \n",
      "MLM type: token masking;\n",
      "\n",
      "All the other parameters are taken as usual -- but for now we only update mlm and do it for each batch, not every 10. \n",
      "\n",
      "N_MLM: 1;\n",
      "N_Cosine: 10;\n",
      "Division_layer: 3;\n",
      "weight_mlm: 1;\n",
      "weight_loss: 1, constant; -- weight_cosine: 1.2, \n",
      "                            weight_projection: 0.9;\n",
      "\n",
      "\n",
      "LR_SCHEDULER: Cosine annealing with warmup;\n",
      "Initial learning rate: 0.0003;\n",
      "Warmup_steps: 2000;\n",
      "Steps: 5, \n",
      "Decay: None,\n",
      "Epochs: 5;\n",
      "\n",
      "Additional parameters and notes:\n",
      "EMA: False;\n",
      "EMA_DECAY: 0.999;\n",
      "\n",
      "SWA: False;\n",
      "SWA_START: 4;\n",
      "SWA_LR: 0.05;\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396,
     "referenced_widgets": [
      "001cfa81c7354e93be3df3a5cf1b1058",
      "1957ad156733493da7a1d98af4e41f75",
      "b09cac7f786d41508fc087bfdc5967b7",
      "3adea4ff86b3452ea61fa306820297e6",
      "644be7a3004544af89d53d40dfad2f2b",
      "ab1566b360054b28942a3037cf3b746a",
      "36d21aa4eb7245f7918062cea3ea7a1b",
      "99f7527310794081b4b6adf4b6f3d4eb",
      "02c75806a08d4fd48c35b5a1dcdea1fb",
      "4064efa851f842cdb64b85b7498e2072",
      "9cd5f89775324214b3bcf755a575bf56",
      "7145096b67ab4dc69573e9047570c587",
      "e465332bfe814a2485071916e79d6ec0",
      "f468a1aab83f440a9a49912cb2cf901e",
      "cf17fde9c27f40a4b4e8ee7a83918f96",
      "e60d7f63aedf4b52982c846515cbc703",
      "991f151a7fe041e39275a97cdc1d2838",
      "edf64befa1a3437f82ca7886bb27b9af",
      "4c82641162ed4e569484ba69cbc255c6",
      "e1441e83a1f84e448f7a4b19dc1e6527",
      "99f562bfbd5c4f25a847a01add5d776a",
      "f76d3bb75a774ce9a538561618ca09cf"
     ]
    },
    "id": "F762mn4J1t5F",
    "outputId": "51fddd23-30ec-446f-fcde-ae5f7db8f13e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModularLM/ckpt/plain_mlm_test_all_layers/DESCRIPTION.txt: |####################| 0.00 MB/0.00 MB 100% [elapsed: 00:00 left: 00:00,  0.34 MB/sec]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdb86a4629249c19545eb0b9549f9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26891f09ff0443d990ed2291dceffafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModularLM/data/TDA_FEATURES/tda_save_dict_plain_mlm_test_all_layers.pkl: |####################| 17.06 MB/17.06 MB 100% [elapsed: 00:00 left: 00:00, 369.90 MB/sec]Saving model checkpoint...\n",
      "ModularLM/data/TDA_FEATURES/tda_save_dict_plain_mlm_test_all_layers.pkl: |####################| 31.28 MB/31.28 MB 100% [elapsed: 00:00 left: 00:00, 123.42 MB/sec] "
     ]
    }
   ],
   "source": [
    "# put description to minio before proceeding\n",
    "minio.put_object(DESCRIPTION, \n",
    "                save_name=f\"ckpt/{TRY_NAME}/DESCRIPTION.txt\", pickle=True)\n",
    "\n",
    "# train model\n",
    "tda_save_dict = defaultdict(dict)\n",
    "\n",
    "try:\n",
    "    with torch.autocast(\"cuda\"): \n",
    "        train(model=model, criteria=criterion, optimizer=optimizer,\n",
    "              lr_scheduler=lr_scheduler, data=dl, hom_data=dl_tda,\n",
    "              n_epochs=num_epochs,\n",
    "              n_cosine=n_cosine, division_layer=division_layer+1,\n",
    "              weight_mlm=weight_mlm, weight_loss=weight_loss,\n",
    "              save_every_epoch=2, test_every=3000)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    minio.put_object(DESCRIPTION, \n",
    "                save_name=f\"ckpt/trained_models/{TRY_NAME}/DESCRIPTION.txt\", pickle=True)\n",
    "    # in case we use averaging optimization -- we need to recalculate batch | layer normalization before inference\n",
    "    if (USE_EMA | USE_SWA):\n",
    "        torch.optim.swa_utils.update_bn(dl, avg_model)\n",
    "    \n",
    "    # save to trained models\n",
    "    logger.info(\"Saving model...\")\n",
    "    buffer = io.BytesIO()\n",
    "    \n",
    "    if (USE_EMA | USE_SWA):\n",
    "        torch.save({\n",
    "            'model_state_dict': avg_model.state_dict(),\n",
    "                    }, f=buffer)\n",
    "    else:\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "                    }, f=buffer)\n",
    "    \n",
    "    minio.put_object(buffer.getvalue(), \n",
    "                     save_name=f\"ckpt/trained_models/{TRY_NAME}/model.pt\")\n",
    "    \n",
    "    minio.fput_object(file_path=path.joinpath(\"base.anisotropy\"),\n",
    "                      object_name=f\"ModularLM/ckpt/trained_models/{TRY_NAME}/base.anisotropy.log\")\n",
    "    \n",
    "    minio.fput_object(file_path=path.joinpath(\"polypers.anisotropy\"),\n",
    "                      object_name=f\"ModularLM/ckpt/trained_models/{TRY_NAME}/polypers.anisotropy.log\", )\n",
    "    \n",
    "    minio.fput_object(file_path=path.joinpath(\"base.ph_dim\"),\n",
    "                      object_name=f\"ModularLM/ckpt/trained_models/{TRY_NAME}/base.ph_dim.log\")\n",
    "    minio.fput_object(file_path=path.joinpath(\"polypers.ph_dim\"),\n",
    "                      object_name=f\"ModularLM/ckpt/trained_models/{TRY_NAME}/polypers.ph_dim.log\")\n",
    "    minio.fput_object(file_path=path.joinpath(\"base.tda_feats\"),\n",
    "                      object_name=f\"ModularLM/ckpt/trained_models/{TRY_NAME}/base.tda_feats.log\")\n",
    "    minio.fput_object(file_path=path.joinpath(\"polypers.tda_feats\"),\n",
    "                      object_name=f\"ModularLM/ckpt/trained_models/{TRY_NAME}/polypers.tda_feats.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "001cfa81c7354e93be3df3a5cf1b1058": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1957ad156733493da7a1d98af4e41f75",
       "IPY_MODEL_b09cac7f786d41508fc087bfdc5967b7",
       "IPY_MODEL_3adea4ff86b3452ea61fa306820297e6"
      ],
      "layout": "IPY_MODEL_644be7a3004544af89d53d40dfad2f2b"
     }
    },
    "02c75806a08d4fd48c35b5a1dcdea1fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1957ad156733493da7a1d98af4e41f75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab1566b360054b28942a3037cf3b746a",
      "placeholder": "",
      "style": "IPY_MODEL_36d21aa4eb7245f7918062cea3ea7a1b",
      "value": "Epochs:0%"
     }
    },
    "36d21aa4eb7245f7918062cea3ea7a1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3adea4ff86b3452ea61fa306820297e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4064efa851f842cdb64b85b7498e2072",
      "placeholder": "",
      "style": "IPY_MODEL_9cd5f89775324214b3bcf755a575bf56",
      "value": "0/1[00:56&lt;?,?it/s]"
     }
    },
    "4064efa851f842cdb64b85b7498e2072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c82641162ed4e569484ba69cbc255c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "644be7a3004544af89d53d40dfad2f2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7145096b67ab4dc69573e9047570c587": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e465332bfe814a2485071916e79d6ec0",
       "IPY_MODEL_f468a1aab83f440a9a49912cb2cf901e",
       "IPY_MODEL_cf17fde9c27f40a4b4e8ee7a83918f96"
      ],
      "layout": "IPY_MODEL_e60d7f63aedf4b52982c846515cbc703"
     }
    },
    "991f151a7fe041e39275a97cdc1d2838": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99f562bfbd5c4f25a847a01add5d776a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99f7527310794081b4b6adf4b6f3d4eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cd5f89775324214b3bcf755a575bf56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab1566b360054b28942a3037cf3b746a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b09cac7f786d41508fc087bfdc5967b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99f7527310794081b4b6adf4b6f3d4eb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02c75806a08d4fd48c35b5a1dcdea1fb",
      "value": 0
     }
    },
    "cf17fde9c27f40a4b4e8ee7a83918f96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99f562bfbd5c4f25a847a01add5d776a",
      "placeholder": "",
      "style": "IPY_MODEL_f76d3bb75a774ce9a538561618ca09cf",
      "value": "166/37379[00:55&lt;2:56:01,3.52it/s,Cosineloss=1.46]"
     }
    },
    "e1441e83a1f84e448f7a4b19dc1e6527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e465332bfe814a2485071916e79d6ec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_991f151a7fe041e39275a97cdc1d2838",
      "placeholder": "",
      "style": "IPY_MODEL_edf64befa1a3437f82ca7886bb27b9af",
      "value": "0%"
     }
    },
    "e60d7f63aedf4b52982c846515cbc703": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edf64befa1a3437f82ca7886bb27b9af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f468a1aab83f440a9a49912cb2cf901e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c82641162ed4e569484ba69cbc255c6",
      "max": 37379,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e1441e83a1f84e448f7a4b19dc1e6527",
      "value": 166
     }
    },
    "f76d3bb75a774ce9a538561618ca09cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
