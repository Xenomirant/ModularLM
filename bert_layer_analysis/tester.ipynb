{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased'\n",
    "SEQ_LEN = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raskind/miniconda3/envs/loop/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_2109270/1161073274.py:176: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(MODEL)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertForMaskedLM,\n",
    "    BertConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DefaultDataCollator,\n",
    "    default_data_collator,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from transformers.modeling_outputs import MaskedLMOutput\n",
    "# from google.colab import drive\n",
    "import torch\n",
    "from typing import Optional\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "# from datasets import load_metric\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased'\n",
    "SEQ_LEN = 64\n",
    "BATCH_SIZE = 32\n",
    "HID_SIZE = 768\n",
    "DROPOUT = 0.15\n",
    "DATA_PATH = '/cephfs/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/test_dataset_prefix.csv'\n",
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased'\n",
    "MODEL = \"/cephfs/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/model_epoch_10.pt\"\n",
    "# MODEL = \"/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/modular_lm_4.1_prefix_mix_flag_full_100k.pt\"\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "@dataclass()\n",
    "class GramMaskedLMOutput(MaskedLMOutput):\n",
    "    gram_output: Optional[torch.tensor] = field(default=None,)\n",
    "    last_hidden_state: Optional[torch.tensor] = field(default=None,)\n",
    "\n",
    "\n",
    "class BertModule(nn.Module):\n",
    "  def __init__(self, model):\n",
    "        super(BertModule, self).__init__()\n",
    "        self.bert = model\n",
    "\n",
    "  def forward(self,\n",
    "            input_ids: Optional[torch.Tensor] = None,\n",
    "            inputs_embeds: Optional[torch.Tensor] = None,\n",
    "            attention_mask: Optional[torch.Tensor] = None,\n",
    "            token_type_ids: Optional[torch.Tensor] = None,\n",
    "            *args, **kwargs):\n",
    "    output = self.bert(input_ids=input_ids,\n",
    "                       inputs_embeds=inputs_embeds,\n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids,\n",
    "                       **kwargs\n",
    "                      )\n",
    "    return output\n",
    "\n",
    "class GramModule(nn.Module):\n",
    "  def __init__(self, hidden_size = HID_SIZE, dropout = DROPOUT, num_layers = 1, flag=True):\n",
    "    super(GramModule, self).__init__()\n",
    "    self.LSTM = nn.LSTM(hidden_size + flag, hidden_size, num_layers)\n",
    "\n",
    "  def forward(self, bert_output, poly_flag):\n",
    "    emb_with_poly_flag = torch.cat([bert_output, poly_flag.unsqueeze(1).repeat(1, SEQ_LEN).unsqueeze(2)], dim=2)\n",
    "    output, _ = self.LSTM(emb_with_poly_flag)\n",
    "    return output\n",
    "\n",
    "\n",
    "class MLMHead(nn.Module):\n",
    "  def __init__(self, vocab_size = VOCAB_SIZE, hidden_size = HID_SIZE, dropout = DROPOUT, flag=False):\n",
    "    super(MLMHead, self).__init__()\n",
    "    self.linear_stack = nn.Sequential(\n",
    "        nn.Linear(hidden_size+flag, hidden_size),\n",
    "        nn.GELU(),\n",
    "        nn.LayerNorm((768,), eps=1e-12)\n",
    "        )\n",
    "    self.emb_matrix = nn.Linear(hidden_size, vocab_size)\n",
    "    self.flag=flag\n",
    "\n",
    "  def forward(self, input, poly_flag=None, *args, **kwargs):\n",
    "    if self.flag:\n",
    "        input = torch.cat([input, poly_flag.unsqueeze(1).repeat(1, SEQ_LEN).unsqueeze(2)], dim=2)\n",
    "    linear_output = self.linear_stack(input)\n",
    "    logits = self.emb_matrix(linear_output)\n",
    "    return logits, linear_output\n",
    "\n",
    "\n",
    "class ModularLM(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(ModularLM, self).__init__()\n",
    "        self.bert_module = BertModule(model=bert_model.bert)\n",
    "        self.head = MLMHead(flag=True)\n",
    "        self.head.emb_matrix.weight = self.bert_module.bert.embeddings.word_embeddings.weight\n",
    "\n",
    "    def forward(self,\n",
    "            input_ids: Optional[torch.Tensor] = None,\n",
    "            inputs_embeds: Optional[torch.Tensor] = None,\n",
    "            attention_mask: Optional[torch.Tensor] = None,\n",
    "            token_type_ids: Optional[torch.Tensor] = None,\n",
    "            poly_flag: Optional[torch.Tensor] = None,\n",
    "            *args, **kwargs):\n",
    "            # if poly_flag is None:\n",
    "            #     poly_flag = kwargs.pop('poly_flag')\n",
    "        bert_output = self.bert_module(input_ids=input_ids,\n",
    "                                       inputs_embeds=inputs_embeds,\n",
    "                                       attention_mask=attention_mask,\n",
    "                                       token_type_ids=token_type_ids,\n",
    "                                      output_attentions=True, **kwargs)\n",
    "\n",
    "        output, gram_output = self.head(bert_output.last_hidden_state, poly_flag)\n",
    "        return GramMaskedLMOutput(\n",
    "            loss=None,\n",
    "            logits=output,\n",
    "            hidden_states=bert_output.hidden_states,\n",
    "            attentions=bert_output.attentions,\n",
    "            last_hidden_state=bert_output.last_hidden_state,\n",
    "            gram_output=gram_output\n",
    "        )\n",
    "class ComposedHead(nn.Module):\n",
    "    def __init__(self, embs):\n",
    "        super(ComposedHead, self).__init__()\n",
    "        self.gram = GramModule(flag=True)\n",
    "        self.head = MLMHead(flag=False)\n",
    "        self.head.emb_matrix.weight = embs\n",
    "    \n",
    "    def forward(self, bert_output, poly_flag):\n",
    "        gram_output = self.gram(bert_output=bert_output,\n",
    "                                poly_flag=poly_flag)\n",
    "        output, _ = self.head(gram_output)\n",
    "        return output, gram_output\n",
    "\n",
    "class ModularLSTMLM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModularLSTMLM, self).__init__()\n",
    "        self.bert_module = BertModule(model=bert_model.bert)\n",
    "        self.head = ComposedHead(self.bert_module.bert.embeddings.word_embeddings.weight)\n",
    "        # self.gram = GramModule(flag=True)\n",
    "        # self.head = MLMHead(flag=False)\n",
    "        # self.head.emb_matrix.weight = self.bert_module.bert.embeddings.word_embeddings.weight\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, poly_flag, token_type_ids=None, **kwargs):\n",
    "        bert_output = self.bert_module(input_ids=input_ids,\n",
    "                                       attention_mask=attention_mask,\n",
    "                                       token_type_ids=token_type_ids,\n",
    "                                      output_attentions=True, **kwargs)\n",
    "        # gram_output = self.gram(bert_output=bert_output.last_hidden_state,\n",
    "        #                         poly_flag=poly_flag)\n",
    "        # output, _ = self.head(gram_output)\n",
    "        output, gram_output = self.head(bert_output=bert_output.last_hidden_state,poly_flag=poly_flag)\n",
    "        return GramMaskedLMOutput(\n",
    "            loss=None,\n",
    "            logits=output,\n",
    "            hidden_states=bert_output.hidden_states,\n",
    "            attentions=bert_output.attentions,\n",
    "            last_hidden_state=bert_output.last_hidden_state,\n",
    "            gram_output=gram_output\n",
    "        )\n",
    "\n",
    "ModularLM.device = device\n",
    "ModularLSTMLM.device = device\n",
    "BertModule.device = device\n",
    "\n",
    "df_test = pd.read_csv(DATA_PATH, index_col=0)\n",
    "df = df_test.sample(10000, random_state=42, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "bert_model = BertForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "checkpoint = torch.load(MODEL)\n",
    "# model = ModularLSTMLM()\n",
    "# model = ModularLM()\n",
    "model=bert_model\n",
    "# checkpoint['model_state_dict'] = checkpoint['model_state_dict'] = {('head.'+k if k.startswith('head') or k.startswith('gram') else k):v for k, v in checkpoint['model_state_dict'].items()}\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "import ecco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('',\n",
       "  BertForMaskedLM(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=119547, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )),\n",
       " ('bert',\n",
       "  BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )),\n",
       " ('bert.embeddings',\n",
       "  BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.embeddings.word_embeddings', Embedding(119547, 768, padding_idx=0)),\n",
       " ('bert.embeddings.position_embeddings', Embedding(512, 768)),\n",
       " ('bert.embeddings.token_type_embeddings', Embedding(2, 768)),\n",
       " ('bert.embeddings.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.embeddings.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder',\n",
       "  BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer',\n",
       "  ModuleList(\n",
       "    (0-11): 12 x BertLayer(\n",
       "      (attention): BertAttention(\n",
       "        (self): BertSdpaSelfAttention(\n",
       "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (output): BertSelfOutput(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (intermediate): BertIntermediate(\n",
       "        (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (intermediate_act_fn): GELUActivation()\n",
       "      )\n",
       "      (output): BertOutput(\n",
       "        (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.0',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.0.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.0.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.0.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.0.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.0.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.0.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.0.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.0.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.0.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.0.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.0.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.0.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.0.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.0.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.0.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.0.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.0.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.1',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.1.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.1.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.1.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.1.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.1.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.1.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.1.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.1.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.1.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.1.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.1.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.1.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.1.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.1.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.1.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.1.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.1.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.2',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.2.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.2.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.2.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.2.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.2.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.2.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.2.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.2.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.2.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.2.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.2.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.2.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.2.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.2.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.2.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.2.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.2.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.3',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.3.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.3.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.3.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.3.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.3.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.3.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.3.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.3.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.3.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.3.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.3.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.3.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.3.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.3.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.3.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.3.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.3.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.4',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.4.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.4.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.4.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.4.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.4.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.4.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.4.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.4.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.4.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.4.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.4.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.4.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.4.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.4.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.4.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.4.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.4.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.5',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.5.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.5.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.5.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.5.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.5.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.5.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.5.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.5.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.5.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.5.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.5.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.5.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.5.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.5.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.5.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.5.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.5.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.6',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.6.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.6.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.6.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.6.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.6.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.6.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.6.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.6.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.6.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.6.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.6.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.6.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.6.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.6.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.6.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.6.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.6.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.7',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.7.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.7.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.7.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.7.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.7.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.7.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.7.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.7.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.7.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.7.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.7.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.7.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.7.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.7.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.7.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.7.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.7.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.8',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.8.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.8.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.8.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.8.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.8.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.8.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.8.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.8.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.8.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.8.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.8.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.8.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.8.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.8.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.8.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.8.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.8.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.9',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.9.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.9.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.9.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.9.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.9.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.9.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.9.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.9.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.9.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.9.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.9.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.9.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.9.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.9.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.9.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.9.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.9.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.10',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.10.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.10.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.10.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.10.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.10.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.10.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.10.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.10.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.10.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.10.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.10.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.10.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.10.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.10.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.10.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.10.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.10.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.11',\n",
       "  BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.11.attention',\n",
       "  BertAttention(\n",
       "    (self): BertSdpaSelfAttention(\n",
       "      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): BertSelfOutput(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )),\n",
       " ('bert.encoder.layer.11.attention.self',\n",
       "  BertSdpaSelfAttention(\n",
       "    (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.11.attention.self.query',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.11.attention.self.key',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.11.attention.self.value',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.11.attention.self.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.11.attention.output',\n",
       "  BertSelfOutput(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.11.attention.output.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.11.attention.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.11.attention.output.dropout',\n",
       "  Dropout(p=0.1, inplace=False)),\n",
       " ('bert.encoder.layer.11.intermediate',\n",
       "  BertIntermediate(\n",
       "    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )),\n",
       " ('bert.encoder.layer.11.intermediate.dense',\n",
       "  Linear(in_features=768, out_features=3072, bias=True)),\n",
       " ('bert.encoder.layer.11.intermediate.intermediate_act_fn', GELUActivation()),\n",
       " ('bert.encoder.layer.11.output',\n",
       "  BertOutput(\n",
       "    (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )),\n",
       " ('bert.encoder.layer.11.output.dense',\n",
       "  Linear(in_features=3072, out_features=768, bias=True)),\n",
       " ('bert.encoder.layer.11.output.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('bert.encoder.layer.11.output.dropout', Dropout(p=0.1, inplace=False)),\n",
       " ('cls',\n",
       "  BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=119547, bias=True)\n",
       "    )\n",
       "  )),\n",
       " ('cls.predictions',\n",
       "  BertLMPredictionHead(\n",
       "    (transform): BertPredictionHeadTransform(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (transform_act_fn): GELUActivation()\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): Linear(in_features=768, out_features=119547, bias=True)\n",
       "  )),\n",
       " ('cls.predictions.transform',\n",
       "  BertPredictionHeadTransform(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (transform_act_fn): GELUActivation()\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )),\n",
       " ('cls.predictions.transform.dense',\n",
       "  Linear(in_features=768, out_features=768, bias=True)),\n",
       " ('cls.predictions.transform.transform_act_fn', GELUActivation()),\n",
       " ('cls.predictions.transform.LayerNorm',\n",
       "  LayerNorm((768,), eps=1e-12, elementwise_affine=True)),\n",
       " ('cls.predictions.decoder',\n",
       "  Linear(in_features=768, out_features=119547, bias=True))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm import LM\n",
    "\n",
    "\n",
    "model_config = {\n",
    "    'embedding': \"bert.embeddings.word_embeddings.weight\",\n",
    "    'type': 'mlm',\n",
    "    'activations': ['intermediate\\.dense'], #This is a regex\n",
    "    'token_prefix': '##',\n",
    "    'partial_token_prefix': '',\n",
    "    'tokenizer_config': '',\n",
    "}\n",
    "ecco_model = LM(model, tokenizer, model_name='DeepPavlov/rubert-base-cased', config=model_config, collect_activations_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_df = df[df['was_changed']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m             inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# model.to(device)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m             out \u001b[38;5;241m=\u001b[39m \u001b[43mecco_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattribution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m             res[t][flag]\u001b[38;5;241m.\u001b[39mappend(out\u001b[38;5;241m.\u001b[39mattribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mig\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m             torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/cephfs/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/lm.py:507\u001b[0m, in \u001b[0;36mLM.__call__\u001b[0;34m(self, input_tokens, attribution)\u001b[0m\n\u001b[1;32m    505\u001b[0m     cur_encoder_input_embeds \u001b[38;5;241m=\u001b[39m encoder_input_embeds[:,:,:]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# cur\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyze_token\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_input_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_encoder_input_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_input_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribution_flags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# poly_flag = input_tokens.get('poly_flag', None)\u001b[39;49;00m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;66;03m# Turn activations from dict to a proper array\u001b[39;00m\n\u001b[1;32m    517\u001b[0m activations_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_activations_dict\n",
      "File \u001b[0;32m/cephfs/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/lm.py:146\u001b[0m, in \u001b[0;36mLM._analyze_token\u001b[0;34m(self, encoder_input_embeds, encoder_attention_mask, decoder_input_embeds, prediction_id, poly_flag, attribution_flags)\u001b[0m\n\u001b[1;32m    143\u001b[0m     forward_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly_flag\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpoly_flag\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mtile(\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Add attribution scores to self.attributions\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributions[attr_method]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 146\u001b[0m     \u001b[43mcompute_primary_attributions_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattr_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforward_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforward_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_id\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    152\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/ecco/attribution.py:101\u001b[0m, in \u001b[0;36mcompute_primary_attributions_scores\u001b[0;34m(attr_method, model, forward_kwargs, prediction_id, aggregation)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo implementation found for primary attribution method \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease choose one of the methods: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(ATTR_NAME_TO_CLASS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m ig \u001b[38;5;241m=\u001b[39m attr_method_class(forward_func\u001b[38;5;241m=\u001b[39mforward_func)\n\u001b[0;32m--> 101\u001b[0m attributions \u001b[38;5;241m=\u001b[39m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Does it make sense to concatenate encoder and decoder attributions before normalization?\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# We assume that the encoder/decoder embeddings are the same\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalize_attributes(torch\u001b[38;5;241m.\u001b[39mcat(attributions, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/_utils/common.py:536\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m    531\u001b[0m output \u001b[38;5;241m=\u001b[39m forward_func(\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39madditional_forward_args)\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m additional_forward_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m inputs\n\u001b[1;32m    535\u001b[0m )\n\u001b[0;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_select_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/_utils/common.py:586\u001b[0m, in \u001b[0;36m_select_targets\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _verify_select_column(output, target)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnumel(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _verify_select_column(output, cast(\u001b[38;5;28mint\u001b[39m, target\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnumel(target) \u001b[38;5;241m==\u001b[39m num_examples:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = {'base':{0:[], 1:[]},'polypers':{0:[], 1:[]}}\n",
    "for i in range(100):\n",
    "    for t in ['base','polypers']:\n",
    "        for flag in [0,1]:\n",
    "            text = dif_df[t][i]\n",
    "            # text = '   ,  .'\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")\n",
    "            # inputs[\"poly_flag\"] = torch.tensor([flag])\n",
    "\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "# model.to(device)\n",
    "            out = ecco_model(inputs,attribution=['ig'])\n",
    "            res[t][flag].append(out.attribution['ig'])\n",
    "            torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/attr_100.pkl', 'wb') as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/cephfs/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/attr_100.pkl', 'rb') as f:\n",
    "    res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m             inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# model.to(device)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m             out \u001b[38;5;241m=\u001b[39m \u001b[43mecco_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattribution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mig\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m             max_res[t][flag]\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[1;32m     14\u001b[0m             torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/cephfs/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/lm.py:507\u001b[0m, in \u001b[0;36mLM.__call__\u001b[0;34m(self, input_tokens, attribution)\u001b[0m\n\u001b[1;32m    505\u001b[0m     cur_encoder_input_embeds \u001b[38;5;241m=\u001b[39m encoder_input_embeds[:,:,:]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# cur\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_analyze_token\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_input_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_encoder_input_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_input_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribution_flags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# poly_flag = input_tokens.get('poly_flag', None)\u001b[39;49;00m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;66;03m# Turn activations from dict to a proper array\u001b[39;00m\n\u001b[1;32m    517\u001b[0m activations_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_activations_dict\n",
      "File \u001b[0;32m/cephfs/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/lm.py:146\u001b[0m, in \u001b[0;36mLM._analyze_token\u001b[0;34m(self, encoder_input_embeds, encoder_attention_mask, decoder_input_embeds, prediction_id, poly_flag, attribution_flags)\u001b[0m\n\u001b[1;32m    143\u001b[0m     forward_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoly_flag\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpoly_flag\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mtile(\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Add attribution scores to self.attributions\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributions[attr_method]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 146\u001b[0m     \u001b[43mcompute_primary_attributions_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattr_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattr_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforward_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforward_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_id\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    152\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/ecco/attribution.py:101\u001b[0m, in \u001b[0;36mcompute_primary_attributions_scores\u001b[0;34m(attr_method, model, forward_kwargs, prediction_id, aggregation)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo implementation found for primary attribution method \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease choose one of the methods: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(ATTR_NAME_TO_CLASS\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m    100\u001b[0m ig \u001b[38;5;241m=\u001b[39m attr_method_class(forward_func\u001b[38;5;241m=\u001b[39mforward_func)\n\u001b[0;32m--> 101\u001b[0m attributions \u001b[38;5;241m=\u001b[39m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Does it make sense to concatenate encoder and decoder attributions before normalization?\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# We assume that the encoder/decoder embeddings are the same\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalize_attributes(torch\u001b[38;5;241m.\u001b[39mcat(attributions, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/log/__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/attr/_core/integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m         num_examples,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    284\u001b[0m     )\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[1;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/attr/_core/integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[1;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[1;32m    364\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/_utils/gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/_utils/common.py:536\u001b[0m, in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    529\u001b[0m additional_forward_args \u001b[38;5;241m=\u001b[39m _format_additional_forward_args(additional_forward_args)\n\u001b[1;32m    531\u001b[0m output \u001b[38;5;241m=\u001b[39m forward_func(\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39madditional_forward_args)\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m additional_forward_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m inputs\n\u001b[1;32m    535\u001b[0m )\n\u001b[0;32m--> 536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_select_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/loop/lib/python3.9/site-packages/captum/_utils/common.py:586\u001b[0m, in \u001b[0;36m_select_targets\u001b[0;34m(output, target)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _verify_select_column(output, target)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnumel(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    587\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _verify_select_column(output, cast(\u001b[38;5;28mint\u001b[39m, target\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mnumel(target) \u001b[38;5;241m==\u001b[39m num_examples:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_res = {'base':{0:[], 1:[]},'polypers':{0:[], 1:[]}}\n",
    "for i in [66, 80, 97]:\n",
    "    for t in ['polypers']:\n",
    "        for flag in [0,1]:\n",
    "            text = dif_df[t][i]\n",
    "            # text = '   ,  .'\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")\n",
    "            # inputs[\"poly_flag\"] = torch.tensor([flag])\n",
    "\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "# model.to(device)\n",
    "            out = ecco_model(inputs,attribution=['ig'])\n",
    "            max_res[t][flag].append(out)\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_p = dif_df['polypers'][0]\n",
    "text_b = dif_df['base'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>base</th>\n",
       "      <th>polypers</th>\n",
       "      <th>was_changed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td> ,  ,    .</td>\n",
       "      <td> ,  ,    .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>       , ...</td>\n",
       "      <td>       , ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>   ,   ,   ...</td>\n",
       "      <td>   ,   ,   ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>     .</td>\n",
       "      <td>     .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>   ,  .</td>\n",
       "      <td>   ,  .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>9981</td>\n",
       "      <td>  ,    ,    ...</td>\n",
       "      <td>  ,    ,    ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>9982</td>\n",
       "      <td>        ,  , ...</td>\n",
       "      <td>        , ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>9983</td>\n",
       "      <td>        .</td>\n",
       "      <td>        .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>9984</td>\n",
       "      <td>     .</td>\n",
       "      <td>     .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>9999</td>\n",
       "      <td> ,     ...</td>\n",
       "      <td> ,     ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2576 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               base  \\\n",
       "0         0          ,  ,    .   \n",
       "1         3         , ...   \n",
       "2         6     ,   ,   ...   \n",
       "3         7                            .   \n",
       "4         8                           ,  .   \n",
       "...     ...                                                ...   \n",
       "2571   9981    ,    ,    ...   \n",
       "2572   9982          ,  , ...   \n",
       "2573   9983                 .   \n",
       "2574   9984             .   \n",
       "2575   9999   ,     ...   \n",
       "\n",
       "                                               polypers  was_changed  \n",
       "0           ,  ,    .         True  \n",
       "1            , ...         True  \n",
       "2        ,   ,   ...         True  \n",
       "3                             .         True  \n",
       "4                           ,  .         True  \n",
       "...                                                 ...          ...  \n",
       "2571    ,    ,    ...         True  \n",
       "2572          , ...         True  \n",
       "2573               .         True  \n",
       "2574           .         True  \n",
       "2575   ,     ...         True  \n",
       "\n",
       "[2576 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n\n\n            let pred = new ecco.LayerPredictions({\n                parentDiv: viz_id,\n                data:[[{\"token\": \".\", \"prob\": \"0.19145598\", \"ranking\": 1, \"layer\": 0}, {\"token\": \"'\", \"prob\": \"0.030898158\", \"ranking\": 2, \"layer\": 0}, {\"token\": \"\\u0441\\u0435\\u043b\\u0438\\u0442\\u0440\\u044b\", \"prob\": \"0.015933277\", \"ranking\": 3, \"layer\": 0}, {\"token\": \"\\u043f\\u0440\\u043e\\u0442\\u0438\\u0432\\u043e\\u0434\\u0435\\u0439\\u0441\\u0442\\u0432\\u0438\\u044f\", \"prob\": \"0.008848605\", \"ranking\": 4, \"layer\": 0}, {\"token\": \"\\u041e\\u043b\\u044c\\u0433\\u043e\\u0439\", \"prob\": \"0.008453569\", \"ranking\": 5, \"layer\": 0}], [{\"token\": \".\", \"prob\": \"0.05974378\", \"ranking\": 1, \"layer\": 1}, {\"token\": \"\\u043d\\u0430\\u0431\\u043b\\u044e\\u0434\\u0430\\u0442\\u0435\\u043b\\u044f\\u043c\\u0438\", \"prob\": \"0.006491515\", \"ranking\": 2, \"layer\": 1}, {\"token\": \"\\u041c\\u0435\\u0442\\u0430\\u043b\\u043b\\u043e\", \"prob\": \"0.0058675963\", \"ranking\": 3, \"layer\": 1}, {\"token\": \"\\u0443\\u043a\\u0430\\u0437\\u044b\\u0432\\u0430\\u044e\\u0449\\u0438\\u0435\", \"prob\": \"0.0047387066\", \"ranking\": 4, \"layer\": 1}, {\"token\": \"\\u043a\\u0440\\u0438\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u0433\\u043e\", \"prob\": \"0.0045527564\", \"ranking\": 5, \"layer\": 1}], [{\"token\": \".\", \"prob\": \"0.018940745\", \"ranking\": 1, \"layer\": 2}, {\"token\": \"\\u0440\\u0430\\u0437\\u043d\", \"prob\": \"0.006309468\", \"ranking\": 2, \"layer\": 2}, {\"token\": \"\\u0437\\u0430\\u0433\", \"prob\": \"0.0052427957\", \"ranking\": 3, \"layer\": 2}, {\"token\": \"\\u0418\\u043d\\u0442\\u0435\\u0440\\u043d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u0430\", \"prob\": \"0.004712288\", \"ranking\": 4, \"layer\": 2}, {\"token\": \"\\u0441\\u0440\\u0435\\u0434\\u043d\\u0435\", \"prob\": \"0.004553224\", \"ranking\": 5, \"layer\": 2}], [{\"token\": \"##\\u0435\\u0439\\u0441\\u043a\\u043e\\u043c\", \"prob\": \"0.01282765\", \"ranking\": 1, \"layer\": 3}, {\"token\": \"\\u0418\\u043d\\u0442\\u0435\\u0440\\u043d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u0430\", \"prob\": \"0.012351628\", \"ranking\": 2, \"layer\": 3}, {\"token\": \"\\u041a\\u0430\\u043c\\u044b\\u0448\\u0438\\u043d\\u0441\\u043a\\u043e\\u0433\\u043e\", \"prob\": \"0.012232702\", \"ranking\": 3, \"layer\": 3}, {\"token\": \"\\u043d\\u0430\\u0431\\u0440\\u043e\", \"prob\": \"0.010539025\", \"ranking\": 4, \"layer\": 3}, {\"token\": \"\\u041c\\u0435\\u0442\\u0430\\u043b\\u043b\\u043e\", \"prob\": \"0.009247316\", \"ranking\": 5, \"layer\": 3}], [{\"token\": \"\\u043f\\u043e\\u0434\\u043f\\u0438\\u0441\\u043a\\u043e\\u0439\", \"prob\": \"0.021741923\", \"ranking\": 1, \"layer\": 4}, {\"token\": \"\\u0418\\u043d\\u0442\\u0435\\u0440\\u043d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u0430\", \"prob\": \"0.008868724\", \"ranking\": 2, \"layer\": 4}, {\"token\": \"\\u041c\\u0435\\u0442\\u0430\\u043b\\u043b\\u043e\", \"prob\": \"0.0077229305\", \"ranking\": 3, \"layer\": 4}, {\"token\": \"\\u0440\\u043e\\u043b\\u0435\\u0432\\u044b\\u0445\", \"prob\": \"0.0075952113\", \"ranking\": 4, \"layer\": 4}, {\"token\": \"Fac\", \"prob\": \"0.0067989277\", \"ranking\": 5, \"layer\": 4}], [{\"token\": \"\\u043f\\u043e\\u0434\\u043f\\u0438\\u0441\\u043a\\u043e\\u0439\", \"prob\": \"0.008865799\", \"ranking\": 1, \"layer\": 5}, {\"token\": \"\\u041c\\u0435\\u0442\\u0430\\u043b\\u043b\\u043e\", \"prob\": \"0.00784996\", \"ranking\": 2, \"layer\": 5}, {\"token\": \"\\u041d\\u0430\\u0440\\u0432\\u044b\", \"prob\": \"0.007017084\", \"ranking\": 3, \"layer\": 5}, {\"token\": \"\\u0438\\u0434\\u0435\\u043d\\u0442\", \"prob\": \"0.0063409363\", \"ranking\": 4, \"layer\": 5}, {\"token\": \"\\u043d\\u0430\\u0437\\u0435\\u043c\\u043d\\u0430\\u044f\", \"prob\": \"0.005515619\", \"ranking\": 5, \"layer\": 5}], [{\"token\": \"\\u0432\\u043e\\u0441\\u043f\\u0440\\u0435\\u043f\\u044f\\u0442\", \"prob\": \"0.02306527\", \"ranking\": 1, \"layer\": 6}, {\"token\": \"\\u043f\\u0435\\u0440\\u0435\\u0444\\u043e\\u0440\\u043c\", \"prob\": \"0.0123236235\", \"ranking\": 2, \"layer\": 6}, {\"token\": \"\\u0434\\u0435\\u043a\\u043b\\u0430\", \"prob\": \"0.0078208605\", \"ranking\": 3, \"layer\": 6}, {\"token\": \"\\u0414\\u0436\\u0430\\u0432\\u0430\\u0445\", \"prob\": \"0.0067794695\", \"ranking\": 4, \"layer\": 6}, {\"token\": \"\\u043d\\u0430\\u0437\\u0435\\u043c\\u043d\\u0430\\u044f\", \"prob\": \"0.0067356345\", \"ranking\": 5, \"layer\": 6}], [{\"token\": \"\\u0434\\u0435\\u043a\\u043b\\u0430\", \"prob\": \"0.035528675\", \"ranking\": 1, \"layer\": 7}, {\"token\": \"\\u0418\\u0442\\u0430\\u043d\", \"prob\": \"0.022427537\", \"ranking\": 2, \"layer\": 7}, {\"token\": \"\\u043f\\u0440\\u043e\\u0442\\u0438\\u0432\\u043e\\u0437\", \"prob\": \"0.021320002\", \"ranking\": 3, \"layer\": 7}, {\"token\": \"\\u0432\\u043e\\u0441\\u043f\\u0440\\u0435\\u043f\\u044f\\u0442\", \"prob\": \"0.016895903\", \"ranking\": 4, \"layer\": 7}, {\"token\": \"\\u043c\\u0430\\u0442\\u0435\\u0440\\u0438\\u043d\\u0441\\u0442\\u0432\\u0430\", \"prob\": \"0.007847903\", \"ranking\": 5, \"layer\": 7}], [{\"token\": \"\\u043f\\u0440\\u043e\\u0442\\u0438\\u0432\\u043e\\u0437\", \"prob\": \"0.011941634\", \"ranking\": 1, \"layer\": 8}, {\"token\": \"\\u0434\\u0435\\u043a\\u043b\\u0430\", \"prob\": \"0.011483272\", \"ranking\": 2, \"layer\": 8}, {\"token\": \"\\u043f\\u0440\\u0435\\u0434\\u0440\\u0430\\u0441\\u043f\", \"prob\": \"0.009791168\", \"ranking\": 3, \"layer\": 8}, {\"token\": \"\\u0418\\u0442\\u0430\\u043d\", \"prob\": \"0.009267007\", \"ranking\": 4, \"layer\": 8}, {\"token\": \"\\u0437\\u043b\\u043e\\u0442\", \"prob\": \"0.0066580414\", \"ranking\": 5, \"layer\": 8}], [{\"token\": \"\\u043f\\u0440\\u0435\\u0434\\u0440\\u0430\\u0441\\u043f\", \"prob\": \"0.026054468\", \"ranking\": 1, \"layer\": 9}, {\"token\": \"\\u0437\\u043b\\u043e\\u0442\", \"prob\": \"0.0046140165\", \"ranking\": 2, \"layer\": 9}, {\"token\": \"\\u0418\\u0433\\u043b\\u0430\", \"prob\": \"0.0045726597\", \"ranking\": 3, \"layer\": 9}, {\"token\": \"\\u0422\\u0438\\u0445\\u043e\\u043d\\u0430\", \"prob\": \"0.0045036697\", \"ranking\": 4, \"layer\": 9}, {\"token\": \"\\u043e\\u0431\\u0438\\u0445\", \"prob\": \"0.004429177\", \"ranking\": 5, \"layer\": 9}], [{\"token\": \"\\u043f\\u0440\\u0435\\u0434\\u0440\\u0430\\u0441\\u043f\", \"prob\": \"0.049872257\", \"ranking\": 1, \"layer\": 10}, {\"token\": \"\\u0422\\u0438\\u0445\\u043e\\u043d\\u0430\", \"prob\": \"0.009401503\", \"ranking\": 2, \"layer\": 10}, {\"token\": \"\\u0418\\u0433\\u043b\\u0430\", \"prob\": \"0.008118844\", \"ranking\": 3, \"layer\": 10}, {\"token\": \"\\u0418\\u043d\\u0442\\u0435\\u0440\\u043d\\u0430\\u0446\\u0438\\u043e\\u043d\\u0430\\u043b\\u0430\", \"prob\": \"0.0059129763\", \"ranking\": 4, \"layer\": 10}, {\"token\": \"##\\u0440\\u043e\\u0440\\u0430\", \"prob\": \"0.004875166\", \"ranking\": 5, \"layer\": 10}], [{\"token\": \"\\u043d\\u0435\\u0434\\u043e\", \"prob\": \"0.49055016\", \"ranking\": 1, \"layer\": 11}, {\"token\": \"\\u043f\\u0440\\u043e\\u043c\\u043e\", \"prob\": \"0.14155357\", \"ranking\": 2, \"layer\": 11}, {\"token\": \"\\u0431\\u044b\\u0441\\u0442\\u0440\\u043e\", \"prob\": \"0.07143499\", \"ranking\": 3, \"layer\": 11}, {\"token\": \"\\u043f\\u0440\\u043e\\u0448\", \"prob\": \"0.069678195\", \"ranking\": 4, \"layer\": 11}, {\"token\": \"\\u0432\\u043d\\u0438\\u043c\\u0430\\u0442\\u0435\\u043b\\u044c\\u043d\\u043e\", \"prob\": \"0.058177963\", \"ranking\": 5, \"layer\": 11}]]\n            })\n            pred.init()\n         }, function (err) {\n            console.log(viz_id, err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'token': '.', 'prob': '0.19145598', 'ranking': 1, 'layer': 0}, {'token': \"'\", 'prob': '0.030898158', 'ranking': 2, 'layer': 0}, {'token': '', 'prob': '0.015933277', 'ranking': 3, 'layer': 0}, {'token': '', 'prob': '0.008848605', 'ranking': 4, 'layer': 0}, {'token': '', 'prob': '0.008453569', 'ranking': 5, 'layer': 0}], [{'token': '.', 'prob': '0.05974378', 'ranking': 1, 'layer': 1}, {'token': '', 'prob': '0.006491515', 'ranking': 2, 'layer': 1}, {'token': '', 'prob': '0.0058675963', 'ranking': 3, 'layer': 1}, {'token': '', 'prob': '0.0047387066', 'ranking': 4, 'layer': 1}, {'token': '', 'prob': '0.0045527564', 'ranking': 5, 'layer': 1}], [{'token': '.', 'prob': '0.018940745', 'ranking': 1, 'layer': 2}, {'token': '', 'prob': '0.006309468', 'ranking': 2, 'layer': 2}, {'token': '', 'prob': '0.0052427957', 'ranking': 3, 'layer': 2}, {'token': '', 'prob': '0.004712288', 'ranking': 4, 'layer': 2}, {'token': '', 'prob': '0.004553224', 'ranking': 5, 'layer': 2}], [{'token': '##', 'prob': '0.01282765', 'ranking': 1, 'layer': 3}, {'token': '', 'prob': '0.012351628', 'ranking': 2, 'layer': 3}, {'token': '', 'prob': '0.012232702', 'ranking': 3, 'layer': 3}, {'token': '', 'prob': '0.010539025', 'ranking': 4, 'layer': 3}, {'token': '', 'prob': '0.009247316', 'ranking': 5, 'layer': 3}], [{'token': '', 'prob': '0.021741923', 'ranking': 1, 'layer': 4}, {'token': '', 'prob': '0.008868724', 'ranking': 2, 'layer': 4}, {'token': '', 'prob': '0.0077229305', 'ranking': 3, 'layer': 4}, {'token': '', 'prob': '0.0075952113', 'ranking': 4, 'layer': 4}, {'token': 'Fac', 'prob': '0.0067989277', 'ranking': 5, 'layer': 4}], [{'token': '', 'prob': '0.008865799', 'ranking': 1, 'layer': 5}, {'token': '', 'prob': '0.00784996', 'ranking': 2, 'layer': 5}, {'token': '', 'prob': '0.007017084', 'ranking': 3, 'layer': 5}, {'token': '', 'prob': '0.0063409363', 'ranking': 4, 'layer': 5}, {'token': '', 'prob': '0.005515619', 'ranking': 5, 'layer': 5}], [{'token': '', 'prob': '0.02306527', 'ranking': 1, 'layer': 6}, {'token': '', 'prob': '0.0123236235', 'ranking': 2, 'layer': 6}, {'token': '', 'prob': '0.0078208605', 'ranking': 3, 'layer': 6}, {'token': '', 'prob': '0.0067794695', 'ranking': 4, 'layer': 6}, {'token': '', 'prob': '0.0067356345', 'ranking': 5, 'layer': 6}], [{'token': '', 'prob': '0.035528675', 'ranking': 1, 'layer': 7}, {'token': '', 'prob': '0.022427537', 'ranking': 2, 'layer': 7}, {'token': '', 'prob': '0.021320002', 'ranking': 3, 'layer': 7}, {'token': '', 'prob': '0.016895903', 'ranking': 4, 'layer': 7}, {'token': '', 'prob': '0.007847903', 'ranking': 5, 'layer': 7}], [{'token': '', 'prob': '0.011941634', 'ranking': 1, 'layer': 8}, {'token': '', 'prob': '0.011483272', 'ranking': 2, 'layer': 8}, {'token': '', 'prob': '0.009791168', 'ranking': 3, 'layer': 8}, {'token': '', 'prob': '0.009267007', 'ranking': 4, 'layer': 8}, {'token': '', 'prob': '0.0066580414', 'ranking': 5, 'layer': 8}], [{'token': '', 'prob': '0.026054468', 'ranking': 1, 'layer': 9}, {'token': '', 'prob': '0.0046140165', 'ranking': 2, 'layer': 9}, {'token': '', 'prob': '0.0045726597', 'ranking': 3, 'layer': 9}, {'token': '', 'prob': '0.0045036697', 'ranking': 4, 'layer': 9}, {'token': '', 'prob': '0.004429177', 'ranking': 5, 'layer': 9}], [{'token': '', 'prob': '0.049872257', 'ranking': 1, 'layer': 10}, {'token': '', 'prob': '0.009401503', 'ranking': 2, 'layer': 10}, {'token': '', 'prob': '0.008118844', 'ranking': 3, 'layer': 10}, {'token': '', 'prob': '0.0059129763', 'ranking': 4, 'layer': 10}, {'token': '##', 'prob': '0.004875166', 'ranking': 5, 'layer': 10}], [{'token': '', 'prob': '0.49055016', 'ranking': 1, 'layer': 11}, {'token': '', 'prob': '0.14155357', 'ranking': 2, 'layer': 11}, {'token': '', 'prob': '0.07143499', 'ranking': 3, 'layer': 11}, {'token': '', 'prob': '0.069678195', 'ranking': 4, 'layer': 11}, {'token': '', 'prob': '0.058177963', 'ranking': 5, 'layer': 11}]]\n",
      "[[{'token': '.', 'prob': '0.19145598', 'ranking': 1, 'layer': 0}, {'token': \"'\", 'prob': '0.030898158', 'ranking': 2, 'layer': 0}, {'token': '', 'prob': '0.015933277', 'ranking': 3, 'layer': 0}, {'token': '', 'prob': '0.008848605', 'ranking': 4, 'layer': 0}, {'token': '', 'prob': '0.008453569', 'ranking': 5, 'layer': 0}], [{'token': '.', 'prob': '0.05974378', 'ranking': 1, 'layer': 1}, {'token': '', 'prob': '0.006491515', 'ranking': 2, 'layer': 1}, {'token': '', 'prob': '0.0058675963', 'ranking': 3, 'layer': 1}, {'token': '', 'prob': '0.0047387066', 'ranking': 4, 'layer': 1}, {'token': '', 'prob': '0.0045527564', 'ranking': 5, 'layer': 1}], [{'token': '.', 'prob': '0.018940745', 'ranking': 1, 'layer': 2}, {'token': '', 'prob': '0.006309468', 'ranking': 2, 'layer': 2}, {'token': '', 'prob': '0.0052427957', 'ranking': 3, 'layer': 2}, {'token': '', 'prob': '0.004712288', 'ranking': 4, 'layer': 2}, {'token': '', 'prob': '0.004553224', 'ranking': 5, 'layer': 2}], [{'token': '##', 'prob': '0.01282765', 'ranking': 1, 'layer': 3}, {'token': '', 'prob': '0.012351628', 'ranking': 2, 'layer': 3}, {'token': '', 'prob': '0.012232702', 'ranking': 3, 'layer': 3}, {'token': '', 'prob': '0.010539025', 'ranking': 4, 'layer': 3}, {'token': '', 'prob': '0.009247316', 'ranking': 5, 'layer': 3}], [{'token': '', 'prob': '0.021741923', 'ranking': 1, 'layer': 4}, {'token': '', 'prob': '0.008868724', 'ranking': 2, 'layer': 4}, {'token': '', 'prob': '0.0077229305', 'ranking': 3, 'layer': 4}, {'token': '', 'prob': '0.0075952113', 'ranking': 4, 'layer': 4}, {'token': 'Fac', 'prob': '0.0067989277', 'ranking': 5, 'layer': 4}], [{'token': '', 'prob': '0.008865799', 'ranking': 1, 'layer': 5}, {'token': '', 'prob': '0.00784996', 'ranking': 2, 'layer': 5}, {'token': '', 'prob': '0.007017084', 'ranking': 3, 'layer': 5}, {'token': '', 'prob': '0.0063409363', 'ranking': 4, 'layer': 5}, {'token': '', 'prob': '0.005515619', 'ranking': 5, 'layer': 5}], [{'token': '', 'prob': '0.02306527', 'ranking': 1, 'layer': 6}, {'token': '', 'prob': '0.0123236235', 'ranking': 2, 'layer': 6}, {'token': '', 'prob': '0.0078208605', 'ranking': 3, 'layer': 6}, {'token': '', 'prob': '0.0067794695', 'ranking': 4, 'layer': 6}, {'token': '', 'prob': '0.0067356345', 'ranking': 5, 'layer': 6}], [{'token': '', 'prob': '0.035528675', 'ranking': 1, 'layer': 7}, {'token': '', 'prob': '0.022427537', 'ranking': 2, 'layer': 7}, {'token': '', 'prob': '0.021320002', 'ranking': 3, 'layer': 7}, {'token': '', 'prob': '0.016895903', 'ranking': 4, 'layer': 7}, {'token': '', 'prob': '0.007847903', 'ranking': 5, 'layer': 7}], [{'token': '', 'prob': '0.011941634', 'ranking': 1, 'layer': 8}, {'token': '', 'prob': '0.011483272', 'ranking': 2, 'layer': 8}, {'token': '', 'prob': '0.009791168', 'ranking': 3, 'layer': 8}, {'token': '', 'prob': '0.009267007', 'ranking': 4, 'layer': 8}, {'token': '', 'prob': '0.0066580414', 'ranking': 5, 'layer': 8}], [{'token': '', 'prob': '0.026054468', 'ranking': 1, 'layer': 9}, {'token': '', 'prob': '0.0046140165', 'ranking': 2, 'layer': 9}, {'token': '', 'prob': '0.0045726597', 'ranking': 3, 'layer': 9}, {'token': '', 'prob': '0.0045036697', 'ranking': 4, 'layer': 9}, {'token': '', 'prob': '0.004429177', 'ranking': 5, 'layer': 9}], [{'token': '', 'prob': '0.049872257', 'ranking': 1, 'layer': 10}, {'token': '', 'prob': '0.009401503', 'ranking': 2, 'layer': 10}, {'token': '', 'prob': '0.008118844', 'ranking': 3, 'layer': 10}, {'token': '', 'prob': '0.0059129763', 'ranking': 4, 'layer': 10}, {'token': '##', 'prob': '0.004875166', 'ranking': 5, 'layer': 10}], [{'token': '', 'prob': '0.49055016', 'ranking': 1, 'layer': 11}, {'token': '', 'prob': '0.14155357', 'ranking': 2, 'layer': 11}, {'token': '', 'prob': '0.07143499', 'ranking': 3, 'layer': 11}, {'token': '', 'prob': '0.069678195', 'ranking': 4, 'layer': 11}, {'token': '', 'prob': '0.058177963', 'ranking': 5, 'layer': 11}]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# res_n.append((pinfl==a[-1]['l_d'][-1]['token'], a))\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m res_r\u001b[38;5;241m.\u001b[39mappend([la[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoi\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m la \u001b[38;5;129;01min\u001b[39;00m a])\n\u001b[1;32m     33\u001b[0m res_p\u001b[38;5;241m.\u001b[39mappend([la[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoi\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m la \u001b[38;5;129;01min\u001b[39;00m a])\n\u001b[1;32m     34\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "Cell \u001b[0;32mIn[13], line 32\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# res_n.append((pinfl==a[-1]['l_d'][-1]['token'], a))\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m res_r\u001b[38;5;241m.\u001b[39mappend([\u001b[43mla\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m la \u001b[38;5;129;01min\u001b[39;00m a])\n\u001b[1;32m     33\u001b[0m res_p\u001b[38;5;241m.\u001b[39mappend([la[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoi\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m la \u001b[38;5;129;01min\u001b[39;00m a])\n\u001b[1;32m     34\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "res_n = []\n",
    "res_p = []\n",
    "res_r = []\n",
    "for i in range(2000):\n",
    "    if True:\n",
    "        if True:\n",
    "            flag =1\n",
    "            SEQ_LEN=64\n",
    "            text_p = dif_df['polypers'][i]\n",
    "            text_b = dif_df['base'][i]\n",
    "            # text = '   ,  .'\n",
    "            inputs = tokenizer(text_p, return_tensors=\"pt\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")\n",
    "            # inputs[\"poly_flag\"] = torch.tensor([flag])\n",
    "            p_toks = tokenizer(text_p, return_tensors=\"np\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")['input_ids'][0]\n",
    "            b_toks = tokenizer(text_b, return_tensors=\"np\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")['input_ids'][0]\n",
    "            c = np.argwhere(p_toks[:min(p_toks.shape[0], b_toks.shape[0])]!=b_toks[:min(p_toks.shape[0], b_toks.shape[0])])\n",
    "            if len(c):\n",
    "                c=c[0][0]\n",
    "            else:\n",
    "                continue\n",
    "            pid = inputs['input_ids'][0][c].item()\n",
    "            pinfl = tokenizer.convert_ids_to_tokens(pid)\n",
    "            inputs['input_ids'][0][c] = 103\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "# model.to(device)\n",
    "            out = ecco_model(inputs,attribution=['ig'])\n",
    "            SEQ_LEN=1\n",
    "            \n",
    "            a = out.layer_predictions(position=c, topk=5,printJson=True, toi=pid)\n",
    "            print(a)\n",
    "            # res_n.append((pinfl==a[-1]['l_d'][-1]['token'], a))\n",
    "            res_r.append([la['toi']['rank'] for la in a])\n",
    "            res_p.append([la['toi']['prob'] for la in a])\n",
    "            torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,  ,    .\n",
      " ,  ,    .\n",
      "------\n",
      "       , -  .\n",
      "       , -  .\n",
      "------\n",
      "   ,   ,    ,    ,          .\n",
      "   ,   ,    ,    ,          .\n",
      "------\n",
      "     .\n",
      "     .\n",
      "------\n",
      "   ,  .\n",
      "   ,  .\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    if True:\n",
    "        if True:\n",
    "            flag =1\n",
    "            SEQ_LEN=64\n",
    "            text_p = dif_df['polypers'][i]\n",
    "            text_b = dif_df['base'][i]\n",
    "            # text = '   ,  .'\n",
    "            inputs = tokenizer(text_p, return_tensors=\"pt\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")\n",
    "            # inputs[\"poly_flag\"] = torch.tensor([flag])\n",
    "            print(text_p)\n",
    "            print(text_b)\n",
    "            print('------')\n",
    "            # p_toks = tokenizer(text_p, return_tensors=\"np\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")['input_ids'][0]\n",
    "            # b_toks = tokenizer(text_b, return_tensors=\"np\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")['input_ids'][0]\n",
    "            # c = np.argwhere(p_toks[:min(p_toks.shape[0], b_toks.shape[0])]!=b_toks[:min(p_toks.shape[0], b_toks.shape[0])])\n",
    "            # if len(c):\n",
    "            #     c=c[0][0]\n",
    "            # else:\n",
    "            #     continue\n",
    "            # pid = inputs['input_ids'][0][c].item()\n",
    "            # pinfl = tokenizer.convert_ids_to_tokens(pid)\n",
    "            # inputs['input_ids'][0][c] = 103\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.layer_predictions(position=c, topk=5, poly_flag=inputs[\"poly_flag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_0 = [res_l['polypers'][0][i][0] for i in range(len(res_l['polypers'][0]))]\n",
    "cor_1 = [res_l['polypers'][1][i][0] for i in range(len(res_l['polypers'][1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cor_0), sum(cor_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr0 = np.array(list(map(lambda x: float(x[1][-1][0]['prob']), res_l['polypers'][0])))[cor_0]\n",
    "pr1 = np.array(list(map(lambda x: float(x[1][-1][0]['prob']), res_l['polypers'][1])))[cor_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flag in [1]:\n",
    "    res_n['polypers'][flag] = res_l['polypers'][flag][100:]\n",
    "    res_l['polypers'][flag] = res_l['polypers'][flag][:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cor_0 = [res_n['polypers'][0][i][0] for i in range(len(res_n['polypers'][0]))]\n",
    "cor_1 = np.array([res_n[i][0] for i in range(len(res_n))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_res = np.array(res_p)\n",
    "r_res = np.array(res_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = {}\n",
    "r['cor_mean_rank'] = r_res[cor_1].mean(axis=0)\n",
    "r['cor_std_rank'] = r_res[cor_1].std(axis=0)\n",
    "r['all_mean_rank'] = r_res.mean(axis=0)\n",
    "r['all_std_rank'] = r_res.std(axis=0)\n",
    "r['cor_mean_prob'] = p_res[cor_1].mean(axis=0)\n",
    "r['cor_std_prob'] = p_res[cor_1].std(axis=0)\n",
    "r['all_mean_prob'] = p_res.mean(axis=0)\n",
    "r['all_std_prob'] = p_res.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df.to_csv('/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/prefix_base_bert_im_head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(tokenizer(text_p, return_tensors=\"np\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")['input_ids'][0]!=\n",
    "tokenizer(text_b, return_tensors=\"np\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")['input_ids'][0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text_p, return_tensors=\"pt\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")\n",
    "# inputs[\"poly_flag\"] = torch.tensor([flag])\n",
    "c = np.argwhere(tokenizer(text_p, return_tensors=\"np\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")['input_ids'][0]!=\n",
    "tokenizer(text_b, return_tensors=\"np\", max_length=SEQ_LEN, truncation=True, padding=\"max_length\")['input_ids'][0])[0][0]\n",
    "pinfl = inputs['input_ids'][0][c]\n",
    "inputs['input_ids'][0][c] = 103\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# model.to(device)\n",
    "out = ecco_model(inputs,attribution=['ig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:6f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_mean_rank</th>\n",
       "      <th>all_std_rank</th>\n",
       "      <th>all_mean_prob</th>\n",
       "      <th>all_std_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63000.150877</td>\n",
       "      <td>31536.996018</td>\n",
       "      <td>2.671966e-07</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83395.175940</td>\n",
       "      <td>26473.905829</td>\n",
       "      <td>2.534479e-07</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73159.558396</td>\n",
       "      <td>32273.455706</td>\n",
       "      <td>1.969689e-06</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67219.399499</td>\n",
       "      <td>32615.288772</td>\n",
       "      <td>3.778360e-06</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59215.248120</td>\n",
       "      <td>31633.501371</td>\n",
       "      <td>5.425694e-06</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77823.788972</td>\n",
       "      <td>26019.991465</td>\n",
       "      <td>1.611569e-07</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93367.026566</td>\n",
       "      <td>23041.292566</td>\n",
       "      <td>1.356274e-07</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>91770.430576</td>\n",
       "      <td>27844.353354</td>\n",
       "      <td>3.659486e-06</td>\n",
       "      <td>0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>91663.088221</td>\n",
       "      <td>26955.874379</td>\n",
       "      <td>1.018121e-06</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>87366.094737</td>\n",
       "      <td>28575.186760</td>\n",
       "      <td>1.217391e-05</td>\n",
       "      <td>0.000487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>88088.721805</td>\n",
       "      <td>29662.028682</td>\n",
       "      <td>1.634364e-05</td>\n",
       "      <td>0.000541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84942.918296</td>\n",
       "      <td>33077.357129</td>\n",
       "      <td>5.105049e-04</td>\n",
       "      <td>0.021919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8447.178446</td>\n",
       "      <td>14535.112474</td>\n",
       "      <td>1.606073e-03</td>\n",
       "      <td>0.026148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    all_mean_rank  all_std_rank  all_mean_prob  all_std_prob\n",
       "0    63000.150877  31536.996018   2.671966e-07      0.000003\n",
       "1    83395.175940  26473.905829   2.534479e-07      0.000002\n",
       "2    73159.558396  32273.455706   1.969689e-06      0.000017\n",
       "3    67219.399499  32615.288772   3.778360e-06      0.000030\n",
       "4    59215.248120  31633.501371   5.425694e-06      0.000068\n",
       "5    77823.788972  26019.991465   1.611569e-07      0.000003\n",
       "6    93367.026566  23041.292566   1.356274e-07      0.000004\n",
       "7    91770.430576  27844.353354   3.659486e-06      0.000132\n",
       "8    91663.088221  26955.874379   1.018121e-06      0.000036\n",
       "9    87366.094737  28575.186760   1.217391e-05      0.000487\n",
       "10   88088.721805  29662.028682   1.634364e-05      0.000541\n",
       "11   84942.918296  33077.357129   5.105049e-04      0.021919\n",
       "12    8447.178446  14535.112474   1.606073e-03      0.026148"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/base_bert_im_head.csv')\n",
    "df[['all_mean_rank','all_std_rank','all_mean_prob','all_std_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_mean_rank</th>\n",
       "      <th>all_std_rank</th>\n",
       "      <th>all_mean_prob</th>\n",
       "      <th>all_std_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15890.737845</td>\n",
       "      <td>28608.112571</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19468.668672</td>\n",
       "      <td>28272.261417</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28159.007519</td>\n",
       "      <td>34318.148815</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19651.222556</td>\n",
       "      <td>30195.350371</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18960.838095</td>\n",
       "      <td>30987.289535</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17221.637594</td>\n",
       "      <td>30539.885033</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16747.040602</td>\n",
       "      <td>29726.562513</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17012.528822</td>\n",
       "      <td>28678.386361</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16493.772431</td>\n",
       "      <td>27986.788810</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18814.284712</td>\n",
       "      <td>30153.862987</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15525.268672</td>\n",
       "      <td>26029.846054</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13401.008521</td>\n",
       "      <td>24390.967117</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31033.679198</td>\n",
       "      <td>34540.555144</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    all_mean_rank  all_std_rank  all_mean_prob  all_std_prob\n",
       "0    15890.737845  28608.112571       0.000084      0.000139\n",
       "1    19468.668672  28272.261417       0.000041      0.000057\n",
       "2    28159.007519  34318.148815       0.000031      0.000040\n",
       "3    19651.222556  30195.350371       0.000040      0.000042\n",
       "4    18960.838095  30987.289535       0.000056      0.000072\n",
       "5    17221.637594  30539.885033       0.000074      0.000111\n",
       "6    16747.040602  29726.562513       0.000089      0.000138\n",
       "7    17012.528822  28678.386361       0.000106      0.000183\n",
       "8    16493.772431  27986.788810       0.000097      0.000177\n",
       "9    18814.284712  30153.862987       0.000079      0.000133\n",
       "10   15525.268672  26029.846054       0.000078      0.000119\n",
       "11   13401.008521  24390.967117       0.000091      0.000161\n",
       "12   31033.679198  34540.555144       0.000036      0.000072"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/modular_lm_4_2_1_im_head.csv')\n",
    "df[['all_mean_rank','all_std_rank','all_mean_prob','all_std_prob']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4542905665078853, 9.617506783722675, 6.0860470126314485, 2.3338655801807726, 0.3987288011512308, 1.0233855062511767, 2.585716581882657, 1.0785654653827605, 1.8253458360007202, 0.8923925657904276, 0.8304014225898683, 2.47324853687422]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cor_mean_rank</th>\n",
       "      <th>all_mean_rank</th>\n",
       "      <th>cor_mean_prob</th>\n",
       "      <th>all_mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>612.883362</td>\n",
       "      <td>8067.939850</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.001516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>955.152659</td>\n",
       "      <td>9495.934336</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.000689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203.120069</td>\n",
       "      <td>5496.289223</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>0.006625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.506861</td>\n",
       "      <td>3712.490226</td>\n",
       "      <td>0.061031</td>\n",
       "      <td>0.040317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.050600</td>\n",
       "      <td>2463.094236</td>\n",
       "      <td>0.143150</td>\n",
       "      <td>0.094095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37.969125</td>\n",
       "      <td>3186.336842</td>\n",
       "      <td>0.056518</td>\n",
       "      <td>0.037518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.759005</td>\n",
       "      <td>2114.324812</td>\n",
       "      <td>0.059433</td>\n",
       "      <td>0.038396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.950257</td>\n",
       "      <td>896.506266</td>\n",
       "      <td>0.158131</td>\n",
       "      <td>0.099281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.591767</td>\n",
       "      <td>776.625063</td>\n",
       "      <td>0.168986</td>\n",
       "      <td>0.107081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.902230</td>\n",
       "      <td>542.480702</td>\n",
       "      <td>0.308908</td>\n",
       "      <td>0.195459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.318182</td>\n",
       "      <td>435.128321</td>\n",
       "      <td>0.278686</td>\n",
       "      <td>0.174426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.003431</td>\n",
       "      <td>378.801003</td>\n",
       "      <td>0.231971</td>\n",
       "      <td>0.144844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>459.819048</td>\n",
       "      <td>0.580161</td>\n",
       "      <td>0.358235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cor_mean_rank  all_mean_rank  cor_mean_prob  all_mean_prob\n",
       "0      612.883362    8067.939850       0.002243       0.001516\n",
       "1      955.152659    9495.934336       0.001023       0.000689\n",
       "2      203.120069    5496.289223       0.010160       0.006625\n",
       "3       76.506861    3712.490226       0.061031       0.040317\n",
       "4       20.050600    2463.094236       0.143150       0.094095\n",
       "5       37.969125    3186.336842       0.056518       0.037518\n",
       "6       25.759005    2114.324812       0.059433       0.038396\n",
       "7        3.950257     896.506266       0.158131       0.099281\n",
       "8        5.591767     776.625063       0.168986       0.107081\n",
       "9        1.902230     542.480702       0.308908       0.195459\n",
       "10       2.318182     435.128321       0.278686       0.174426\n",
       "11       2.003431     378.801003       0.231971       0.144844\n",
       "12       1.000000     459.819048       0.580161       0.358235"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/modular_lm_4_2_1_lstm.csv')\n",
    "a = df['all_mean_prob']\n",
    "a = [a[i+1]/a[i] for i in range(len(a)-1)]\n",
    "print(a)\n",
    "\n",
    "df[df.columns[1::2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15382710754514262, 11.834883391705418, 7.614394402004726, 3.4911292590305356, 0.48995138884922745, 2.1746258902969675, 4.3411348150524995, 1.4252215317467598, 1.766972509845081, 0.8927198926060412, 0.8714644386275108, 2.2371332717056323]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cor_mean_rank</th>\n",
       "      <th>all_mean_rank</th>\n",
       "      <th>cor_mean_prob</th>\n",
       "      <th>all_mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>491.551661</td>\n",
       "      <td>10575.542356</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3965.110701</td>\n",
       "      <td>16546.143358</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190.428967</td>\n",
       "      <td>7515.458647</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.000594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.211255</td>\n",
       "      <td>5090.519298</td>\n",
       "      <td>0.007202</td>\n",
       "      <td>0.004519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.074723</td>\n",
       "      <td>3348.921303</td>\n",
       "      <td>0.025493</td>\n",
       "      <td>0.015777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.196494</td>\n",
       "      <td>3814.379449</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.007730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.360701</td>\n",
       "      <td>2351.019549</td>\n",
       "      <td>0.027353</td>\n",
       "      <td>0.016810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.109779</td>\n",
       "      <td>1123.002506</td>\n",
       "      <td>0.117864</td>\n",
       "      <td>0.072975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.011993</td>\n",
       "      <td>916.883208</td>\n",
       "      <td>0.165278</td>\n",
       "      <td>0.104006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.241697</td>\n",
       "      <td>619.264662</td>\n",
       "      <td>0.292520</td>\n",
       "      <td>0.183776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.440037</td>\n",
       "      <td>557.318797</td>\n",
       "      <td>0.270192</td>\n",
       "      <td>0.164060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.350554</td>\n",
       "      <td>481.025063</td>\n",
       "      <td>0.238831</td>\n",
       "      <td>0.142973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>507.163910</td>\n",
       "      <td>0.555139</td>\n",
       "      <td>0.319849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cor_mean_rank  all_mean_rank  cor_mean_prob  all_mean_prob\n",
       "0      491.551661   10575.542356       0.000464       0.000326\n",
       "1     3965.110701   16546.143358       0.000069       0.000050\n",
       "2      190.428967    7515.458647       0.000925       0.000594\n",
       "3       27.211255    5090.519298       0.007202       0.004519\n",
       "4        7.074723    3348.921303       0.025493       0.015777\n",
       "5        9.196494    3814.379449       0.012456       0.007730\n",
       "6        4.360701    2351.019549       0.027353       0.016810\n",
       "7        2.109779    1123.002506       0.117864       0.072975\n",
       "8        2.011993     916.883208       0.165278       0.104006\n",
       "9        1.241697     619.264662       0.292520       0.183776\n",
       "10       1.440037     557.318797       0.270192       0.164060\n",
       "11       1.350554     481.025063       0.238831       0.142973\n",
       "12       1.000000     507.163910       0.555139       0.319849"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/raskind/venv/RMT_interpretation/t5-experiments/analysis_memory/cpts/modular_lm_4_1_im_head.csv')\n",
    "b = df['all_mean_prob']\n",
    "b= [b[i+1]/b[i] for i in range(len(b)-1)]\n",
    "print(b)\n",
    "df[df.columns[1::2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4542905665078853, 9.617506783722675, 6.0860470126314485, 2.3338655801807726, 0.3987288011512308, 1.0233855062511767, 2.585716581882657, 1.0785654653827605, 1.8253458360007202, 0.8923925657904276, 0.8304014225898683, 2.47324853687422]\n",
      "[0.15382710754514262, 11.834883391705418, 7.614394402004726, 3.4911292590305356, 0.48995138884922745, 2.1746258902969675, 4.3411348150524995, 1.4252215317467598, 1.766972509845081, 0.8927198926060412, 0.8714644386275108, 2.2371332717056323]\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n\n\n            let pred = new ecco.LayerPredictions({\n                parentDiv: viz_id,\n                data:[[{\"token\": \".\", \"prob\": \"0.19145598\", \"ranking\": 1, \"layer\": 0}], [{\"token\": \".\", \"prob\": \"0.05974378\", \"ranking\": 1, \"layer\": 1}], [{\"token\": \".\", \"prob\": \"0.018940745\", \"ranking\": 1, \"layer\": 2}], [{\"token\": \"##\\u0435\\u0439\\u0441\\u043a\\u043e\\u043c\", \"prob\": \"0.01282765\", \"ranking\": 1, \"layer\": 3}], [{\"token\": \"\\u043f\\u043e\\u0434\\u043f\\u0438\\u0441\\u043a\\u043e\\u0439\", \"prob\": \"0.021741923\", \"ranking\": 1, \"layer\": 4}], [{\"token\": \"\\u043f\\u043e\\u0434\\u043f\\u0438\\u0441\\u043a\\u043e\\u0439\", \"prob\": \"0.008865799\", \"ranking\": 1, \"layer\": 5}], [{\"token\": \"\\u0432\\u043e\\u0441\\u043f\\u0440\\u0435\\u043f\\u044f\\u0442\", \"prob\": \"0.02306527\", \"ranking\": 1, \"layer\": 6}], [{\"token\": \"\\u0434\\u0435\\u043a\\u043b\\u0430\", \"prob\": \"0.035528675\", \"ranking\": 1, \"layer\": 7}], [{\"token\": \"\\u043f\\u0440\\u043e\\u0442\\u0438\\u0432\\u043e\\u0437\", \"prob\": \"0.011941634\", \"ranking\": 1, \"layer\": 8}], [{\"token\": \"\\u043f\\u0440\\u0435\\u0434\\u0440\\u0430\\u0441\\u043f\", \"prob\": \"0.026054468\", \"ranking\": 1, \"layer\": 9}], [{\"token\": \"\\u043f\\u0440\\u0435\\u0434\\u0440\\u0430\\u0441\\u043f\", \"prob\": \"0.049872257\", \"ranking\": 1, \"layer\": 10}], [{\"token\": \"\\u043d\\u0435\\u0434\\u043e\", \"prob\": \"0.49055016\", \"ranking\": 1, \"layer\": 11}]]\n            })\n            pred.init()\n         }, function (err) {\n            console.log(viz_id, err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'token': '.', 'prob': '0.19145598', 'ranking': 1, 'layer': 0}], [{'token': '.', 'prob': '0.05974378', 'ranking': 1, 'layer': 1}], [{'token': '.', 'prob': '0.018940745', 'ranking': 1, 'layer': 2}], [{'token': '##', 'prob': '0.01282765', 'ranking': 1, 'layer': 3}], [{'token': '', 'prob': '0.021741923', 'ranking': 1, 'layer': 4}], [{'token': '', 'prob': '0.008865799', 'ranking': 1, 'layer': 5}], [{'token': '', 'prob': '0.02306527', 'ranking': 1, 'layer': 6}], [{'token': '', 'prob': '0.035528675', 'ranking': 1, 'layer': 7}], [{'token': '', 'prob': '0.011941634', 'ranking': 1, 'layer': 8}], [{'token': '', 'prob': '0.026054468', 'ranking': 1, 'layer': 9}], [{'token': '', 'prob': '0.049872257', 'ranking': 1, 'layer': 10}], [{'token': '', 'prob': '0.49055016', 'ranking': 1, 'layer': 11}]]\n"
     ]
    }
   ],
   "source": [
    "a = out.layer_predictions(position=c, topk=1, printJson=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n\n            ecco.renderOutputSequence({\n                parentDiv: viz_id,\n                data: {'tokens': [{'token': '[CLS]', 'token_id': 101, 'type': 'input'}, {'token': '', 'token_id': 6654, 'type': 'input'}, {'token': '', 'token_id': 31656, 'type': 'input'}, {'token': '[MASK]', 'token_id': 103, 'type': 'input'}, {'token': '##', 'token_id': 63819, 'type': 'input'}, {'token': '##', 'token_id': 2834, 'type': 'input'}, {'token': '##', 'token_id': 57269, 'type': 'input'}, {'token': ',', 'token_id': 128, 'type': 'input'}, {'token': '', 'token_id': 9537, 'type': 'input'}, {'token': '.', 'token_id': 132, 'type': 'input'}, {'token': '[SEP]', 'token_id': 102, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}, {'token': '[PAD]', 'token_id': 0, 'type': 'input'}]},\n                tokenization_config: \"\"\n            })\n         }, function (err) {\n            console.log(err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<OutputSeq>"
      ],
      "text/plain": [
       "<output.OutputSeq at 0x7faf14a4ce20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n             requirejs(['basic', 'ecco'], function(basic, ecco){\n                const viz_id = basic.init()\n                console.log(viz_id)\n                // ecco.interactiveTokens(viz_id, {})\n                window.ecco[viz_id] = new ecco.MinimalHighlighter({\n                    parentDiv: viz_id,\n                    data: {\"tokens\": [{\"token\": \"[CLS]\", \"token_id\": 101, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0294428160934612\", \"position\": 0}, {\"token\": \"\\u042d\\u0442\\u043e\", \"token_id\": 6654, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.07607014822396746\", \"position\": 1}, {\"token\": \"\\u0442\\u0435\\u0431\\u044f\", \"token_id\": 31656, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.03260596307623999\", \"position\": 2}, {\"token\": \"[MASK]\", \"token_id\": 103, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.016479865628064187\", \"position\": 3}, {\"token\": \"\\u0448\\u044c\", \"token_id\": 63819, \"is_partial\": false, \"type\": \"input\", \"value\": \"0.07673712155616828\", \"position\": 4}, {\"token\": \"\\u0440\\u0430\\u0437\", \"token_id\": 2834, \"is_partial\": false, \"type\": \"input\", \"value\": \"0.11895179553311927\", \"position\": 5}, {\"token\": \"\\u044b\\u0433\\u0440\\u0430\\u043b\\u0438\", \"token_id\": 57269, \"is_partial\": false, \"type\": \"input\", \"value\": \"0.10318504506260065\", \"position\": 6}, {\"token\": \",\", \"token_id\": 128, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.08889688276098177\", \"position\": 7}, {\"token\": \"\\u0431\\u0440\\u0430\\u0442\", \"token_id\": 9537, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.05993679498644235\", \"position\": 8}, {\"token\": \".\", \"token_id\": 132, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.04583968991124159\", \"position\": 9}, {\"token\": \"[SEP]\", \"token_id\": 102, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.057376451628030414\", \"position\": 10}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 11}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 12}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 13}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 14}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 15}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 16}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 17}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 18}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 19}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 20}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 21}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 22}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 23}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 24}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 25}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 26}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 27}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 28}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 29}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 30}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 31}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 32}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 33}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 34}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 35}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 36}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 37}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 38}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 39}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 40}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 41}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 42}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 43}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 44}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 45}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 46}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 47}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 48}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 49}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 50}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 51}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 52}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 53}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 54}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 55}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 56}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 57}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 58}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 59}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 60}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 61}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 62}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 63}], \"attributions\": [[0.0294428160934612, 0.07607014822396746, 0.03260596307623999, 0.016479865628064187, 0.07673712155616828, 0.11895179553311927, 0.10318504506260065, 0.08889688276098177, 0.05993679498644235, 0.04583968991124159, 0.057376451628030414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03165394149542381, 0.09005846017324301, 0.03138901446024844, 0.016697448735192317, 0.07202458438080514, 0.1320424767403851, 0.10068516139592773, 0.07955104015910547, 0.0540981711475391, 0.04061182745310658, 0.056988840499001554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.032962798863726855, 0.08851120060951105, 0.02945379863841034, 0.017886358752793576, 0.06633413961825523, 0.11286896387718572, 0.10569307149872201, 0.08905702457672639, 0.05272162408713168, 0.04110899787532182, 0.059447432307331786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.031256150782788476, 0.09378030985437212, 0.02898215583404124, 0.018240602691686994, 0.07272846111399363, 0.12280571805376862, 0.09886623346874503, 0.07917173103937895, 0.050734191878970436, 0.04231220327873563, 0.05740380066209165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03229774612103173, 0.09346158571145491, 0.02650313765581829, 0.021118906412342403, 0.07009512343526043, 0.13400098454924814, 0.10186795989191941, 0.07973749593623984, 0.046360991842547064, 0.03704122364381902, 0.056773838335877305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04046738276191056, 0.08757321634561734, 0.03362792210911443, 0.025581139725377493, 0.05395216527791636, 0.08475188570737954, 0.09997109076410463, 0.07068510387461047, 0.055268275358895454, 0.04335918736438405, 0.05989918956264675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0294428160934612, 0.07607014822396746, 0.03260596307623999, 0.016479865628064187, 0.07673712155616828, 0.11895179553311927, 0.10318504506260065, 0.08889688276098177, 0.05993679498644235, 0.04583968991124159, 0.057376451628030414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04046738276191056, 0.08757321634561734, 0.03362792210911443, 0.025581139725377493, 0.05395216527791636, 0.08475188570737954, 0.09997109076410463, 0.07068510387461047, 0.055268275358895454, 0.04335918736438405, 0.05989918956264675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03024408975364424, 0.07362743451049326, 0.0269336095758236, 0.014954354379816969, 0.06666057513482249, 0.1235993106354011, 0.11359373975889349, 0.09319816570184261, 0.05883159822591195, 0.045987630357286605, 0.05419271884811447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03045733718703141, 0.03871269696929025, 0.030203681903642417, 0.012626073667994868, 0.059689287018130914, 0.1093595417477713, 0.1128050155898324, 0.0876787719686129, 0.058617920277788026, 0.06388327370119011, 0.09744637207742754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0294428160934612, 0.07607014822396746, 0.03260596307623999, 0.016479865628064187, 0.07673712155616828, 0.11895179553311927, 0.10318504506260065, 0.08889688276098177, 0.05993679498644235, 0.04583968991124159, 0.057376451628030414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]},\n                    preset: 'viridis',\n                    tokenization_config: \"\"\n\n             })\n\n             window.ecco[viz_id].init();\n             window.ecco[viz_id].selectFirstToken();\n\n             }, function (err) {\n                console.log(err);\n            })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out.primary_attributions(attr_method='ig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n             requirejs(['basic', 'ecco'], function(basic, ecco){\n                const viz_id = basic.init()\n                console.log(viz_id)\n                // ecco.interactiveTokens(viz_id, {})\n                window.ecco[viz_id] = new ecco.MinimalHighlighter({\n                    parentDiv: viz_id,\n                    data: {\"tokens\": [{\"token\": \"[CLS]\", \"token_id\": 101, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0294428160934612\", \"position\": 0}, {\"token\": \"\\u042d\\u0442\\u043e\", \"token_id\": 6654, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.07607014822396746\", \"position\": 1}, {\"token\": \"\\u0442\\u0435\\u0431\\u044f\", \"token_id\": 31656, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.03260596307623999\", \"position\": 2}, {\"token\": \"[MASK]\", \"token_id\": 103, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.016479865628064187\", \"position\": 3}, {\"token\": \"\\u0448\\u044c\", \"token_id\": 63819, \"is_partial\": false, \"type\": \"input\", \"value\": \"0.07673712155616828\", \"position\": 4}, {\"token\": \"\\u0440\\u0430\\u0437\", \"token_id\": 2834, \"is_partial\": false, \"type\": \"input\", \"value\": \"0.11895179553311927\", \"position\": 5}, {\"token\": \"\\u044b\\u0433\\u0440\\u0430\\u043b\\u0438\", \"token_id\": 57269, \"is_partial\": false, \"type\": \"input\", \"value\": \"0.10318504506260065\", \"position\": 6}, {\"token\": \",\", \"token_id\": 128, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.08889688276098177\", \"position\": 7}, {\"token\": \"\\u0431\\u0440\\u0430\\u0442\", \"token_id\": 9537, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.05993679498644235\", \"position\": 8}, {\"token\": \".\", \"token_id\": 132, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.04583968991124159\", \"position\": 9}, {\"token\": \"[SEP]\", \"token_id\": 102, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.057376451628030414\", \"position\": 10}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 11}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 12}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 13}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 14}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 15}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 16}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 17}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 18}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 19}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 20}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 21}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 22}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 23}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 24}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 25}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 26}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 27}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 28}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 29}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 30}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 31}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 32}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 33}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 34}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 35}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 36}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 37}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 38}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 39}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 40}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 41}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 42}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 43}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 44}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 45}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 46}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 47}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 48}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 49}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 50}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 51}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 52}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 53}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 54}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 55}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 56}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 57}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 58}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 59}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 60}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 61}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 62}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"input\", \"value\": \"0.0\", \"position\": 63}], \"attributions\": [[0.0294428160934612, 0.07607014822396746, 0.03260596307623999, 0.016479865628064187, 0.07673712155616828, 0.11895179553311927, 0.10318504506260065, 0.08889688276098177, 0.05993679498644235, 0.04583968991124159, 0.057376451628030414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03165394149542381, 0.09005846017324301, 0.03138901446024844, 0.016697448735192317, 0.07202458438080514, 0.1320424767403851, 0.10068516139592773, 0.07955104015910547, 0.0540981711475391, 0.04061182745310658, 0.056988840499001554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.032962798863726855, 0.08851120060951105, 0.02945379863841034, 0.017886358752793576, 0.06633413961825523, 0.11286896387718572, 0.10569307149872201, 0.08905702457672639, 0.05272162408713168, 0.04110899787532182, 0.059447432307331786, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.031256150782788476, 0.09378030985437212, 0.02898215583404124, 0.018240602691686994, 0.07272846111399363, 0.12280571805376862, 0.09886623346874503, 0.07917173103937895, 0.050734191878970436, 0.04231220327873563, 0.05740380066209165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03229774612103173, 0.09346158571145491, 0.02650313765581829, 0.021118906412342403, 0.07009512343526043, 0.13400098454924814, 0.10186795989191941, 0.07973749593623984, 0.046360991842547064, 0.03704122364381902, 0.056773838335877305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04046738276191056, 0.08757321634561734, 0.03362792210911443, 0.025581139725377493, 0.05395216527791636, 0.08475188570737954, 0.09997109076410463, 0.07068510387461047, 0.055268275358895454, 0.04335918736438405, 0.05989918956264675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0294428160934612, 0.07607014822396746, 0.03260596307623999, 0.016479865628064187, 0.07673712155616828, 0.11895179553311927, 0.10318504506260065, 0.08889688276098177, 0.05993679498644235, 0.04583968991124159, 0.057376451628030414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04046738276191056, 0.08757321634561734, 0.03362792210911443, 0.025581139725377493, 0.05395216527791636, 0.08475188570737954, 0.09997109076410463, 0.07068510387461047, 0.055268275358895454, 0.04335918736438405, 0.05989918956264675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03024408975364424, 0.07362743451049326, 0.0269336095758236, 0.014954354379816969, 0.06666057513482249, 0.1235993106354011, 0.11359373975889349, 0.09319816570184261, 0.05883159822591195, 0.045987630357286605, 0.05419271884811447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03045733718703141, 0.03871269696929025, 0.030203681903642417, 0.012626073667994868, 0.059689287018130914, 0.1093595417477713, 0.1128050155898324, 0.0876787719686129, 0.058617920277788026, 0.06388327370119011, 0.09744637207742754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0294428160934612, 0.07607014822396746, 0.03260596307623999, 0.016479865628064187, 0.07673712155616828, 0.11895179553311927, 0.10318504506260065, 0.08889688276098177, 0.05993679498644235, 0.04583968991124159, 0.057376451628030414, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]},\n                    preset: 'viridis',\n                    tokenization_config: \"\"\n\n             })\n\n             window.ecco[viz_id].init();\n             window.ecco[viz_id].selectFirstToken();\n\n             }, function (err) {\n                console.log(err);\n            })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out.primary_attributions(attr_method='ig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    for t in ['base','polypers']:\n",
    "        for flag in [0,1]:\n",
    "            cur = res[t][flag][i]\n",
    "            cur = [attr[:len(cur)] for attr in cur]\n",
    "            res[t][flag][i] = cur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = {'base':[],'polypers':[]}\n",
    "for i in range(100):\n",
    "    for t in ['base','polypers']:\n",
    "        if True:\n",
    "            cur0 = res[t][0][i]\n",
    "            cur1 = res[t][1][i]\n",
    "            cur = [abs(cur0[attr] - cur1[attr]).mean() for attr in range(len(cur0))]\n",
    "            changes[t].append(cur)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   101,    103,  85450,    880,  51296,  16616,   2068,  20181,\n",
       "         1758,  29890,  72838,   3474,  63200,    158,  12798,  46984,\n",
       "       118015,   7404,   3806,    845,  35681,  13534,    326,    132,\n",
       "          103,    102])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('[MASK]'+t+'[MASK]', return_tensors=\"np\", truncation=True)['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = 17\n",
    "t = dif_df['polypers'][s]\n",
    "labs = tokenizer.convert_ids_to_tokens(tokenizer(t, return_tensors=\"np\", truncation=True)['input_ids'][0])\n",
    "sns.heatmap(np.stack(diffs['polypers'][s]), xticklabels=labs, yticklabels=labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00227356, 0.01344133, 0.00087515, ..., 0.00635727, 0.0124331 ,\n",
       "       0.00448852])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(changes['polypers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c = np.concatenate(changes['polypers']) *1000\n",
    "b_c = np.concatenate(changes['base'])* 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113708/2564218624.py:1: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode(p_c).mode[0], p_c.mean(), p_c.std()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.11142514785386724, 0.5839251204423386, 1.3306468820491328)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode(p_c).mode[0], p_c.mean(), p_c.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113708/367906997.py:1: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode(b_c).mode[0], b_c.mean(), b_c.std()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05492227864629867, 0.4800031734785778, 1.2444865735027257)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode(b_c).mode[0], b_c.mean(), b_c.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.vstack([np.pad(p_c[np.argwhere(p_c<1)].reshape(-1,1),((0,0),(0,1)), 'constant', constant_values=(1)),\n",
    "np.pad(b_c[np.argwhere(b_c<1)].reshape(-1,1),((0,0),(0,1)), 'constant', constant_values=(0))]), columns=['val', 'cor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = sns.histplot(data=df, x='val', hue='cor', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.377e+03, 3.420e+02, 1.040e+02, 3.700e+01, 2.200e+01, 1.400e+01,\n",
       "        3.000e+00, 1.000e+01, 6.000e+00, 2.000e+00, 4.000e+00, 1.000e+00,\n",
       "        2.000e+00, 2.000e+00, 3.000e+00, 0.000e+00, 1.000e+00, 3.000e+00,\n",
       "        1.000e+00, 1.000e+00, 1.000e+00, 1.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
       "        0.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 2.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 1.000e+00]),\n",
       " array([1.14118692e-02, 4.87809164e-01, 9.64206458e-01, 1.44060375e+00,\n",
       "        1.91700105e+00, 2.39339834e+00, 2.86979564e+00, 3.34619293e+00,\n",
       "        3.82259022e+00, 4.29898752e+00, 4.77538481e+00, 5.25178211e+00,\n",
       "        5.72817940e+00, 6.20457670e+00, 6.68097399e+00, 7.15737128e+00,\n",
       "        7.63376858e+00, 8.11016587e+00, 8.58656317e+00, 9.06296046e+00,\n",
       "        9.53935776e+00, 1.00157551e+01, 1.04921523e+01, 1.09685496e+01,\n",
       "        1.14449469e+01, 1.19213442e+01, 1.23977415e+01, 1.28741388e+01,\n",
       "        1.33505361e+01, 1.38269334e+01, 1.43033307e+01, 1.47797280e+01,\n",
       "        1.52561253e+01, 1.57325226e+01, 1.62089199e+01, 1.66853172e+01,\n",
       "        1.71617145e+01, 1.76381118e+01, 1.81145091e+01, 1.85909063e+01,\n",
       "        1.90673036e+01, 1.95437009e+01, 2.00200982e+01, 2.04964955e+01,\n",
       "        2.09728928e+01, 2.14492901e+01, 2.19256874e+01, 2.24020847e+01,\n",
       "        2.28784820e+01, 2.33548793e+01, 2.38312766e+01]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(p_c[np.argwhere(p_c<1)], bins=50, color='b')\n",
    "plt.hist(p_c[np.argwhere(b_c<1)], bins=50, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.41051755e-04, -7.04832726e-06,  3.55336308e-05,  3.39554377e-05,\n",
       "       -2.24572580e-05,  6.33666029e-05,  1.61529401e-05, -8.85531356e-04,\n",
       "        1.84473613e-04,  5.25681974e-04,  5.69938476e-04])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.attribution['ig'][0][:11] - out0.attribution['ig'][0][:11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0409113 , 0.02747081, 0.02172472, 0.03666571, 0.02289571,\n",
       "       0.04275521, 0.03420676, 0.15935339, 0.05101077, 0.0662736 ,\n",
       "       0.04833716])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0.attribution['ig'][0][:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['polypers'][0][0].attribution['ig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['base'][0] = res['base'][0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = {'base':{0:[], 1:[]},'polypers':{0:[], 1:[]}}\n",
    "for t in ['base','polypers']:\n",
    "    for flag in [0,1]:\n",
    "        res1[t][flag] = [np.stack(out) for out in res[t][flag]]\n",
    "        # print(len(res[t][flag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1['polypers'][0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = np.vstack(res1['polypers'][0])\n",
    "p1 = np.vstack(res1['polypers'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00020316527857642768, 0.0012820826340480262)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs((p0-p1)).mean(), abs((p0-p1)).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17243157, 0.09544357, 0.09443364, 0.08967682, 0.07503111,\n",
       "       0.07251684, 0.0696497 , 0.06340493, 0.05902478, 0.05416311,\n",
       "       0.05407436, 0.05376127, 0.05344851, 0.05267371, 0.05231038,\n",
       "       0.0522711 , 0.05121176, 0.04355365, 0.04282097, 0.04205654])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(abs(p0-p1).flatten())[::-1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19983199, 0.12897636, 0.03041787, 0.12255545, 0.10503583,\n",
       "       0.13157672, 0.11315736, 0.01101037, 0.20759156, 0.06882063,\n",
       "       0.1315627 , 0.09188041, 0.10799935, 0.10703571, 0.14826825,\n",
       "       0.0685371 , 0.1611104 , 0.07512699, 0.09945709, 0.2376764 ])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0.flatten()[np.argsort(abs(p0-p1).flatten())[::-1][:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02740043, 0.03353279, 0.12485152, 0.03287863, 0.03000472,\n",
       "       0.05905988, 0.04350766, 0.07441529, 0.26661634, 0.01465751,\n",
       "       0.07748833, 0.03811914, 0.05455084, 0.05436201, 0.09595787,\n",
       "       0.1208082 , 0.10989864, 0.03157334, 0.05663612, 0.27973294])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.flatten()[np.argsort(abs(p0-p1).flatten())[::-1][:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_c = np.argsort(abs(p0-p1).flatten())[::-1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 730, 2137,  422, 2137, 2137,  372, 1769, 1479, 1334,  730,  325,\n",
       "       1479, 1769, 1769,  758,  922, 1351, 1479,  220, 1342])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(max_c // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 220,  325,  372,  422,  730,  758,  922, 1334, 1342, 1351, 1479,\n",
       "        1769, 2137]),\n",
       " array([1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 3]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique((max_c // 64), return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = np.cumsum(np.array(list(map(lambda x: x.shape[0], res1['polypers'][0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3, 16])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1479,1769, 2137] - cs[[bisect_left(cs, i)-1 for i in (1479,1769, 2137)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (100,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_res \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mlist\u001b[39m(i\u001b[38;5;241m.\u001b[39mvalues())) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(res1\u001b[38;5;241m.\u001b[39mvalues())]\n",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_res \u001b[38;5;241m=\u001b[39m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(res1\u001b[38;5;241m.\u001b[39mvalues())]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/venv/RMT_interpretation/venv/lib/python3.8/site-packages/numpy/core/shape_base.py:293\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mARRAY_FUNCTION_ENABLED:\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;66;03m# raise warning if necessary\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     _arrays_for_stack_dispatcher(tup, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 293\u001b[0m arrs \u001b[38;5;241m=\u001b[39m \u001b[43matleast_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    295\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36matleast_2d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/venv/RMT_interpretation/venv/lib/python3.8/site-packages/numpy/core/shape_base.py:121\u001b[0m, in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m    119\u001b[0m res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ary \u001b[38;5;129;01min\u001b[39;00m arys:\n\u001b[0;32m--> 121\u001b[0m     ary \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ary\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    123\u001b[0m         result \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (100,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "all_res = [np.vstack(list(i.values())) for i in list(res1.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_diff = all_res[:,0,:,:,:] - all_res[:,1,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12481090223752968"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(flag_diff[1][4][33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out0 = res['base'][1][11]\n",
    "# out1 = res['polypers'][1][11]\n",
    "out0 = max_res['polypers'][0][2]\n",
    "out1 = max_res['polypers'][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "out0.n_input_tokens=0\n",
    "out1.n_input_tokens=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n             requirejs(['basic', 'ecco'], function(basic, ecco){\n                const viz_id = basic.init()\n                console.log(viz_id)\n                // ecco.interactiveTokens(viz_id, {})\n                window.ecco[viz_id] = new ecco.MinimalHighlighter({\n                    parentDiv: viz_id,\n                    data: {\"tokens\": [{\"token\": \"[CLS]\", \"token_id\": 101, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.02181350896851866\", \"position\": 0}, {\"token\": \"\\u041c\\u043d\\u043e\\u0433\\u043e\", \"token_id\": 21956, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.013874906011234828\", \"position\": 1}, {\"token\": \"\\u0445\\u0440\\u0438\\u0441\\u0442\\u0438\\u0430\\u043d\\u0441\\u043a\\u043e\\u0439\", \"token_id\": 33866, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.022882205943039132\", \"position\": 2}, {\"token\": \"\\u043a\\u0440\\u043e\\u0432\\u0438\", \"token_id\": 18531, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.02668839694352416\", \"position\": 3}, {\"token\": \"\\u043f\\u0440\\u043e\\u043b\", \"token_id\": 14441, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.047099916343895286\", \"position\": 4}, {\"token\": \"\\u0438\\u043b\\u0438\", \"token_id\": 2761, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.026560386070625205\", \"position\": 5}, {\"token\": \"\\u0432\\u0430\\u0440\\u0432\\u0430\\u0440\", \"token_id\": 38926, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.02870860116447556\", \"position\": 6}, {\"token\": \"\\u044b\", \"token_id\": 880, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.02295235662310335\", \"position\": 7}, {\"token\": \",\", \"token_id\": 128, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.016096339320416108\", \"position\": 8}, {\"token\": \"\\u0438\", \"token_id\": 851, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.026124656695507096\", \"position\": 9}, {\"token\": \"\\u043d\\u0435\", \"token_id\": 1699, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0327271400734065\", \"position\": 10}, {\"token\": \"\\u0440\\u0430\\u0437\", \"token_id\": 2226, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.061532468865001244\", \"position\": 11}, {\"token\": \"\\u0440\\u0430\\u0437\\u0433\\u043e\\u043d\\u044f\", \"token_id\": 71593, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.056428748884130735\", \"position\": 12}, {\"token\": \"\\u043b\\u0438\", \"token_id\": 1698, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.08365359632445302\", \"position\": 13}, {\"token\": \"\\u0435\\u0442\", \"token_id\": 1465, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.0486315364050739\", \"position\": 14}, {\"token\": \"\\u043e\\u043d\\u0438\", \"token_id\": 4725, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.037749661263793644\", \"position\": 15}, {\"token\": \"\\u0432\\u0438\\u0437\\u0430\\u043d\\u0442\", \"token_id\": 21371, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.027755291549381368\", \"position\": 16}, {\"token\": \"\\u0438\\u0439\\u0441\\u043a\\u043e\\u0435\", \"token_id\": 19818, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.030063835046818674\", \"position\": 17}, {\"token\": \"\\u043e\\u043f\\u043e\\u043b\\u0447\\u0435\\u043d\\u0438\\u0435\", \"token_id\": 53275, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.029942942527254098\", \"position\": 18}, {\"token\": \"\\u0438\", \"token_id\": 851, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0180426971313495\", \"position\": 19}, {\"token\": \"\\u0434\\u0430\\u0436\\u0435\", \"token_id\": 8152, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.01869697701570709\", \"position\": 20}, {\"token\": \"\\u043f\\u043e\\u0434\\u043e\\u0448\\u043b\\u0438\", \"token_id\": 41078, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.01723940170811507\", \"position\": 21}, {\"token\": \"\\u043e\\u0434\\u043d\\u0430\\u0436\\u0434\\u044b\", \"token_id\": 26893, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.01805493479822067\", \"position\": 22}, {\"token\": \"\\u0431\\u043b\\u0438\\u0437\\u043a\\u043e\", \"token_id\": 30341, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.020209773798927713\", \"position\": 23}, {\"token\": \"\\u043a\", \"token_id\": 861, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.015756371178568717\", \"position\": 24}, {\"token\": \"\\u041a\\u043e\\u043d\\u0441\\u0442\\u0430\\u043d\\u0442\\u0438\\u043d\\u043e\", \"token_id\": 20067, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.04127611036701812\", \"position\": 25}, {\"token\": \"\\u043f\\u043e\\u043b\", \"token_id\": 3603, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.023873702433304556\", \"position\": 26}, {\"token\": \"\\u044e\", \"token_id\": 898, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.019964437908263473\", \"position\": 27}, {\"token\": \".\", \"token_id\": 132, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.016943675615931356\", \"position\": 28}, {\"token\": \"[SEP]\", \"token_id\": 102, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0298291229139221\", \"position\": 29}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 30}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 31}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 32}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 33}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 34}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 35}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 36}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 37}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 38}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 39}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 40}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 41}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 42}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 43}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 44}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 45}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 46}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 47}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 48}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 49}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 50}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 51}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 52}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 53}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 54}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 55}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 56}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 57}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 58}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 59}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 60}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 61}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 62}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 63}], \"attributions\": [[0.02181350896851866, 0.013874906011234828, 0.022882205943039132, 0.02668839694352416, 0.047099916343895286, 0.026560386070625205, 0.02870860116447556, 0.02295235662310335, 0.016096339320416108, 0.026124656695507096, 0.0327271400734065, 0.061532468865001244, 0.056428748884130735, 0.08365359632445302, 0.0486315364050739, 0.037749661263793644, 0.027755291549381368, 0.030063835046818674, 0.029942942527254098, 0.0180426971313495, 0.01869697701570709, 0.01723940170811507, 0.01805493479822067, 0.020209773798927713, 0.015756371178568717, 0.04127611036701812, 0.023873702433304556, 0.019964437908263473, 0.016943675615931356, 0.0298291229139221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03824605471749145, 0.031973820455370915, 0.05301198825092465, 0.05121775502330851, 0.049325569819156964, 0.030216821048076478, 0.030609720742801976, 0.02696849937423334, 0.020860604592649372, 0.023504089553931438, 0.02687030433411092, 0.029921587636294125, 0.03526101712815039, 0.03202168722844672, 0.03346347423339088, 0.025786845592518468, 0.031683822833937794, 0.030877320139147978, 0.024141927316645693, 0.019050392433717186, 0.025243120108747553, 0.023894697686154518, 0.028695836288867554, 0.037537936005654644, 0.029132396756485896, 0.06432558418038159, 0.03452039310724793, 0.026759933708078377, 0.019026665713132836, 0.0200306129025387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019441461979797597, 0.01393238107237395, 0.01743433547445434, 0.021815532279874813, 0.02709291112074989, 0.01881066878732583, 0.018853760383821222, 0.01518343380473982, 0.011162094988205995, 0.016623854287430236, 0.02686196870682421, 0.06091188105865669, 0.06879055658805769, 0.14234907229035293, 0.05468898798960086, 0.031110038860808792, 0.0236970047327246, 0.025266193577685173, 0.024560756273530177, 0.013433004268963362, 0.013193109451090994, 0.0175883808866046, 0.01647809826629125, 0.020036368280600424, 0.012020153562229312, 0.04013474553250733, 0.02320620112600739, 0.021068578850777276, 0.02406163943286096, 0.06297666447503403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.037453063600775806, 0.023755048554979098, 0.03446484840476489, 0.038702516072214824, 0.031573491396100606, 0.022638897451143926, 0.027198982536041225, 0.02018049261592371, 0.016045760274441923, 0.01818635082558938, 0.024530006822232605, 0.036122467227225265, 0.08553249646137821, 0.049623342074116145, 0.03216260468819081, 0.026435243201512342, 0.03107418385187821, 0.03261782728339528, 0.03820861736623359, 0.021396650421428236, 0.02237006196968046, 0.02423421586377007, 0.027201799456451223, 0.03079097038344199, 0.02785143322316166, 0.05639047465005409, 0.03182831062828362, 0.025469360684130454, 0.02406306304396997, 0.031117836877422554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025901200974869254, 0.022535763332620074, 0.019347693100766127, 0.024259600811787553, 0.027556912539466842, 0.019542842922577505, 0.02159067505038894, 0.009754951831151354, 0.010080853165057371, 0.015102807165636023, 0.03309331807373504, 0.061361328260753245, 0.12290424322831942, 0.08446695071437671, 0.06636669329848499, 0.02306863491658699, 0.0269642252971747, 0.022752957136853713, 0.06365550307787972, 0.0098216309369171, 0.010174036798227823, 0.018054525880553916, 0.014575048828075313, 0.013694045330374561, 0.010180760829220542, 0.03685044976895655, 0.02031910897022928, 0.009814721066956026, 0.012132331100956021, 0.03136260641006171, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019061515946126137, 0.016080932530148116, 0.017158975712065927, 0.023733799353670496, 0.028047401651617666, 0.021067090534546248, 0.019522715109451184, 0.014354021452516711, 0.010657630003276684, 0.02103701661588425, 0.037916541915989505, 0.08099396779670746, 0.08751383450782202, 0.16964472854587756, 0.0418557576537496, 0.030955906598785065, 0.02168534166528276, 0.020948067285452846, 0.021849732118415094, 0.009243436646578786, 0.013522704929168626, 0.0222999637582176, 0.01763084148163526, 0.01690122903388519, 0.011406145398982765, 0.032395927258229505, 0.017730489521611655, 0.013905882970550816, 0.011839691724286889, 0.019090481053939005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021877169105936723, 0.01746440747373333, 0.023705179882801124, 0.027919141404836107, 0.028124434209025703, 0.01726837787593467, 0.030755652195198317, 0.013494580294310056, 0.010263631586213061, 0.013918397994360126, 0.024027281018465692, 0.05517446100566713, 0.131187580167643, 0.1000790278298586, 0.041524292465906776, 0.02489335365514328, 0.03355927452113707, 0.038597070961602115, 0.06674733973838999, 0.011603742855397413, 0.013376820531170073, 0.017046230409497265, 0.018389573202403083, 0.018593356204562487, 0.01211258461577031, 0.04930061826070571, 0.026192653371354735, 0.015472942832284998, 0.010596190618765197, 0.015314725724499599, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028420427822331427, 0.018272769466298282, 0.024148208406860012, 0.025567179790346364, 0.027467161830323036, 0.02491582913661915, 0.02368461079493937, 0.021121118928239584, 0.01588578745133278, 0.021745904444103636, 0.03687981861387468, 0.07531096179083316, 0.04707999417920751, 0.09377704681554445, 0.038818592310686836, 0.03194993644436984, 0.023326412345351936, 0.027649351099166945, 0.02683901709518392, 0.014242662599708567, 0.01713278300587089, 0.019828560624642704, 0.020805034696080547, 0.024445929677766525, 0.017506542002653162, 0.04607081286074832, 0.02687172328919623, 0.02211724961841226, 0.023682786091114762, 0.051740660722502295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020413169397418322, 0.014661180048205087, 0.01833919777879796, 0.02134341158185467, 0.03366124104670503, 0.02267679296652283, 0.022112560812665123, 0.017108769396747374, 0.013645277738774896, 0.02351923837048075, 0.02487063050229171, 0.0519183303077987, 0.0547790277338925, 0.10545546977854074, 0.048635714857238055, 0.040751633019445475, 0.03618027519464466, 0.03240011586610102, 0.029986191052758886, 0.019266075213034393, 0.015989620577624312, 0.016418022392678776, 0.017771003107147916, 0.022428536310374413, 0.013969679628889177, 0.03758630924128356, 0.02033320172101835, 0.01825858476008492, 0.02615372072408988, 0.061840210637191084, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018986621720674262, 0.013393202424053523, 0.016750861317748732, 0.021467963046458326, 0.030417605589187796, 0.024939540536412702, 0.020834718959299423, 0.017403052715711777, 0.014163863508236464, 0.02449877299674746, 0.03727328657417086, 0.06442544871586647, 0.06247796213969058, 0.12408160975384838, 0.05406763316459096, 0.04404090051278221, 0.029607188984027328, 0.029805132935285965, 0.029620054916032198, 0.01997920593138157, 0.01714922011794426, 0.01810331345472855, 0.013963344567122542, 0.016711290617305037, 0.009823459390405144, 0.03379532448745199, 0.01905754159813635, 0.016023141796604932, 0.01465170072294164, 0.04858310941162628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01897677918150646, 0.014677790515714844, 0.01543691589879926, 0.017304755407962738, 0.027691299059965046, 0.02134009201377657, 0.016197155541479335, 0.012586631584343259, 0.010276433333412858, 0.017594197549521694, 0.033882296109642024, 0.06020743243692442, 0.07260115631482363, 0.16782743151983442, 0.051515158021193594, 0.04342724820623277, 0.04036591486737265, 0.03516524225686543, 0.022317303332014867, 0.012420252042482175, 0.01416264120919738, 0.018452214987115533, 0.014983708514632179, 0.017806531686746927, 0.011314433984075754, 0.035095111211743954, 0.01771691378336549, 0.015967812279485842, 0.009238486001954505, 0.024860817161157955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.049725942047722516, 0.026163308885739776, 0.0402689780414558, 0.040804612562665994, 0.042549513100284375, 0.02850283063670823, 0.028247979225206124, 0.0244817305126762, 0.02136080009599292, 0.023363808615720984, 0.02605923785425427, 0.032230737394307644, 0.05474828884306457, 0.041567067301226834, 0.03536906793988435, 0.025211087019373385, 0.02584345623251758, 0.02781558931066533, 0.029546923890034115, 0.02142254321482583, 0.02403212552736385, 0.023682650862484837, 0.03136352059163615, 0.034595842495391216, 0.031021234367090145, 0.05768932670895617, 0.03266108481171205, 0.02351533321739549, 0.01657870443390714, 0.016098343551727293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01629075411744989, 0.014075479633197864, 0.013536077459554284, 0.01847843150077706, 0.017850896873976556, 0.014505520528304375, 0.02003677553967479, 0.0060404701394947725, 0.011436028185046455, 0.011049485915425749, 0.020295575589824838, 0.05359615014529545, 0.15694734233431976, 0.10783904647445787, 0.0727366614071377, 0.02313606237646618, 0.03659258690891096, 0.027616265238112187, 0.05056056435000663, 0.0069941060990796515, 0.008595798041870927, 0.0166866059893185, 0.013403879556327481, 0.0126322565310815, 0.006319800411946201, 0.041220340382723784, 0.016117959116087818, 0.0060383178711318425, 0.012592435294943074, 0.013089322655622463, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024805873681296695, 0.013144068672488112, 0.01508117577181713, 0.01950016553078821, 0.02806249993874054, 0.022489355141968977, 0.018298106770717738, 0.012646763558439992, 0.010452154271974202, 0.017499229802770945, 0.029547645770950735, 0.06294125866078826, 0.06272793339351472, 0.12367376801043353, 0.03667019302703029, 0.02569925489207011, 0.0232328174719843, 0.02133025400051894, 0.023279225845933196, 0.011967260025133406, 0.01326579754984309, 0.017734026920881423, 0.016889139201570858, 0.016546886779003803, 0.012081275481164158, 0.03702815594732364, 0.02037090852874805, 0.020978708414759215, 0.03660199816279317, 0.11812980059184308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019427332739822084, 0.014354559098713412, 0.018682120757935856, 0.02065437002820938, 0.028825014413615728, 0.020661006975743787, 0.018606546710506648, 0.014813459716643607, 0.011763904207391849, 0.01745576410564578, 0.026967315936950925, 0.05496347921454732, 0.06440841244236867, 0.12274852927734094, 0.04997989056950681, 0.02700679509656751, 0.02847919567232132, 0.027705323501921165, 0.024445689069676167, 0.012020992898572348, 0.012992483358565461, 0.015361533740448057, 0.017133425836528212, 0.021786532843053142, 0.014497981753772001, 0.039931944118741465, 0.02164493510463844, 0.017487079409700707, 0.017436482158759252, 0.06646238501826443, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01836323006283373, 0.012570491507253525, 0.016019875093744848, 0.019913481463671133, 0.028379861230318736, 0.018489692001496423, 0.017930226271713354, 0.013101760211372313, 0.010223911976142681, 0.016773619420998517, 0.024719094021538553, 0.04602716956667476, 0.07240138007538993, 0.1926824050930038, 0.05911700841447062, 0.06003816020660483, 0.02809747586848525, 0.02740223596913648, 0.02397440030652135, 0.01070994432796504, 0.012502043517338465, 0.015739002663103005, 0.013922273055069153, 0.01690242279592774, 0.01093415174608934, 0.032032241273713284, 0.01760973296609382, 0.013186362295797496, 0.00713140001393229, 0.02152912856034965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0372187957639206, 0.02860772333667991, 0.041900039638793296, 0.044173253379590834, 0.03772651376280174, 0.029495580606319207, 0.028421340238287737, 0.025539966023264377, 0.02114756889000863, 0.022734819231708354, 0.026784786122096834, 0.03473944685164844, 0.033532788191810735, 0.03287862836547385, 0.03000472421879058, 0.02551680207381375, 0.027380412262506468, 0.03401898625526968, 0.02834156330538034, 0.0199475434257549, 0.024510460362389144, 0.02569932236792953, 0.029191211114873522, 0.03562355352116792, 0.027254914237443997, 0.05713725554745782, 0.03173935632883243, 0.025140495258602298, 0.016568108594863528, 0.03129697172942282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.042087356014849316, 0.021159665440129087, 0.0339538303383279, 0.03559453466473699, 0.03477529897307345, 0.028935796640548732, 0.027007543182265545, 0.02307975091784975, 0.02062472727103014, 0.020407240636980507, 0.027615168153272664, 0.04875606099860515, 0.04706249500357485, 0.04443875212581869, 0.029632974004445763, 0.025797108162159937, 0.028549369037370778, 0.030956663843598107, 0.02816024478360398, 0.01937038366907371, 0.022724974743360125, 0.024433664757025256, 0.029636280189051168, 0.03505782216143393, 0.03131595982354336, 0.06011921622726372, 0.03162878084181661, 0.023550049441789785, 0.017728202823595704, 0.05004207063417201, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020440823283911672, 0.016875554562145297, 0.017900138461746328, 0.024906885210961877, 0.025320837168240327, 0.017526867101616193, 0.02026423126060436, 0.011952056876040599, 0.009090781271914811, 0.012585587190474685, 0.021501776627836346, 0.0519466435498517, 0.14678354225454573, 0.09055259583461035, 0.06905075310128991, 0.02138982084951521, 0.028827832515523164, 0.029292444785425607, 0.057650427730743935, 0.009438686970156956, 0.010651682041868464, 0.017128353934019687, 0.015881511398684166, 0.014932243880685035, 0.009796354007659507, 0.03811136713162515, 0.02034520445361068, 0.009923874894190422, 0.010614674565378183, 0.009319906237125152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018986621720674262, 0.013393202424053523, 0.016750861317748732, 0.021467963046458326, 0.030417605589187796, 0.024939540536412702, 0.020834718959299423, 0.017403052715711777, 0.014163863508236464, 0.02449877299674746, 0.03727328657417086, 0.06442544871586647, 0.06247796213969058, 0.12408160975384838, 0.05406763316459096, 0.04404090051278221, 0.029607188984027328, 0.029805132935285965, 0.029620054916032198, 0.01997920593138157, 0.01714922011794426, 0.01810331345472855, 0.013963344567122542, 0.016711290617305037, 0.009823459390405144, 0.03379532448745199, 0.01905754159813635, 0.016023141796604932, 0.01465170072294164, 0.04858310941162628, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01842001027888926, 0.011958745517911271, 0.013586057155452523, 0.015853973671192637, 0.025852242611640274, 0.020153761213794096, 0.019962918760810792, 0.0153935463057595, 0.012554621509382899, 0.02028458861291743, 0.026864481335301216, 0.05016797989289158, 0.07355231708800568, 0.1895967517508221, 0.05856974313604966, 0.04187576031292774, 0.019916160620816234, 0.023992837013414807, 0.029310695323026142, 0.01296892809554471, 0.014620742649041982, 0.019610446754588878, 0.01364490751360003, 0.015033798670436527, 0.01193787758242439, 0.0340009331633222, 0.017386837589921204, 0.013910782241944412, 0.011779760792692372, 0.03130310883860707, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019160431547906497, 0.01829968074402942, 0.019419306179495822, 0.025434126643894796, 0.024638771005114624, 0.01936369887210261, 0.0208039658922006, 0.012079574956072321, 0.01432283605906916, 0.013107919690789503, 0.01824085812606555, 0.04986016634572137, 0.12099800614808821, 0.10541862698764023, 0.09380475479245629, 0.025621816813438177, 0.030991792495504166, 0.028595778696204038, 0.04685096562511802, 0.010118640040541036, 0.012093952071196418, 0.02208725130973096, 0.018115097235504314, 0.018058248043744316, 0.0144011951309454, 0.03921899038203367, 0.02048281269905901, 0.011930936061757009, 0.01142281080195914, 0.011158339704749864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026485272728961277, 0.02045501082312953, 0.028669135942968292, 0.03342501069139275, 0.03546671048550523, 0.02440341104897483, 0.025053484651007568, 0.019401924434918057, 0.016230876119460582, 0.01804328330882429, 0.025187209581688626, 0.04825466883353123, 0.05672297213661534, 0.13213003708260154, 0.04627082969991244, 0.0295457462642334, 0.028208942569613964, 0.026622693351333288, 0.02650796826705755, 0.012928425532026909, 0.017375471225118105, 0.019958123446727826, 0.01934466540123612, 0.024041618277131423, 0.022798045472327427, 0.04522975180969684, 0.021309405903475267, 0.017118285356923432, 0.014474443796164714, 0.03208971540053725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03132987656539767, 0.02237213213225934, 0.030186065406507052, 0.034426694597151614, 0.03708591294978797, 0.024437980148295978, 0.026329135771014627, 0.019708915678779877, 0.015945259219723524, 0.021180443280607815, 0.02723836193402992, 0.048230354413451186, 0.07948900453683908, 0.07907919060631756, 0.03408600573976622, 0.02856428946982922, 0.03160797563970112, 0.03134804072570644, 0.04041437252739547, 0.016190279845850055, 0.018285258028185872, 0.023167619365228938, 0.02557149878679474, 0.02820239239377482, 0.02376195838672804, 0.050487447818693576, 0.02894014982958034, 0.02110944362430612, 0.016657711621997202, 0.022635740969942246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.022459485438697944, 0.019530512162139333, 0.0294389820539501, 0.033948103724217624, 0.03937369567149392, 0.02602451150336483, 0.025069941203443587, 0.021256948257274453, 0.01387111312136469, 0.018375979953065825, 0.02271157048545798, 0.04473096216411674, 0.06615525393233926, 0.09505300842521038, 0.058910280154320455, 0.03265180206084342, 0.03384967396722375, 0.0311250732350772, 0.029129101946471725, 0.012228952412100905, 0.016190156205381785, 0.019761019949034574, 0.021476319383267096, 0.025119186815528185, 0.022622281517245896, 0.05295198084531687, 0.028922383872944046, 0.016895833392176794, 0.011113232069541791, 0.01351793777346561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027205016645599968, 0.02380904087961314, 0.027818834291665828, 0.03160475301558238, 0.03384152848375623, 0.024610002295098153, 0.025203896413386655, 0.019350258366681156, 0.015476103848424206, 0.018542407938296465, 0.027802261099942667, 0.04975899951964275, 0.09236313702256652, 0.07491842195184453, 0.04705571449210013, 0.027250580013975557, 0.029908017109719232, 0.03712729979387327, 0.049315729741748526, 0.01588385256338708, 0.019934339233498907, 0.023602492367396123, 0.02553737302340428, 0.023203633735768715, 0.018608794539482346, 0.050438919424496624, 0.0277833551270646, 0.017829459899486175, 0.014229423051756148, 0.01581842869536978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019475132008469273, 0.025370888300500525, 0.023171339294120102, 0.026947478704874232, 0.025085443239724427, 0.022563032638781535, 0.022967320062830494, 0.015690752567217758, 0.014215349070301838, 0.020052991092577497, 0.04299983793960751, 0.08507888127928442, 0.1095828968805397, 0.05153798325198144, 0.03423113328150824, 0.02557113305855306, 0.0283140031797308, 0.029821479134374718, 0.05315997398810664, 0.012044350425994067, 0.014148958503403912, 0.01734915968566011, 0.018491900664644838, 0.01884687576468545, 0.016780317374460355, 0.04371810592372149, 0.02594784218772359, 0.015742603046343707, 0.014835317289382234, 0.029135315661236304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024122394820769593, 0.014934516383951178, 0.017792913391308802, 0.019679470830809412, 0.02646901979216535, 0.018710680773945602, 0.02061642632087687, 0.016362915860692405, 0.010778361019136989, 0.0151420929629701, 0.02785775900308853, 0.057518871965987, 0.04937058353540759, 0.07046690092807455, 0.03157686081543422, 0.020419295764157998, 0.019607408854497303, 0.02014272825357337, 0.020402460487785674, 0.011753380107248662, 0.013198908885524665, 0.013890037902486498, 0.014302544602082815, 0.015951462972492995, 0.012882388118866111, 0.04235561873284009, 0.022672006917582282, 0.030732367211441822, 0.05443966213885434, 0.18802909299855944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02181350896851866, 0.013874906011234828, 0.022882205943039132, 0.02668839694352416, 0.047099916343895286, 0.026560386070625205, 0.02870860116447556, 0.02295235662310335, 0.016096339320416108, 0.026124656695507096, 0.0327271400734065, 0.061532468865001244, 0.056428748884130735, 0.08365359632445302, 0.0486315364050739, 0.037749661263793644, 0.027755291549381368, 0.030063835046818674, 0.029942942527254098, 0.0180426971313495, 0.01869697701570709, 0.01723940170811507, 0.01805493479822067, 0.020209773798927713, 0.015756371178568717, 0.04127611036701812, 0.023873702433304556, 0.019964437908263473, 0.016943675615931356, 0.0298291229139221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02181350896851866, 0.013874906011234828, 0.022882205943039132, 0.02668839694352416, 0.047099916343895286, 0.026560386070625205, 0.02870860116447556, 0.02295235662310335, 0.016096339320416108, 0.026124656695507096, 0.0327271400734065, 0.061532468865001244, 0.056428748884130735, 0.08365359632445302, 0.0486315364050739, 0.037749661263793644, 0.027755291549381368, 0.030063835046818674, 0.029942942527254098, 0.0180426971313495, 0.01869697701570709, 0.01723940170811507, 0.01805493479822067, 0.020209773798927713, 0.015756371178568717, 0.04127611036701812, 0.023873702433304556, 0.019964437908263473, 0.016943675615931356, 0.0298291229139221, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]},\n                    preset: 'viridis',\n                    tokenization_config: \"\"\n\n             })\n\n             window.ecco[viz_id].init();\n             window.ecco[viz_id].selectFirstToken();\n\n             }, function (err) {\n                console.log(err);\n            })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out1.primary_attributions(attr_method='ig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n             requirejs(['basic', 'ecco'], function(basic, ecco){\n                const viz_id = basic.init()\n                console.log(viz_id)\n                // ecco.interactiveTokens(viz_id, {})\n                window.ecco[viz_id] = new ecco.MinimalHighlighter({\n                    parentDiv: viz_id,\n                    data: {\"tokens\": [{\"token\": \"[CLS]\", \"token_id\": 101, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.02182230488025352\", \"position\": 0}, {\"token\": \"\\u041c\\u043d\\u043e\\u0433\\u043e\", \"token_id\": 21956, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.013778376442705225\", \"position\": 1}, {\"token\": \"\\u0445\\u0440\\u0438\\u0441\\u0442\\u0438\\u0430\\u043d\\u0441\\u043a\\u043e\\u0439\", \"token_id\": 33866, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.02258625400864665\", \"position\": 2}, {\"token\": \"\\u043a\\u0440\\u043e\\u0432\\u0438\", \"token_id\": 18531, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.026634170729205844\", \"position\": 3}, {\"token\": \"\\u043f\\u0440\\u043e\\u043b\", \"token_id\": 14441, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.04755168431131054\", \"position\": 4}, {\"token\": \"\\u0438\\u043b\\u0438\", \"token_id\": 2761, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.026554442491576916\", \"position\": 5}, {\"token\": \"\\u0432\\u0430\\u0440\\u0432\\u0430\\u0440\", \"token_id\": 38926, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.02874049788177813\", \"position\": 6}, {\"token\": \"\\u044b\", \"token_id\": 880, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.022979186294026933\", \"position\": 7}, {\"token\": \",\", \"token_id\": 128, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.016182997412384516\", \"position\": 8}, {\"token\": \"\\u0438\", \"token_id\": 851, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.02617415766720741\", \"position\": 9}, {\"token\": \"\\u043d\\u0435\", \"token_id\": 1699, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.032957401768486626\", \"position\": 10}, {\"token\": \"\\u0440\\u0430\\u0437\", \"token_id\": 2226, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.062061773171426735\", \"position\": 11}, {\"token\": \"\\u0440\\u0430\\u0437\\u0433\\u043e\\u043d\\u044f\", \"token_id\": 71593, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.057552755960019276\", \"position\": 12}, {\"token\": \"\\u043b\\u0438\", \"token_id\": 1698, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.08435160110964043\", \"position\": 13}, {\"token\": \"\\u0435\\u0442\", \"token_id\": 1465, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.04870956716019493\", \"position\": 14}, {\"token\": \"\\u043e\\u043d\\u0438\", \"token_id\": 4725, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.03765943418443371\", \"position\": 15}, {\"token\": \"\\u0432\\u0438\\u0437\\u0430\\u043d\\u0442\", \"token_id\": 21371, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.027647946741218815\", \"position\": 16}, {\"token\": \"\\u0438\\u0439\\u0441\\u043a\\u043e\\u0435\", \"token_id\": 19818, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.02991242948299924\", \"position\": 17}, {\"token\": \"\\u043e\\u043f\\u043e\\u043b\\u0447\\u0435\\u043d\\u0438\\u0435\", \"token_id\": 53275, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.029836583162738385\", \"position\": 18}, {\"token\": \"\\u0438\", \"token_id\": 851, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.018003324396528412\", \"position\": 19}, {\"token\": \"\\u0434\\u0430\\u0436\\u0435\", \"token_id\": 8152, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.01862668514667694\", \"position\": 20}, {\"token\": \"\\u043f\\u043e\\u0434\\u043e\\u0448\\u043b\\u0438\", \"token_id\": 41078, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.017147684970966845\", \"position\": 21}, {\"token\": \"\\u043e\\u0434\\u043d\\u0430\\u0436\\u0434\\u044b\", \"token_id\": 26893, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.01796333669514961\", \"position\": 22}, {\"token\": \"\\u0431\\u043b\\u0438\\u0437\\u043a\\u043e\", \"token_id\": 30341, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.02019857856276661\", \"position\": 23}, {\"token\": \"\\u043a\", \"token_id\": 861, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.01574427661487506\", \"position\": 24}, {\"token\": \"\\u041a\\u043e\\u043d\\u0441\\u0442\\u0430\\u043d\\u0442\\u0438\\u043d\\u043e\", \"token_id\": 20067, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.041167410392422644\", \"position\": 25}, {\"token\": \"\\u043f\\u043e\\u043b\", \"token_id\": 3603, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.02370846114765134\", \"position\": 26}, {\"token\": \"\\u044e\", \"token_id\": 898, \"is_partial\": false, \"type\": \"output\", \"value\": \"0.01988941181491256\", \"position\": 27}, {\"token\": \".\", \"token_id\": 132, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.01615654101379897\", \"position\": 28}, {\"token\": \"[SEP]\", \"token_id\": 102, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.02755554919431698\", \"position\": 29}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 30}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 31}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 32}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 33}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 34}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 35}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 36}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 37}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 38}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 39}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 40}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 41}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 42}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 43}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 44}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 45}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 46}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 47}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 48}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 49}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 50}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 51}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 52}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 53}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 54}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 55}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 56}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 57}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 58}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 59}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 60}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 61}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 62}, {\"token\": \"[PAD]\", \"token_id\": 0, \"is_partial\": true, \"type\": \"output\", \"value\": \"0.0\", \"position\": 63}], \"attributions\": [[0.02182230488025352, 0.013778376442705225, 0.02258625400864665, 0.026634170729205844, 0.04755168431131054, 0.026554442491576916, 0.02874049788177813, 0.022979186294026933, 0.016182997412384516, 0.02617415766720741, 0.032957401768486626, 0.062061773171426735, 0.057552755960019276, 0.08435160110964043, 0.04870956716019493, 0.03765943418443371, 0.027647946741218815, 0.02991242948299924, 0.029836583162738385, 0.018003324396528412, 0.01862668514667694, 0.017147684970966845, 0.01796333669514961, 0.02019857856276661, 0.01574427661487506, 0.041167410392422644, 0.02370846114765134, 0.01988941181491256, 0.01615654101379897, 0.02755554919431698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03823049317850452, 0.03197501964218383, 0.053127461428210655, 0.05122580127213791, 0.04926594890071488, 0.03014059396422075, 0.03049038236094907, 0.026938894735401366, 0.02087620576973787, 0.023537829385048916, 0.02685875567898062, 0.029855001429022324, 0.03538814428361667, 0.03215886556595168, 0.03345693071727435, 0.025846183128814954, 0.03156552070552618, 0.03095397875322386, 0.024122587107863823, 0.019093342087236367, 0.025232640846168268, 0.02390599889413293, 0.02870883344648508, 0.03753049674114511, 0.029075123972615535, 0.06416238473289872, 0.03440686351415359, 0.026625623572184225, 0.018921375939605377, 0.019727883203925888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019475155979814366, 0.013928725001452988, 0.01736599167149938, 0.021801616750500144, 0.026944988300884543, 0.01873639075288345, 0.018882145142384062, 0.0151753920140493, 0.01112611473637342, 0.01668817384728508, 0.02703795122646008, 0.06153262080776253, 0.0690502706700268, 0.14083798409514847, 0.05446563384197172, 0.03090810959537063, 0.023520227851573636, 0.025079861060368216, 0.024349819714237456, 0.013311220142159186, 0.013133875712864075, 0.017554238374101958, 0.01659030687963898, 0.020122268694519642, 0.012040646911596758, 0.040445278653986345, 0.023323816675748316, 0.02111197825576549, 0.024520776689686417, 0.06410801889974234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03803926211051332, 0.023876337740374686, 0.03489001552908529, 0.03875574751475431, 0.031827611103264784, 0.023069679965875105, 0.027343521137292836, 0.020564581507714903, 0.016316023563367095, 0.018435465479467544, 0.02455856819227423, 0.03536015834701145, 0.08176455171941026, 0.047869467630559326, 0.0316755898420745, 0.026484524611462223, 0.03087403730801564, 0.03262172944604581, 0.03715398619652571, 0.021690092177087478, 0.022780489944631204, 0.02441797282052744, 0.02759898174312197, 0.0312593993428166, 0.02837586634899523, 0.05708338980896109, 0.03227264314176064, 0.025946506487168973, 0.02463490716417648, 0.032011860786432075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025950164549552082, 0.022490201909232132, 0.019417276060486658, 0.0242327360120255, 0.027575663470411668, 0.019615368908077004, 0.021641332756977508, 0.009804765166473087, 0.010080712393812152, 0.015090281585607195, 0.03296462034121573, 0.0610072038622367, 0.12253900544398828, 0.08463762892696586, 0.06625119548394441, 0.023113076370458178, 0.02684105002724651, 0.022703095441463518, 0.06326442485449867, 0.009843626223685143, 0.010199590149818322, 0.01807672458612771, 0.014604182628467358, 0.013729976706176523, 0.010202050342054663, 0.03688727402354675, 0.020368846751342245, 0.009873684070369319, 0.012242994204037327, 0.032078486043254265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01915460596488655, 0.016072773769476755, 0.01717717572027904, 0.023788684511501974, 0.027952165390022828, 0.02098797929330631, 0.019507823944958754, 0.014341746851505941, 0.010643651931327578, 0.02090581725344029, 0.0378500732585272, 0.08070448564424862, 0.08734337405710552, 0.16941168361419096, 0.04197730604685472, 0.030638513928577766, 0.02195049275456088, 0.02098702961129147, 0.021897711036776745, 0.009229145395764858, 0.013524925900992543, 0.02229421762835084, 0.017640797065268003, 0.016898461149596866, 0.01136070421302804, 0.032469603790675275, 0.017774975052555347, 0.013957252923625608, 0.011961892329846329, 0.019712591241659798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021795747829854394, 0.017393865022023933, 0.023522678179125404, 0.027894463163782707, 0.028120780932965942, 0.017367093730650787, 0.030862337281392416, 0.013504953819571059, 0.010238181996767532, 0.013965256218722867, 0.024097414625237346, 0.05561222877630355, 0.13030192273920824, 0.10035467945043977, 0.04174048274587358, 0.024849302347799713, 0.03356244614352367, 0.038568284047636986, 0.0662669224518464, 0.01159598851761081, 0.01330983396345768, 0.017046194513490966, 0.01840466531027857, 0.01868142931529412, 0.012110818416947786, 0.04934398476047386, 0.026202937262303338, 0.01563422023535619, 0.010669583440403325, 0.01594632585452951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028285482467367194, 0.018221822405687663, 0.023907057048162882, 0.025468551206902064, 0.027322609655939592, 0.02470613433865398, 0.023646730276366306, 0.020993037846120555, 0.015728410554149336, 0.021609402557899903, 0.03698059440231125, 0.07643038813125684, 0.047387539901290354, 0.09305089894659001, 0.03876020662553818, 0.03153305690340247, 0.023077591682548772, 0.027499288210365725, 0.026601726205026387, 0.014066284367123576, 0.017013501493239932, 0.01984956166508041, 0.02082722482334841, 0.024498194925260543, 0.01736737171089956, 0.046125433843882506, 0.026837562417049755, 0.022217381714256013, 0.024053476141970218, 0.05262210632523433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020026045324647173, 0.01441100338351992, 0.017947118760648192, 0.02102856133245179, 0.03378197490643357, 0.02248283564707268, 0.021883368866112092, 0.016982647404795347, 0.013634624951220515, 0.023656057593502457, 0.02500701924638733, 0.052317379862853196, 0.05580875149172225, 0.10831736191510044, 0.049033926125539515, 0.04113594313218073, 0.03644304918267615, 0.032399041160806955, 0.030053263418830193, 0.0192964451777104, 0.015832910931573064, 0.016186533131127976, 0.017366458160417594, 0.02198879664191561, 0.013566856156770214, 0.036928289986438635, 0.020043656973636692, 0.01803680929341196, 0.025454104777883745, 0.06030811526185901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018873668424074973, 0.013385859681992403, 0.016662206188422752, 0.021272893079505837, 0.03018137079275141, 0.0246344885409985, 0.020586012401760282, 0.01731509978353512, 0.014016393102346545, 0.024394828687743397, 0.03729667982999543, 0.06421911667242755, 0.06294738606046082, 0.1255068738671817, 0.0539905109071816, 0.043773429118241516, 0.029124322055619024, 0.029431178035148296, 0.02931401435781651, 0.019820419544618197, 0.017049276326260954, 0.017992908966096535, 0.013749090125918581, 0.016508690490262577, 0.009723718269407355, 0.033565875743587256, 0.018933478135139892, 0.01610711948298274, 0.015283053608217611, 0.04997819945696735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018909194987428213, 0.01485217215034118, 0.015305420999599742, 0.01718732065413992, 0.02758586560305652, 0.02106793438691503, 0.01616386876617096, 0.012557086911095507, 0.010271403255821893, 0.017649613628051865, 0.03389634149046824, 0.06005298953235661, 0.07304076925473126, 0.170799967794435, 0.051983619217540945, 0.04284496165399292, 0.03930457347375016, 0.03436512147619911, 0.021721819098760753, 0.012173306119174788, 0.01397903704835652, 0.01829310603837855, 0.014921142516730981, 0.017676545641549093, 0.011338901172427973, 0.034921286953413656, 0.017789857693342525, 0.01587539081346198, 0.009412359906131736, 0.024410618254181043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.049919366937889564, 0.026215005049921934, 0.040275513956478395, 0.04088599904881788, 0.04267622915565027, 0.028601995515780684, 0.028351378861753773, 0.024594194115198278, 0.02146323936249572, 0.023475148454008037, 0.026163188921080032, 0.03222663152984766, 0.05406939513048446, 0.0412070227399885, 0.035243768824836076, 0.025266145292272214, 0.025903679731431793, 0.027852142322869568, 0.029404566919648698, 0.021473990187514835, 0.024106981758011823, 0.02371842023170502, 0.03141380467798266, 0.034673369933625756, 0.031136758740219626, 0.05787608018614521, 0.03274020640604614, 0.023606501088065435, 0.016628747638297164, 0.016128246269044386, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016302743278994433, 0.013994311828200922, 0.013486950166110175, 0.018400700183935643, 0.017819175595943804, 0.01459210428508844, 0.019829617381185154, 0.006032518763977729, 0.011407993044940898, 0.010975088475138546, 0.020047220641090942, 0.053302287168752974, 0.15656465002329215, 0.10852419266928352, 0.0734078312526022, 0.023189830680189094, 0.036650794575751586, 0.027571817061417276, 0.05017366905320737, 0.006981956891705015, 0.008575751793096604, 0.016644607410104238, 0.013353057809781068, 0.012592504549307727, 0.006272837589461594, 0.04092104389405943, 0.01607748762510152, 0.006053795559007225, 0.01267598070195492, 0.013100557507615893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024972607176049787, 0.013142651074406032, 0.015089928372271157, 0.01946448144316053, 0.027688172604793775, 0.02232617841011458, 0.018301059688259153, 0.01268770859462871, 0.010473232221131683, 0.017420883127210487, 0.029708112395715778, 0.06321418883338752, 0.06182158408601281, 0.11913427314286712, 0.03634114064880959, 0.025105789470184145, 0.022149301042328613, 0.021047063704250572, 0.02309211814547866, 0.01187309619028716, 0.013249413999121513, 0.017628558590545882, 0.0168052216775256, 0.01660740990006191, 0.012172017217048721, 0.03737748033560581, 0.02058256862536138, 0.02141644150275523, 0.038361291655271954, 0.12467518818240993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019889628050473056, 0.014524032972044191, 0.019349580451733357, 0.021084419955176934, 0.028329875741261674, 0.020750085846553308, 0.018965237160227577, 0.015001042910534463, 0.01194602035559381, 0.017362559400277398, 0.027387108994107373, 0.05470578240005352, 0.060935993048781084, 0.10580605117376171, 0.04649264460041955, 0.026397900012748717, 0.028644119721670323, 0.028233784656140563, 0.025120296082547993, 0.0126541713467565, 0.013760750069628003, 0.015921241107342853, 0.018249206515740687, 0.0230395030065321, 0.015807560341326778, 0.04160931183913573, 0.022512154974612796, 0.018303707928427573, 0.019829767246922553, 0.07605329689798315, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018505774344885706, 0.012662284387695937, 0.015976470830635487, 0.019932569849297997, 0.02822757954599204, 0.018483686370888153, 0.01789912452734941, 0.013073152408313948, 0.010209522482102662, 0.016709603284864098, 0.024632567324593225, 0.045355506385820046, 0.07283881930167836, 0.19391804975033522, 0.05928437323848028, 0.05996669022026749, 0.027995542339260812, 0.027282047569354147, 0.02373594719214179, 0.010552090182637532, 0.012329396793276512, 0.015595112094538826, 0.013846086872758682, 0.016733683668189878, 0.010916805588203281, 0.032001685714254345, 0.017529944990172675, 0.01301360462227965, 0.007272661520824792, 0.021581381024758324, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01762486719245962, 0.016941620642594687, 0.013193402312966472, 0.01808258584118642, 0.01989681988482725, 0.018731992629848808, 0.016376442639287222, 0.006429101141121318, 0.010642683712919944, 0.009816888770669633, 0.026178785844207207, 0.05255931145350966, 0.12897635917348885, 0.12255544812130886, 0.1050358322737555, 0.024812454125733283, 0.025604337236070442, 0.021048699929273103, 0.05785322368379938, 0.006647417797696849, 0.007112603822100392, 0.01596620781691804, 0.01255883760696378, 0.010194380761305317, 0.007299426944439358, 0.03407396155730203, 0.017452912486483663, 0.007342291640070452, 0.01351198755075762, 0.008747759745498985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04257417918580446, 0.021373917312545215, 0.03417175343650133, 0.03563165165894526, 0.034835555048429924, 0.028911088086148482, 0.02711347352618516, 0.02318348634304571, 0.020645240807560875, 0.020515375709333303, 0.027651180030746576, 0.0484621888783758, 0.04650743405889179, 0.043540364215151, 0.029558789722249845, 0.025884488087049278, 0.02849786874121648, 0.030915316462264676, 0.028026232196708935, 0.01955904925953776, 0.022873590412771837, 0.024574247749978274, 0.02976253829534204, 0.03516912537458157, 0.03151209743530412, 0.060130457167926664, 0.0318208508747714, 0.023703927405117543, 0.017770507940592994, 0.05032347780564873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02036724715720457, 0.016939515711365496, 0.017950569552205375, 0.02503614670527496, 0.025386506519491165, 0.0177138766514128, 0.020273751845152652, 0.012016560870460267, 0.009201826271510245, 0.012570005037874084, 0.02120823616912489, 0.05151328069805788, 0.14592699419804814, 0.0902298151324298, 0.06973519377626537, 0.021331747804239014, 0.028954578914138725, 0.029253367161305294, 0.057686867247836573, 0.009454464054666495, 0.010708873384527754, 0.017171911119388202, 0.0159044801644215, 0.015024030949963237, 0.009808779697499579, 0.038129837371407564, 0.02044763648459664, 0.009988295459108103, 0.010589867020730904, 0.00946501950411772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018873668424074973, 0.013385859681992403, 0.016662206188422752, 0.021272893079505837, 0.03018137079275141, 0.0246344885409985, 0.020586012401760282, 0.01731509978353512, 0.014016393102346545, 0.024394828687743397, 0.03729667982999543, 0.06421911667242755, 0.06294738606046082, 0.1255068738671817, 0.0539905109071816, 0.043773429118241516, 0.029124322055619024, 0.029431178035148296, 0.02931401435781651, 0.019820419544618197, 0.017049276326260954, 0.017992908966096535, 0.013749090125918581, 0.016508690490262577, 0.009723718269407355, 0.033565875743587256, 0.018933478135139892, 0.01610711948298274, 0.015283053608217611, 0.04997819945696735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018514989669737327, 0.012003995934534634, 0.013502885745995974, 0.015773006872978484, 0.02568914207707035, 0.01989968046926924, 0.019780351468687663, 0.015292615730791952, 0.012498781156185869, 0.02004669969171081, 0.026519566805497836, 0.04945683536344781, 0.07358661219015378, 0.19143980762058374, 0.05894581980960902, 0.0414929742214354, 0.019827689793621917, 0.02372400894430406, 0.028882935872512384, 0.012743695214272462, 0.01450872532910838, 0.01940643955151578, 0.013682724994508103, 0.015016467072228956, 0.011966990212006241, 0.033830476120564335, 0.017395412200313456, 0.013925142774410145, 0.01220617158104313, 0.03202047127548817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01898285677099072, 0.018225048252443695, 0.019223057713271895, 0.025248548787640795, 0.024497995683616727, 0.019351983404892973, 0.020670048075124615, 0.011990368888979999, 0.014329786610667201, 0.013098817941101676, 0.01829106366338079, 0.05001576933251293, 0.1211828605962827, 0.10613510792233626, 0.09477224623753963, 0.025732948415804317, 0.030988897403433094, 0.02866612549865532, 0.046693853469941635, 0.010001302515934236, 0.01198490847086475, 0.022077982301592327, 0.017961508092281402, 0.017897065232902812, 0.014181162732223954, 0.038975354745724444, 0.020303467850471005, 0.011806111081158359, 0.011381437826867647, 0.010668044730784488, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026610183120704865, 0.020577711668646158, 0.028809685518753944, 0.03355028302580904, 0.03546665796165415, 0.02439270034201542, 0.02509717649236819, 0.019408671363628737, 0.016187142900150598, 0.017958458853513916, 0.025211364212169202, 0.04787916909749141, 0.05633077417257212, 0.13161508027796534, 0.04581536225630107, 0.029049463145736698, 0.02809227195841656, 0.02669108627399739, 0.026208951468441766, 0.01293689840052326, 0.017423387214520244, 0.019990080925165316, 0.019441116876742014, 0.024098919382252195, 0.022830606715612097, 0.04502567464338282, 0.021359242191109285, 0.01714728269736198, 0.01490150629326214, 0.034090639930168955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030545016078540845, 0.02231592743375587, 0.029810105983935752, 0.03419800645698764, 0.036857472614093945, 0.02423138700732309, 0.026242842880650787, 0.019397136671564345, 0.015707233710647698, 0.021271917532305146, 0.027211130285843266, 0.04883413676034709, 0.08230016100438928, 0.07993926554272618, 0.03449407689888955, 0.02864366368870412, 0.03152722224292787, 0.03138858374303092, 0.04145696963856472, 0.01602490828549376, 0.01795343460718015, 0.02304110911966506, 0.02516642679536406, 0.02785828780426867, 0.023174071550053424, 0.04991851000841819, 0.02849353428803293, 0.02067942745624533, 0.016421927814257886, 0.022441564034515714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.022055401143459448, 0.019083612604506778, 0.029072624260184855, 0.0334054505518883, 0.03899801137879409, 0.0260668430696511, 0.02501458610235515, 0.0209909098488195, 0.013817605354087364, 0.018297625933102416, 0.022655527511217927, 0.044864337795279825, 0.0661481658929077, 0.09617835163381451, 0.059008129557297256, 0.03288359481101249, 0.033649061800866624, 0.031120080706506393, 0.028932212912065262, 0.01212358027593176, 0.0159766642514276, 0.019649423247999055, 0.021141411243937137, 0.024979682186241327, 0.022607419239012997, 0.052779976487937016, 0.028686039971387488, 0.016773626741617278, 0.011380111217294422, 0.015642477527624297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027078262036386608, 0.023733653039842928, 0.027548640224906308, 0.03139439133409887, 0.033729256861812856, 0.024452235716159135, 0.025021926008661946, 0.01918853385472468, 0.015339076125531495, 0.01834382317512667, 0.027551744201861707, 0.04960559524267392, 0.09278657126511387, 0.07575084111385132, 0.04718266983159575, 0.027198274013082002, 0.029709583129596828, 0.03689501531487672, 0.04963006913248983, 0.01583587453958748, 0.019875552321223195, 0.023648171025494224, 0.025452285101358704, 0.02305973413070238, 0.018530186676791415, 0.05035404678289793, 0.027703157965294944, 0.017782875750917842, 0.014450853811264045, 0.017030811472250974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019644468533051327, 0.025399910072722274, 0.023361256360502333, 0.027172698078739538, 0.025279565558453693, 0.022518093851310435, 0.023016905748893587, 0.01587039096026574, 0.014437429117232302, 0.020089429435339822, 0.042996250666640555, 0.08473056512064557, 0.10862273970364066, 0.051027074474240326, 0.033620907799706085, 0.02576476529786599, 0.02836730682085361, 0.029895224922608283, 0.05298872156136668, 0.012189389084808626, 0.014356771346804352, 0.017468565839534256, 0.01862741810873644, 0.0190537493308137, 0.01706317955245464, 0.04396549831411986, 0.026094585479233996, 0.01599205654209659, 0.014990118836467742, 0.03042949768648691, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02433464460538167, 0.015030625743656004, 0.017647968606515543, 0.019517633367144495, 0.025975184210993305, 0.018445606159742757, 0.020269846641982593, 0.01616370328795435, 0.010792813342290474, 0.01504883732398556, 0.027674249925122397, 0.05720437051148734, 0.04865464682325222, 0.06749184001023258, 0.031012903667528097, 0.020079005363309515, 0.019144255850948717, 0.020075606556147905, 0.020083220040961892, 0.01167244661996968, 0.013074018441750504, 0.01378339589582981, 0.014278896290077546, 0.01596125284573355, 0.012931168044741159, 0.042527357380494187, 0.022822561222914744, 0.030961983937331412, 0.056205183741843225, 0.1943083164454462, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02182230488025352, 0.013778376442705225, 0.02258625400864665, 0.026634170729205844, 0.04755168431131054, 0.026554442491576916, 0.02874049788177813, 0.022979186294026933, 0.016182997412384516, 0.02617415766720741, 0.032957401768486626, 0.062061773171426735, 0.057552755960019276, 0.08435160110964043, 0.04870956716019493, 0.03765943418443371, 0.027647946741218815, 0.02991242948299924, 0.029836583162738385, 0.018003324396528412, 0.01862668514667694, 0.017147684970966845, 0.01796333669514961, 0.02019857856276661, 0.01574427661487506, 0.041167410392422644, 0.02370846114765134, 0.01988941181491256, 0.01615654101379897, 0.02755554919431698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02182230488025352, 0.013778376442705225, 0.02258625400864665, 0.026634170729205844, 0.04755168431131054, 0.026554442491576916, 0.02874049788177813, 0.022979186294026933, 0.016182997412384516, 0.02617415766720741, 0.032957401768486626, 0.062061773171426735, 0.057552755960019276, 0.08435160110964043, 0.04870956716019493, 0.03765943418443371, 0.027647946741218815, 0.02991242948299924, 0.029836583162738385, 0.018003324396528412, 0.01862668514667694, 0.017147684970966845, 0.01796333669514961, 0.02019857856276661, 0.01574427661487506, 0.041167410392422644, 0.02370846114765134, 0.01988941181491256, 0.01615654101379897, 0.02755554919431698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]},\n                    preset: 'viridis',\n                    tokenization_config: \"\"\n\n             })\n\n             window.ecco[viz_id].init();\n             window.ecco[viz_id].selectFirstToken();\n\n             }, function (err) {\n                console.log(err);\n            })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out0.primary_attributions(attr_method='ig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([16, 16, 16]), array([12, 13, 14])]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.argsort(abs(np.stack(out0.attribution['ig']) - np.stack(out1.attribution['ig'])).flatten())[::-1][:3] // 64,\n",
    "np.argsort(abs(np.stack(out0.attribution['ig']) - np.stack(out1.attribution['ig'])).flatten())[::-1][:3] % 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['poly_flag'] = torch.Tensor([0]).to(device)\n",
    "inputs['poly_flag'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n\n\n            let pred = new ecco.LayerPredictions({\n                parentDiv: viz_id,\n                data:[[{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.0014381408\", \"ranking\": 1, \"layer\": 0}, {\"token\": \"\\u0441\\u0442\\u043e\\u0440\\u043e\\u043d\", \"prob\": \"0.001097262\", \"ranking\": 2, \"layer\": 0}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.0010779102\", \"ranking\": 1, \"layer\": 1}, {\"token\": \"##\\u0435\\u0442\\u043e\\u0439\", \"prob\": \"0.00058196025\", \"ranking\": 2, \"layer\": 1}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.0009000953\", \"ranking\": 1, \"layer\": 2}, {\"token\": \"\\u0438\\u043d\\u043e\\u0433\\u0434\\u0430\", \"prob\": \"0.0004659592\", \"ranking\": 2, \"layer\": 2}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.00425631\", \"ranking\": 1, \"layer\": 3}, {\"token\": \"##\\u044e\\u0442\", \"prob\": \"0.0017229223\", \"ranking\": 2, \"layer\": 3}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.002771246\", \"ranking\": 1, \"layer\": 4}, {\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.0014521559\", \"ranking\": 2, \"layer\": 4}], [{\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.012900124\", \"ranking\": 1, \"layer\": 5}, {\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.0048567494\", \"ranking\": 2, \"layer\": 5}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.02684393\", \"ranking\": 1, \"layer\": 6}, {\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.020065267\", \"ranking\": 2, \"layer\": 6}], [{\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.045332905\", \"ranking\": 1, \"layer\": 7}, {\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.042308137\", \"ranking\": 2, \"layer\": 7}], [{\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.26713803\", \"ranking\": 1, \"layer\": 8}, {\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.12255971\", \"ranking\": 2, \"layer\": 8}], [{\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.284813\", \"ranking\": 1, \"layer\": 9}, {\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.14418912\", \"ranking\": 2, \"layer\": 9}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.15735644\", \"ranking\": 1, \"layer\": 10}, {\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.12770596\", \"ranking\": 2, \"layer\": 10}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.5562811\", \"ranking\": 1, \"layer\": 11}, {\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.19507928\", \"ranking\": 2, \"layer\": 11}]]\n            })\n            pred.init()\n         }, function (err) {\n            console.log(viz_id, err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'token': '##', 'prob': '0.0014381408', 'ranking': 1, 'layer': 0}, {'token': '', 'prob': '0.001097262', 'ranking': 2, 'layer': 0}], [{'token': '##', 'prob': '0.0010779102', 'ranking': 1, 'layer': 1}, {'token': '##', 'prob': '0.00058196025', 'ranking': 2, 'layer': 1}], [{'token': '##', 'prob': '0.0009000953', 'ranking': 1, 'layer': 2}, {'token': '', 'prob': '0.0004659592', 'ranking': 2, 'layer': 2}], [{'token': '##', 'prob': '0.00425631', 'ranking': 1, 'layer': 3}, {'token': '##', 'prob': '0.0017229223', 'ranking': 2, 'layer': 3}], [{'token': '##', 'prob': '0.002771246', 'ranking': 1, 'layer': 4}, {'token': '##', 'prob': '0.0014521559', 'ranking': 2, 'layer': 4}], [{'token': '##', 'prob': '0.012900124', 'ranking': 1, 'layer': 5}, {'token': '##', 'prob': '0.0048567494', 'ranking': 2, 'layer': 5}], [{'token': '##', 'prob': '0.02684393', 'ranking': 1, 'layer': 6}, {'token': '##', 'prob': '0.020065267', 'ranking': 2, 'layer': 6}], [{'token': '##', 'prob': '0.045332905', 'ranking': 1, 'layer': 7}, {'token': '##', 'prob': '0.042308137', 'ranking': 2, 'layer': 7}], [{'token': '##', 'prob': '0.26713803', 'ranking': 1, 'layer': 8}, {'token': '##', 'prob': '0.12255971', 'ranking': 2, 'layer': 8}], [{'token': '##', 'prob': '0.284813', 'ranking': 1, 'layer': 9}, {'token': '##', 'prob': '0.14418912', 'ranking': 2, 'layer': 9}], [{'token': '##', 'prob': '0.15735644', 'ranking': 1, 'layer': 10}, {'token': '##', 'prob': '0.12770596', 'ranking': 2, 'layer': 10}], [{'token': '##', 'prob': '0.5562811', 'ranking': 1, 'layer': 11}, {'token': '##', 'prob': '0.19507928', 'ranking': 2, 'layer': 11}]]\n"
     ]
    }
   ],
   "source": [
    "a = out1.layer_predictions(position=14, topk=2, poly_flag=inputs['poly_flag'], printJson=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html lang=\"en\">\n",
       "<script src=\"https://requirejs.org/docs/release/2.3.6/minified/require.js\"></script>\n",
       "<script>\n",
       "    var ecco_url = 'https://storage.googleapis.com/ml-intro/ecco/'\n",
       "    //var ecco_url = 'http://localhost:8000/'\n",
       "\n",
       "    if (window.ecco === undefined) window.ecco = {}\n",
       "\n",
       "    // Setup the paths of the script we'll be using\n",
       "    requirejs.config({\n",
       "        urlArgs: \"bust=\" + (new Date()).getTime(),\n",
       "        nodeRequire: require,\n",
       "        paths: {\n",
       "            d3: \"https://d3js.org/d3.v6.min\", // This is only for use in setup.html and basic.html\n",
       "            \"d3-array\": \"https://d3js.org/d3-array.v2.min\",\n",
       "            jquery: \"https://code.jquery.com/jquery-3.5.1.min\",\n",
       "            ecco: ecco_url + 'js/0.0.6/ecco-bundle.min',\n",
       "            xregexp: 'https://cdnjs.cloudflare.com/ajax/libs/xregexp/3.2.0/xregexp-all.min'\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Add the css file\n",
       "    //requirejs(['d3'],\n",
       "    //    function (d3) {\n",
       "    //        d3.select('#css').attr('href', ecco_url + 'html/styles.css')\n",
       "    //    })\n",
       "\n",
       "    console.log('Ecco initialize!!')\n",
       "\n",
       "    // returns a 'basic' object. basic.init() selects the html div we'll be\n",
       "    // rendering the html into, adds styles.css to the document.\n",
       "    define('basic', ['d3'],\n",
       "        function (d3) {\n",
       "            return {\n",
       "                init: function (viz_id = null) {\n",
       "                    if (viz_id == null) {\n",
       "                        viz_id = \"viz_\" + Math.round(Math.random() * 10000000)\n",
       "                    }\n",
       "                    // Select the div rendered below, change its id\n",
       "                    const div = d3.select('#basic').attr('id', viz_id),\n",
       "                        div_parent = d3.select('#' + viz_id).node().parentNode\n",
       "\n",
       "                    // Link to CSS file\n",
       "                    d3.select(div_parent).insert('link')\n",
       "                        .attr('rel', 'stylesheet')\n",
       "                        .attr('type', 'text/css')\n",
       "                        .attr('href', ecco_url + 'html/0.0.2/styles.css')\n",
       "\n",
       "                    return viz_id\n",
       "                }\n",
       "            }\n",
       "        }, function (err) {\n",
       "            console.log(err);\n",
       "        }\n",
       "    )\n",
       "</script>\n",
       "\n",
       "<head>\n",
       "    <link id='css' rel=\"stylesheet\" type=\"text/css\">\n",
       "</head>\n",
       "<div id=\"basic\"></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n         requirejs(['basic', 'ecco'], function(basic, ecco){\n            const viz_id = basic.init()\n\n\n            let pred = new ecco.LayerPredictions({\n                parentDiv: viz_id,\n                data:[[{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.0014381408\", \"ranking\": 1, \"layer\": 0}, {\"token\": \"\\u0441\\u0442\\u043e\\u0440\\u043e\\u043d\", \"prob\": \"0.001097262\", \"ranking\": 2, \"layer\": 0}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.0010779102\", \"ranking\": 1, \"layer\": 1}, {\"token\": \"##\\u0435\\u0442\\u043e\\u0439\", \"prob\": \"0.00058196025\", \"ranking\": 2, \"layer\": 1}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.0009000953\", \"ranking\": 1, \"layer\": 2}, {\"token\": \"\\u0438\\u043d\\u043e\\u0433\\u0434\\u0430\", \"prob\": \"0.0004659592\", \"ranking\": 2, \"layer\": 2}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.00425631\", \"ranking\": 1, \"layer\": 3}, {\"token\": \"##\\u044e\\u0442\", \"prob\": \"0.0017229223\", \"ranking\": 2, \"layer\": 3}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.002771246\", \"ranking\": 1, \"layer\": 4}, {\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.0014521559\", \"ranking\": 2, \"layer\": 4}], [{\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.012900124\", \"ranking\": 1, \"layer\": 5}, {\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.0048567494\", \"ranking\": 2, \"layer\": 5}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.02684393\", \"ranking\": 1, \"layer\": 6}, {\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.020065267\", \"ranking\": 2, \"layer\": 6}], [{\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.045332905\", \"ranking\": 1, \"layer\": 7}, {\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.042308137\", \"ranking\": 2, \"layer\": 7}], [{\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.26713803\", \"ranking\": 1, \"layer\": 8}, {\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.12255971\", \"ranking\": 2, \"layer\": 8}], [{\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.284813\", \"ranking\": 1, \"layer\": 9}, {\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.14418912\", \"ranking\": 2, \"layer\": 9}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.15735644\", \"ranking\": 1, \"layer\": 10}, {\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.12770596\", \"ranking\": 2, \"layer\": 10}], [{\"token\": \"##\\u0435\\u0442\", \"prob\": \"0.5562811\", \"ranking\": 1, \"layer\": 11}, {\"token\": \"##\\u0435\\u0442\\u0435\", \"prob\": \"0.19507928\", \"ranking\": 2, \"layer\": 11}]]\n            })\n            pred.init()\n         }, function (err) {\n            console.log(viz_id, err);\n        })",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out0.layer_predictions(position=14, topk=2, poly_flag=inputs['poly_flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 119547])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17, device='cuda:0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out0.token_ids[0] > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9436]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[:, 5:6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 67189,  49914,  56402,  37105, 116190,  77223,  28269,  32889,\n",
       "           72885,  52131]]], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_softmax[:,:,-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "position=5\n",
    "k = 10\n",
    "top_tokens = []\n",
    "probs = []\n",
    "data = []\n",
    "_, dec_hidden_states = out0._get_hidden_states()\n",
    "dec_hidden_states = [h[:,position:position+1,:] for h in dec_hidden_states]\n",
    "\n",
    "h = dec_hidden_states[0]\n",
    "logits = model.head(h, poly_flag=inputs[\"poly_flag\"])[0]\n",
    "softmax = softmax = F.softmax(logits, dim=-1)\n",
    "sorted_softmax = out0.to(torch.argsort(softmax))\n",
    "layer_top_tokens = [out0.tokenizer.decode(t) for t in sorted_softmax[0,0,-k:]][::-1]\n",
    "top_tokens.append(layer_top_tokens)\n",
    "layer_probs = softmax[0,0,sorted_softmax[0,0,-k:]].cpu().detach().numpy()[::-1]\n",
    "probs.append(layer_probs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 119547])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = softmax.cpu().detach()\n",
    "sorted_softmax = sorted_softmax.cpu().detach()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
